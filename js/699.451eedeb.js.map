{"version":3,"file":"js/699.451eedeb.js","mappings":"6GAAA,IAAI,OAAEA,GAAW,EAAQ,OAErBC,EAAI,CAAC,EAELC,EAAgBD,EAAEC,WAAgB,EAClCC,EAAgBF,EAAEE,YAAgB,EAClCC,EAAgBH,EAAEG,aAAgB,EAClCC,EAAgBJ,EAAEI,cAAgB,EAClCC,EAAgBL,EAAEK,MAAgB,EAClCC,EAAgBN,EAAEM,MAAgB,EAClCC,EAAgBP,EAAEO,KAAgB,EAClCC,EAAgBR,EAAEQ,MAAgB,EAClCC,EAAgBT,EAAES,KAAgB,EAClCC,EAAgBV,EAAEU,OAAgB,GAClCC,EAAgBX,EAAEW,OAAgB,GAElCC,EAAUZ,EAAEY,MAAU,GACtBC,EAAUb,EAAEa,KAAU,GACtBC,EAAUd,EAAEc,MAAU,GACtBC,EAAUf,EAAEe,MAAU,GACtBC,EAAUhB,EAAEgB,MAAU,GACtBC,EAAUjB,EAAEiB,OAAU,GACtBC,EAAUlB,EAAEkB,OAAU,GACtBC,EAAUnB,EAAEmB,OAAU,GACtBC,EAAUpB,EAAEoB,OAAU,GACtBC,EAAUrB,EAAEqB,MAAU,GACtBC,EAAUtB,EAAEsB,MAAU,GACtBC,EAAUvB,EAAEuB,MAAU,GACtBC,EAAUxB,EAAEwB,QAAU,GACtBC,EAAUzB,EAAEyB,QAAU,GACtBC,EAAU1B,EAAE0B,QAAU,GACtBC,EAAU3B,EAAE2B,QAAU,GACtBC,EAAU5B,EAAE4B,QAAU,GACtBC,EAAU7B,EAAE6B,QAAU,IACtBC,EAAU9B,EAAE8B,QAAU,IACtBC,EAAU/B,EAAE+B,QAAU,IAEtBC,EAAUhC,EAAEgC,MAAU,IACtBC,EAAUjC,EAAEiC,IAAU,IAEtBC,EAAUlC,EAAEkC,OAAU,IACtBC,EAAUnC,EAAEmC,MAAU,IAEtBC,EAAkB,KAAKC,WAAW,GAClCC,EAAkB,IAAKD,WAAW,GAClCE,EAAkB,KAAKF,WAAW,GAClCG,EAAkB,KAAKH,WAAW,GAClCI,EAAkB,KAAKJ,WAAW,GAClCK,EAAkB,KAAKL,WAAW,GAClCM,EAAkB,KAAKN,WAAW,GAElCO,EAAqB,MAEzB,SAASC,EAAMC,GACb,OAAO/C,EAAO8C,MAAQ9C,EAAO8C,MAAMC,GAAQ,IAAI/C,EAAO+C,EACxD,CAEA,SAASC,IACPC,KAAKC,OAASrC,EACdoC,KAAKE,WAAQC,EAEbH,KAAKI,YAASD,EACdH,KAAKK,aAAeR,EAAMD,GAC1BI,KAAKM,mBAAqB,EAC1BN,KAAKO,aAAUJ,EACfH,KAAKQ,mBAAgBL,EAErBH,KAAKS,SAAMN,EACXH,KAAKU,UAAOP,EACZH,KAAKW,MAAQ,GACbX,KAAKY,MAAQ5B,EACbgB,KAAKa,gBAAkB,EACvBb,KAAKc,kBAAoB,EACzBd,KAAKe,WAAa,CAAE,EAAKlB,EAAM,GAAI,EAAKA,EAAM,GAAI,EAAKA,EAAM,IAG7DG,KAAKgB,QAAU,CACjB,CAGAjB,EAAOkB,OAAS,SAAUC,GAExB,IADA,IAAIC,EAAOC,OAAOD,KAAKnE,GACdqE,EAAI,EAAGC,EAAIH,EAAKI,OAAQF,EAAIC,EAAGD,IAAK,CAC3C,IAAIZ,EAAMU,EAAKE,GACf,GAAIrE,EAAEyD,KAASS,EAAQ,OAAOT,CAChC,CACA,OAAOS,GAAS,KAAOA,EAAKM,SAAS,GACvC,EAEA,IAAIC,EAAQ1B,EAAO2B,UACnBD,EAAME,QAAU,SAAUC,GAAO,MAAMA,CAAK,EAC5CH,EAAMI,UAAY,SAAUC,EAAQT,GAClCrB,KAAKC,OAASpC,EACdmC,KAAK2B,QAAQ,IAAII,MAAM,cAAgBC,KAAKC,UAAUC,OAAOC,aAAaL,EAAOT,KAAO,gBAAkBA,EAAI,aAAetB,EAAOkB,OAAOjB,KAAKC,SAClJ,EACAwB,EAAMW,iBAAmB,SAAUC,GAC7BrC,KAAKM,oBAAsBV,IAC7BI,KAAKI,QAAUJ,KAAKK,aAAamB,SAAS,QAC1CxB,KAAKM,mBAAqB,GAG5BN,KAAKK,aAAaL,KAAKM,sBAAwB+B,CACjD,EACAZ,EAAMa,gBAAkB,SAAUC,EAAKC,EAAOC,GAC5C,IAAI3C,EAAOyC,EAAIhB,OACM,kBAAViB,IAIL1C,EAHe,kBAAR2C,EACLA,EAAM,EAEDF,EAAIhB,OAASiB,EAAQC,EAErBA,EAAMD,EAGRD,EAAIhB,OAASiB,GAIpB1C,EAAO,IACTA,EAAO,GAGLE,KAAKM,mBAAqBR,EAAOF,IACnCI,KAAKI,QAAUJ,KAAKK,aAAamB,SAAS,OAAQ,EAAGxB,KAAKM,oBAC1DN,KAAKM,mBAAqB,GAG5BiC,EAAIG,KAAK1C,KAAKK,aAAcL,KAAKM,mBAAoBkC,EAAOC,GAC5DzC,KAAKM,oBAAsBR,CAC7B,EACA2B,EAAMkB,MAAQ,SAAUb,GAEtB,IAAIc,EADkB,kBAAXd,IAAqBA,EAAS,IAAI/E,EAAO+E,IAEpD,IAAK,IAAIT,EAAI,EAAGC,EAAIQ,EAAOP,OAAQF,EAAIC,EAAGD,IACxC,GAAIrB,KAAKC,SAAWrC,GAGlB,GAFAgF,EAAId,EAAOT,GACXrB,KAAKgB,SACI,MAAN4B,EAAa5C,KAAK6C,QAAQ5F,EAAY,UACnC,GAAS,MAAN2F,EAAa5C,KAAK6C,QAAQ3F,EAAa,UAC1C,GAAS,KAAN0F,EAAa5C,KAAK6C,QAAQ1F,EAAc,UAC3C,GAAS,KAANyF,EAAa5C,KAAK6C,QAAQzF,EAAe,UAC5C,GAAS,KAANwF,EAAa5C,KAAK6C,QAAQxF,EAAO,UACpC,GAAS,KAANuF,EAAa5C,KAAK6C,QAAQvF,EAAO,UACpC,GAAS,MAANsF,EAAa5C,KAAKC,OAASnC,OAC9B,GAAS,MAAN8E,EAAa5C,KAAKC,OAAShC,OAC9B,GAAS,MAAN2E,EAAa5C,KAAKC,OAAS5B,OAC9B,GAAS,KAANuE,EACP5C,KAAKI,OAAS,GACdJ,KAAKM,mBAAqB,EAC1BN,KAAKC,OAASvB,OACV,GAAS,KAANkE,EAAa5C,KAAKI,OAAS,IAAKJ,KAAKC,OAASzB,OAErD,GAAIoE,GAAK,IAAQA,EAAI,GACnB5C,KAAKI,OAAS8B,OAAOC,aAAaS,GAAI5C,KAAKC,OAASxB,OAC/C,GAAU,KAANmE,GAAoB,IAANA,GAAoB,KAANA,GAAoB,KAANA,EAGnD,OAAO5C,KAAK6B,UAAUC,EAAQT,QAG9B,GAAIrB,KAAKC,SAAWvB,EAIxB,GAHAkE,EAAId,EAAOT,GAGPrB,KAAKa,gBAAkB,EAAG,CAC5B,IAAK,IAAIiC,EAAI,EAAGA,EAAI9C,KAAKa,gBAAiBiC,IACxC9C,KAAKe,WAAWf,KAAKc,mBAAmBd,KAAKc,kBAAoBd,KAAKa,gBAAkBiC,GAAKhB,EAAOgB,GAGtG9C,KAAKsC,gBAAgBtC,KAAKe,WAAWf,KAAKc,oBAC1Cd,KAAKc,kBAAoBd,KAAKa,gBAAkB,EAChDQ,EAAIA,EAAIyB,EAAI,CACd,MAAO,GAA6B,IAAzB9C,KAAKa,iBAAyB+B,GAAK,IAAK,CACjD,GAAIA,GAAK,KAAOA,EAAI,IAClB,OAAO5C,KAAK2B,QAAQ,IAAII,MAAM,uCAAyCV,EAAI,aAAetB,EAAOkB,OAAOjB,KAAKC,UAK/G,GAHK2C,GAAK,KAASA,GAAK,MAAM5C,KAAKc,kBAAoB,GAClD8B,GAAK,KAASA,GAAK,MAAM5C,KAAKc,kBAAoB,GAClD8B,GAAK,KAASA,GAAK,MAAM5C,KAAKc,kBAAoB,GAClDd,KAAKc,kBAAoBO,EAAKS,EAAOP,OAAQ,CAChD,IAAK,IAAIwB,EAAI,EAAGA,GAAMjB,EAAOP,OAAS,EAAIF,EAAI0B,IAC5C/C,KAAKe,WAAWf,KAAKc,mBAAmBiC,GAAKjB,EAAOT,EAAI0B,GAE1D/C,KAAKa,gBAAmBQ,EAAIrB,KAAKc,kBAAqBgB,EAAOP,OAC7DF,EAAIS,EAAOP,OAAS,CACtB,MACEvB,KAAKsC,gBAAgBR,EAAQT,EAAGA,EAAIrB,KAAKc,mBACzCO,EAAIA,EAAIrB,KAAKc,kBAAoB,CAErC,MAAO,GAAU,KAAN8B,EACT5C,KAAKC,OAASrC,EACdoC,KAAKI,QAAUJ,KAAKK,aAAamB,SAAS,OAAQ,EAAGxB,KAAKM,oBAC1DN,KAAKM,mBAAqB,EAC1BN,KAAK6C,QAAQnF,EAAQsC,KAAKI,QAC1BJ,KAAKgB,QAAUjE,EAAOiG,WAAWhD,KAAKI,OAAQ,QAAU,EACxDJ,KAAKI,YAASD,OAEX,GAAU,KAANyC,EACP5C,KAAKC,OAAStB,MAEX,MAAIiE,GAAK,IAEV,OAAO5C,KAAK6B,UAAUC,EAAQT,GAFZrB,KAAKoC,iBAAiBQ,EAG5C,MACI,GAAI5C,KAAKC,SAAWtB,EAExB,GADAiE,EAAId,EAAOT,GACF,KAANuB,EAAa5C,KAAKoC,iBAAiBQ,GAAI5C,KAAKC,OAASvB,OAClD,GAAS,KAANkE,EAAa5C,KAAKoC,iBAAiBhD,GAAaY,KAAKC,OAASvB,OACjE,GAAS,KAANkE,EAAa5C,KAAKoC,iBAAiB9C,GAAgBU,KAAKC,OAASvB,OACpE,GAAS,KAANkE,EAAa5C,KAAKoC,iBAAiB7C,GAAYS,KAAKC,OAASvB,OAChE,GAAS,MAANkE,EAAa5C,KAAKoC,iBAAiB5C,GAAYQ,KAAKC,OAASvB,OAChE,GAAS,MAANkE,EAAa5C,KAAKoC,iBAAiB3C,GAAUO,KAAKC,OAASvB,OAC9D,GAAS,MAANkE,EAAa5C,KAAKoC,iBAAiB1C,GAAkBM,KAAKC,OAASvB,OACtE,GAAS,MAANkE,EAAa5C,KAAKoC,iBAAiBzC,GAAMK,KAAKC,OAASvB,MAC1D,IAAS,MAANkE,EAEP,OAAO5C,KAAK6B,UAAUC,EAAQT,GAFVrB,KAAKO,QAAU,GAAIP,KAAKC,OAASrB,CAGvD,MACI,GAAIoB,KAAKC,SAAWrB,GAAWoB,KAAKC,SAAWpB,GAAWmB,KAAKC,SAAWnB,GAAWkB,KAAKC,SAAWlB,EAAQ,CAGjH,GAFA6D,EAAId,EAAOT,KAENuB,GAAK,IAAQA,EAAI,IAAUA,EAAI,IAAQA,GAAK,IAAUA,EAAI,IAAQA,GAAK,KAoB1E,OAAO5C,KAAK6B,UAAUC,EAAQT,GAlB9B,GADArB,KAAKO,SAAW2B,OAAOC,aAAaS,GAChC5C,KAAKC,WAAalB,EAAS,CAC7B,IAAIkE,EAASC,SAASlD,KAAKO,QAAS,IACpCP,KAAKO,aAAUJ,OACYA,IAAvBH,KAAKQ,eAA+ByC,GAAU,OAAUA,EAAS,OACnEjD,KAAKsC,gBAAgB,IAAIvF,EAAOmF,OAAOC,aAAanC,KAAKQ,cAAeyC,KACxEjD,KAAKQ,mBAAgBL,QACWA,IAAvBH,KAAKQ,eAA+ByC,GAAU,OAAUA,EAAS,MAC1EjD,KAAKQ,cAAgByC,QAEM9C,IAAvBH,KAAKQ,gBACPR,KAAKsC,gBAAgB,IAAIvF,EAAOmF,OAAOC,aAAanC,KAAKQ,iBACzDR,KAAKQ,mBAAgBL,GAEvBH,KAAKsC,gBAAgB,IAAIvF,EAAOmF,OAAOC,aAAac,MAEtDjD,KAAKC,OAASvB,CAChB,CAIJ,MAAO,GAAIsB,KAAKC,SAAWzB,GAAWwB,KAAKC,SAAWxB,EAGlD,OAFAmE,EAAId,EAAOT,GAEHuB,GACN,KAAK,GACL,KAAK,GACL,KAAK,GACL,KAAK,GACL,KAAK,GACL,KAAK,GACL,KAAK,GACL,KAAK,GACL,KAAK,GACL,KAAK,GACL,KAAK,GACL,KAAK,IACL,KAAK,GACL,KAAK,GACL,KAAK,GACH5C,KAAKI,QAAU8B,OAAOC,aAAaS,GACnC5C,KAAKC,OAASxB,EACd,MACF,QACEuB,KAAKC,OAASrC,EACd,IAAIuF,EAAQnD,KAAKoD,cAAcpD,KAAKI,QACpC,GAAI+C,EACF,OAAOA,EAGTnD,KAAKgB,QAAUhB,KAAKI,OAAOmB,OAAS,EACpCvB,KAAKI,YAASD,EACdkB,IACA,WAEF,GAAIrB,KAAKC,SAAWnC,EAAM,CAC9B,GAAkB,MAAdgE,EAAOT,GACJ,OAAOrB,KAAK6B,UAAUC,EAAQT,GADXrB,KAAKC,OAASlC,CAE1C,MAAM,GAAIiC,KAAKC,SAAWlC,EAAM,CAC9B,GAAkB,MAAd+D,EAAOT,GACJ,OAAOrB,KAAK6B,UAAUC,EAAQT,GADXrB,KAAKC,OAASjC,CAE1C,MAAM,GAAIgC,KAAKC,SAAWjC,EAAM,CAC9B,GAAkB,MAAd8D,EAAOT,GACJ,OAAOrB,KAAK6B,UAAUC,EAAQT,GADXrB,KAAKC,OAASrC,EAAOoC,KAAK6C,QAAQtF,GAAM,GAAOyC,KAAKgB,QAAS,CAEzF,MAAM,GAAIhB,KAAKC,SAAWhC,EAAO,CAC/B,GAAkB,KAAd6D,EAAOT,GACJ,OAAOrB,KAAK6B,UAAUC,EAAQT,GADXrB,KAAKC,OAAS/B,CAE1C,MAAM,GAAI8B,KAAKC,SAAW/B,EAAO,CAC/B,GAAkB,MAAd4D,EAAOT,GACJ,OAAOrB,KAAK6B,UAAUC,EAAQT,GADXrB,KAAKC,OAAS9B,CAE1C,MAAM,GAAI6B,KAAKC,SAAW9B,EAAO,CAC/B,GAAkB,MAAd2D,EAAOT,GACJ,OAAOrB,KAAK6B,UAAUC,EAAQT,GADXrB,KAAKC,OAAS7B,CAE1C,MAAM,GAAI4B,KAAKC,SAAW7B,EAAO,CAC/B,GAAkB,MAAd0D,EAAOT,GACJ,OAAOrB,KAAK6B,UAAUC,EAAQT,GADXrB,KAAKC,OAASrC,EAAOoC,KAAK6C,QAAQrF,GAAO,GAAQwC,KAAKgB,QAAS,CAE3F,MAAM,GAAIhB,KAAKC,SAAW5B,EAAM,CAC9B,GAAkB,MAAdyD,EAAOT,GACJ,OAAOrB,KAAK6B,UAAUC,EAAQT,GADXrB,KAAKC,OAAS3B,CAE1C,MAAM,GAAI0B,KAAKC,SAAW3B,EAAM,CAC9B,GAAkB,MAAdwD,EAAOT,GACJ,OAAOrB,KAAK6B,UAAUC,EAAQT,GADXrB,KAAKC,OAAS1B,CAE1C,MAAM,GAAIyB,KAAKC,SAAW1B,EAAM,CAC9B,GAAkB,MAAduD,EAAOT,GACJ,OAAOrB,KAAK6B,UAAUC,EAAQT,GADXrB,KAAKC,OAASrC,EAAOoC,KAAK6C,QAAQpF,EAAM,MAAOuC,KAAKgB,QAAU,CAE1F,CAEJ,EACAS,EAAMoB,QAAU,SAAUQ,EAAOnD,GAEjC,EAEAuB,EAAM6B,WAAa,SAAUD,EAAOnD,GAClCF,KAAKC,OAASpC,EACdmC,KAAK2B,QAAQ,IAAII,MAAM,cAAgBhC,EAAOkB,OAAOoC,IAAUnD,EAAS,IAAM8B,KAAKC,UAAU/B,GAAS,IAAO,IAAM,aAAeH,EAAOkB,OAAOjB,KAAKY,QACvJ,EACAa,EAAM8B,KAAO,WACXvD,KAAKW,MAAM4C,KAAK,CAACrD,MAAOF,KAAKE,MAAOO,IAAKT,KAAKS,IAAKC,KAAMV,KAAKU,MAChE,EACAe,EAAM+B,IAAM,WACV,IAAItD,EAAQF,KAAKE,MACbuD,EAASzD,KAAKW,MAAM6C,MACxBxD,KAAKE,MAAQuD,EAAOvD,MACpBF,KAAKS,IAAMgD,EAAOhD,IAClBT,KAAKU,KAAO+C,EAAO/C,KACnBV,KAAK0D,KAAKxD,GACLF,KAAKU,OAAQV,KAAKY,MAAQ5B,EACjC,EACAyC,EAAMiC,KAAO,SAAUxD,GACjBF,KAAKU,OAAQV,KAAKY,MAAQtD,GAC9B0C,KAAK2D,QAAQzD,EACf,EACAuB,EAAMkC,QAAU,SAAUzD,GAE1B,EACAuB,EAAMoB,QAAU,SAAUQ,EAAOnD,GAC/B,GAAGF,KAAKY,QAAU5B,EAChB,GAAGqE,IAAU3F,GAAU2F,IAAU1F,GAAU0F,IAAU9F,GAAQ8F,IAAU7F,GAAS6F,IAAU5F,EACpFuC,KAAKE,QACPF,KAAKE,MAAMF,KAAKS,KAAOP,GAEzBF,KAAK0D,KAAKxD,QACN,GAAGmD,IAAUpG,EACjB+C,KAAKuD,OACDvD,KAAKE,MACPF,KAAKE,MAAQF,KAAKE,MAAMF,KAAKS,KAAO,CAAC,EAErCT,KAAKE,MAAQ,CAAC,EAEhBF,KAAKS,SAAMN,EACXH,KAAKY,MAAQ3B,EACbe,KAAKU,KAAOxB,OACR,GAAGmE,IAAUlG,EACjB6C,KAAKuD,OACDvD,KAAKE,MACPF,KAAKE,MAAQF,KAAKE,MAAMF,KAAKS,KAAO,GAEpCT,KAAKE,MAAQ,GAEfF,KAAKS,IAAM,EACXT,KAAKU,KAAOvB,EACZa,KAAKY,MAAQ5B,OACT,GAAGqE,IAAUnG,EAAY,CAC7B,GAAI8C,KAAKU,OAASxB,EAGhB,OAAOc,KAAKsD,WAAWD,EAAOnD,GAF9BF,KAAKwD,KAIT,KAAM,IAAGH,IAAUjG,EAOjB,OAAO4C,KAAKsD,WAAWD,EAAOnD,GAN9B,GAAIF,KAAKU,OAASvB,EAGhB,OAAOa,KAAKsD,WAAWD,EAAOnD,GAF9BF,KAAKwD,KAMT,MACI,GAAGxD,KAAKY,QAAU3B,EACtB,GAAIoE,IAAU3F,EACZsC,KAAKS,IAAMP,EACXF,KAAKY,MAAQvD,MACR,IAAIgG,IAAUnG,EAGnB,OAAO8C,KAAKsD,WAAWD,EAAOnD,GAF9BF,KAAKwD,KAGP,MACI,GAAGxD,KAAKY,QAAUvD,EAAM,CAC5B,GAAIgG,IAAUhG,EACP,OAAO2C,KAAKsD,WAAWD,EAAOnD,GADdF,KAAKY,MAAQ5B,CAEtC,KAAM,IAAGgB,KAAKY,QAAUtD,EAWtB,OAAO0C,KAAKsD,WAAWD,EAAOnD,GAV9B,GAAImD,IAAU/F,EACR0C,KAAKU,OAASvB,GAASa,KAAKS,MAAOT,KAAKY,MAAQ5B,GAC3CgB,KAAKU,OAASxB,IAAUc,KAAKY,MAAQ3B,OAEzC,MAAIoE,IAAUjG,GAAiB4C,KAAKU,OAASvB,GAASkE,IAAUnG,GAAe8C,KAAKU,OAASxB,GAGlG,OAAOc,KAAKsD,WAAWD,EAAOnD,GAF9BF,KAAKwD,KAGP,CAGF,CACF,EAIA/B,EAAM2B,cAAgB,SAAUQ,GAC9B,IAAIC,EAASC,OAAOF,GAEpB,GAAIG,MAAMF,GACR,OAAO7D,KAAK6B,UAAUC,OAAQT,GAG3BuC,EAAKI,MAAM,WAAaJ,GAAUC,EAAOrC,YAAcoC,EAE1D5D,KAAK6C,QAAQnF,EAAQkG,GAErB5D,KAAK6C,QAAQlF,EAAQkG,EAEzB,EAEA9D,EAAO/C,EAAIA,EAEXiH,EAAOC,QAAUnE,C,qCCxajB,IAAIoE,EAAmBnE,MAAQA,KAAKmE,kBAAqB/C,OAAOgD,OAAS,SAAUC,EAAGC,EAAGvB,EAAGwB,QAC7EpE,IAAPoE,IAAkBA,EAAKxB,GAC3B,IAAIyB,EAAOpD,OAAOqD,yBAAyBH,EAAGvB,GACzCyB,KAAS,QAASA,GAAQF,EAAEI,WAAaF,EAAKG,UAAYH,EAAKI,gBAClEJ,EAAO,CAAEK,YAAY,EAAMC,IAAK,WAAa,OAAOR,EAAEvB,EAAI,IAE5D3B,OAAO2D,eAAeV,EAAGE,EAAIC,EAChC,EAAI,SAAUH,EAAGC,EAAGvB,EAAGwB,QACTpE,IAAPoE,IAAkBA,EAAKxB,GAC3BsB,EAAEE,GAAMD,EAAEvB,EACb,GACGiC,EAAgBhF,MAAQA,KAAKgF,cAAiB,SAASV,EAAGJ,GAC1D,IAAK,IAAIe,KAAKX,EAAa,YAANW,GAAoB7D,OAAOM,UAAUwD,eAAeC,KAAKjB,EAASe,IAAId,EAAgBD,EAASI,EAAGW,EAC3H,EACA7D,OAAO2D,eAAeb,EAAS,aAAc,CAAEhE,OAAO,IACtD8E,EAAa,EAAQ,OAAuBd,E,kCCf5C9C,OAAO2D,eAAeb,EAAS,aAAc,CAAEhE,OAAO,IACtDgE,EAAQkB,iBAAc,EAOtB,MAAMA,EACF,WAAAC,GACIrF,KAAKsF,SAAW,CAAC,CACrB,CACA,UAAAC,CAAWpE,GACP,GAAIA,EAAKI,OAAS,EAAG,CACjB,MAAOiE,KAASC,GAAQtE,EAClBuE,EAAU1F,KAAKsF,SAASE,GAC9B,GAAIE,EAAS,CACT,MAAMC,EAAaD,EAAQH,WAAWE,GACtC,GAAIE,EACA,OAAOA,EAAWC,MAAK,EAAGC,UAASC,YAAY,CAAGD,UAASC,MAAOA,EAAQ,KAElF,CACJ,CACA,OAAO9F,KAAK6F,QAAU7F,KAAK6F,QAAQD,MAAMC,IAAY,CAAGA,UAASC,MAAO,MAAQ,IACpF,CACA,UAAAC,CAAW5E,EAAM0E,GACb,GAAoB,IAAhB1E,EAAKI,OACLvB,KAAK6F,QAAUA,MAEd,CACD,MAAOL,KAASC,GAAQtE,EACxB,IAAIuE,EAAU1F,KAAKsF,SAASE,GACvBE,IACDA,EAAU1F,KAAKsF,SAASE,GAAQ,IAAIJ,GAExCM,EAAQK,WAAWN,EAAMI,EAC7B,CACJ,CACA,aAAAG,CAAcC,GACVjG,KAAK+F,WAAWE,EAAM,KAC1B,EAEJ/B,EAAQkB,YAAcA,C,qCC1CtBhE,OAAO2D,eAAeb,EAAS,aAAc,CAAEhE,OAAO,IACtDgE,EAAQgC,kBAAe,EAEvB,MAAMnG,EAAS,EAAQ,OACjBoG,EAA0B,EAAQ,OAClCC,EAAoB,EAAQ,OAC5BC,EAA2B,EAAQ,MACnCC,EAA0B,EAAQ,OAClCC,EAAgC,EAAQ,MACxCC,EAA0B,EAAQ,OAClCC,EAA+B,EAAQ,OACvCC,EAA6B,EAAQ,OACrCC,EAA0B,EAAQ,OAClCC,EAAgC,EAAQ,OACxCC,EAA4B,EAAQ,MACpCC,EAA4B,EAAQ,OACpCC,EAAuC,EAAQ,OAC/CC,EAA6B,EAAQ,OACrCC,EAAmB,EAAQ,OAC3BC,EAAS,EAAQ,OACjBC,EAAqB,EAAQ,MAC7BC,EAAkC,EAAQ,OAIhD,MAAMlB,UAAqBE,EAAkBiB,UACzC,WAAAhC,CAAYiC,GACRC,MAAM,CAAEC,oBAAoB,IAC5BF,EAAUA,GAAW,CAAC,EACtBtH,KAAKsH,QAAUA,EACftH,KAAKyH,eAAiB,IAAIR,EAAiBS,eAAetG,OAAOuG,OAAO,CAAEC,OAAQ5H,MAAQsH,IAC1FtH,KAAK6H,KAAO,IAAIX,EAAOY,KAAK,CAAEC,YAAaT,EAAQS,YAAaN,eAAgBzH,KAAKyH,iBACrFzH,KAAKgI,WAAa,IAAIjI,EACtBC,KAAKiI,YAAc,GACnBjI,KAAKkI,SAAW,GAChBlI,KAAKmI,oBAAsB,GAC3BnI,KAAKoI,UAAY,EACjBpI,KAAKqI,SAAW,GAChBrI,KAAKsI,eAAiBC,QAAQC,UAC9BxI,KAAKyI,4BACLzI,KAAK0I,GAAG,OAAO,KACyB,qBAAzB1I,KAAKgI,WAAWtH,MACvBV,KAAK0D,KAAK,QAAS,IAAI3B,MAAM,qBACjC,GAER,CAgBA,uBAAO4G,CAAiBC,EAASC,EAAWC,EAASxB,GACjD,IAAIzB,EA8BAkD,EA7BAC,EAAsB,CAAC,6BAK3B,GAJI1B,GAAWA,EAAQ0B,sBACnBA,EAAsB1B,EAAQ0B,qBAGhB,wBAAdH,IAAwCG,EAAoBC,SAASJ,GAAY,CAEjF,GAAkB,qBAAdA,IAAqCA,EAAUK,SAAS,SACxD,MAAM,IAAI/C,EAAwBgD,WAAW,kCAAkCN,IAAa1C,EAAwBiD,YAAYC,yBAgBpI,GAbIP,GAAWA,EAAQQ,IAAI,SACvBR,EAAQS,SAAQ,CAACrJ,EAAOO,KACpB,GAAY,SAARA,EAAgB,CAChB,MAAM+I,GAAa,EAAIrC,EAAmBsC,OAAOvJ,GACjD,IAAK,MAAMwJ,KAAQF,EAAW1E,IAAI,MAAO,wCAAyC,CAC9E,GAAIe,EACA,MAAM,IAAIM,EAAwBgD,WAAW,uDAAyDP,EAASzC,EAAwBiD,YAAYO,+BAEvJ9D,EAAU6D,EAAKE,GACnB,CACJ,MAGH/D,KAAyB,OAAZyB,QAAgC,IAAZA,OAAqB,EAASA,EAAQuC,gCACxE,MAAM,IAAI1D,EAAwBgD,WAAW,8CAA8CN,QAAgBD,IAAWzC,EAAwBiD,YAAYC,wBAElK,CAGA,GAAIP,GAAWA,EAAQQ,IAAI,gBAAiB,CACxC,MAAMQ,EAAchB,EAAQhE,IAAI,gBAC1Bd,EAAQ,qBAAqB+F,KAAKD,GACpC9F,GAAsB,2CAAbA,EAAM,KACf+E,GAAmB,EAE3B,CACA,OAAO,IAAI7C,EAAa9E,OAAOuG,OAAO,CAAEiB,UACpC/C,UACAkD,oBAAoBzB,GAAoB,CAAC,GACjD,CAMA,MAAA0C,CAAOC,GACH,GAAI,SAAUA,EAAQ,CAClBA,EAAOvB,GAAG,SAAUvF,GAAU+G,EAAOxG,KAAK,QAASP,KACnD,MAAM+G,EAASD,EAAOE,KAAK,IAAIjE,EAAalG,KAAKsH,UACjD,OAAO4C,CACX,CACK,CACD,MAAME,EAAS,IAAIhE,EAAkBiE,YAAY,CAAE7C,oBAAoB,IACvEyC,EAAOvB,GAAG,SAAUvF,GAAU+G,EAAOxG,KAAK,QAASP,KACnD8G,EAAOvB,GAAG,QAAS4B,GAASF,EAAO7G,KAAK+G,KACxCL,EAAOvB,GAAG,OAAO,IAAM0B,EAAO7G,KAAK,QACnC,MAAM2G,EAASE,EAAOD,KAAK,IAAIjE,EAAalG,KAAKsH,UACjD,OAAO4C,CACX,CACJ,CACA,UAAAK,CAAWC,EAAOC,EAAUC,GACxB1K,KAAKgI,WAAWrF,MAAM6H,GACtBxK,KAAKsI,eACA1C,MAAK,IAAM8E,MAAavH,GAAUuH,EAASvH,IACpD,CAYA,mBAAMwH,CAAcxJ,EAAMjB,EAAO4F,EAAO8E,GACpC,IAAIC,GAAc,EAGlB,GAAID,GAAkB9E,EAAQ9F,KAAKoI,UAAW,CAE1C,MAAM0C,EAAc9K,KAAKyH,eAAesD,iBAAiB/K,KAAKoI,WAC1D0C,IAEIA,EAAY5K,OACZF,KAAKuD,KAAKvD,KAAK6H,KAAKE,YAAYiD,KAAKF,EAAY5K,MAAOF,KAAK6H,KAAKoD,QAASjL,KAAK6H,KAAKqD,OAAQlL,KAAK6H,KAAKsD,oBAG3GL,EAAYM,OAAOC,UAAW,EAC9BrL,KAAKyH,eAAe6D,QAAQR,EAAYS,cAAgB,GAAK,CAACT,EAAYM,QAC1EpL,KAAKyH,eAAesD,iBAAiBS,OAAOxL,KAAKoI,UAAW,UAItD9B,EAAwBmF,sBAAsBC,6BAA6B1L,KAAKyH,eAAgBzH,KAAKqI,SAAUrI,KAAKoI,YAC1HpI,KAAKyH,eAAekE,6BACfpI,KAAK,CAAEuC,MAAO9F,KAAKoI,UAAWjH,KAAMnB,KAAKqI,SAASuD,MAAM,EAAG5L,KAAKqI,SAAS9G,UAC9EsJ,GAAc,SAGR7K,KAAK6L,YAAY7L,KAAKoI,UAAWpI,KAAKqI,SAEpD,CACA,MAAM5H,QAAYT,KAAK6H,KAAKiE,eAAe3K,EAAK2E,GAAQ3E,EAAM2E,GACxDiG,QAAkB/L,KAAK6H,KAAKmE,qBAAqB7K,EAAM2E,GAC7D9F,KAAKyH,eAAewE,aAAanG,IAAS,EAC1C,IAAIoG,GAAY,EAEZ/F,EAAwB2B,KAAKqE,eAAe1L,IAAsB,aAAdsL,GAAoC,aAARtL,GAChFT,KAAK0D,KAAK,QAAS,IAAIyC,EAAwBgD,WAAW,kBAAkBjJ,iCAAsCiG,EAAwBiD,YAAYgD,+BAI1J,IAAIC,GAAa,EACbrM,KAAKyH,eAAe6E,gBAAgB/K,OAAS,IAC7C8K,EAAarM,KAAKyH,eAAe6E,gBAAgBtM,KAAKyH,eAAe6E,gBAAgB/K,OAAS,GAAGgL,UAErG,IAAK,IAAIlL,EAAImL,KAAKC,IAAI,EAAGzM,KAAKyH,eAAe6E,gBAAgB/K,OAAS,GAAIF,EAAIF,EAAKI,OAAS,EAAGF,IAAK,CAChG,MAAMqL,EAAmB1M,KAAKyH,eAAe6E,gBAAgBjL,KACrDrB,KAAKyH,eAAe6E,gBAAgBjL,SAAWrB,KAAK2M,YAAYxL,EAAKyK,MAAM,EAAGvK,EAAI,GAAIA,EAAGgL,IACjG,IAAKK,EAAiBE,MAAO,CACzB5M,KAAKyH,eAAewE,aAAanG,IAAS,EAC1CoG,GAAY,EACZ,KACJ,EACUG,GAAcK,EAAiBH,WACrCF,GAAa,EAErB,CAMA,SAJUrM,KAAK6H,KAAKgF,UAAU1L,EAAM2E,KAChCoG,GAAY,GAGZA,EACA,IAAK,MAAMY,KAAgB5G,EAAa6G,eAAgB,CACpD,MAAMC,QAAmBF,EAAaG,KAAKjN,KAAKyH,eAAgBzH,KAAK6H,KAAMpH,EAAKU,EAAM2E,GACtF,GAAIkH,EAAY,OAENF,EAAaI,OAAOlN,KAAKyH,eAAgBzH,KAAK6H,KAAMpH,EAAKU,EAAMjB,EAAO4F,EAAOkH,GAE/EF,EAAaK,qBACbnN,KAAKyH,eAAe2F,gBAAgBtH,IAAS,GAEjD,KACJ,CACJ,CAGU,IAAVA,GAAeuH,MAAMC,QAAQpN,UACvBF,KAAK6H,KAAK0F,qBAAqBrN,GAGrC2K,GAAe/E,EAAQ9F,KAAKoI,WAE5BpI,KAAK6K,YAAY7K,KAAKoI,WAE1BpI,KAAKoI,UAAYtC,EACjB9F,KAAKqI,SAAWlH,EAEhBnB,KAAKyH,eAAe+F,2BAA2BhC,OAAO1F,EAAQ,EAClE,CAKA,WAAA+E,CAAY/E,GACR9F,KAAKyH,eAAe2F,gBAAgB5B,OAAO1F,EAAO,GAClD9F,KAAKyH,eAAegG,eAAejC,OAAO1F,EAAO,GACjD9F,KAAKyH,eAAewE,aAAaT,OAAO1F,EAAO,GAC/C9F,KAAKyH,eAAe6D,QAAQE,OAAO1F,EAAO,GAC1C9F,KAAKyH,eAAeiG,WAAWlC,OAAO1F,EAAQ,EAAG,GACjD9F,KAAKyH,eAAekG,wBAAwBnC,OAAO1F,EAAO,GAC1D9F,KAAKyH,eAAemG,iBAAiBpC,OAAO1F,EAAO,GACnD9F,KAAKyH,eAAe6E,gBAAgBd,OAAO1F,EAAQ,EAAG,GACtD9F,KAAKyH,eAAeoG,aAAarC,OAAO1F,EAAO9F,KAAKyH,eAAeoG,aAAatM,OAASuE,GACzF9F,KAAKyH,eAAeqG,kBAAkBtC,OAAO1F,EAAO,EAExD,CAUA,iBAAM+F,CAAY/F,EAAO3E,GACrB,IAAI4M,EAAW/N,KAAKyH,eAAe6D,QAAQxF,GAC3C,MAAMkI,IAAuBD,EACxBC,IACDD,EAAW/N,KAAKyH,eAAe6D,QAAQxF,GAAS,CAAC9F,KAAK6H,KAAKE,YAAYkG,cAG3E,MAAMC,EAAclO,KAAKyH,eAAe0G,yBAAyBrI,GACjE,GAAIoI,EAAa,CACb,IAAK,MAAME,KAAWL,EAAU,CAC5B,MAAMM,QAAyBrO,KAAK6H,KAAKyG,oBAAoBxI,EAAO3E,GAC9DoN,EAAUvO,KAAKyH,eAAeiG,WAAW5H,IAAUuI,GAAoB,EACvErO,KAAKyH,eAAe6D,QAAQxF,EAAQuI,EAAmB,GACvD,OAAOrO,KAAK6H,KAAK2G,uBAAuBrN,EAAM2E,IACpD,GAAIyI,EACA,IAAK,MAAME,KAASF,EAAQ,CAExBvO,KAAKyH,eAAewE,aAAanG,IAAS,EAC1C,IAAK,MAAM4I,KAAiBR,EACxBlO,KAAK6H,KAAK8G,gBAAgB7I,EAAOsI,EAASM,EAAcE,UAAWF,EAAcG,OAAQJ,EAAOC,EAAcI,QAASJ,EAAcK,WAE7I,KAEC,CAED,MAAMC,EAAiBhP,KAAKyH,eAAewH,+BAA+BnJ,QAAc9F,KAAK6H,KAAKyG,oBAAoBxI,EAAO3E,GAAQ,GACrI,IAAK,MAAMuN,KAAiBR,EACpBQ,EAAcI,QACdE,EAAezL,KAAK,CAChBsL,OAAQT,EACRQ,UAAWF,EAAcE,UACzBR,QAASM,EAAcG,OACvBE,WAAYL,EAAcK,aAI9BC,EAAezL,KAAK,CAChBsL,OAAQH,EAAcG,OACtBD,UAAWF,EAAcE,UACzBR,UACAW,WAAYL,EAAcK,YAI1C,CACJ,CACA/O,KAAKyH,eAAe0G,yBAAyB3C,OAAO1F,EAAO,GAC3D9F,KAAKyH,eAAeoG,aAAarC,OAAO1F,EAAO,GAC/C9F,KAAKyH,eAAemG,iBAAiBpC,OAAO1F,EAAO,EACvD,CAEA,MAAMoJ,EAAclP,KAAKyH,eAAe0H,yBAAyBrJ,GACjE,GAAIoJ,EAAa,CACb,IAAK,MAAMd,KAAWL,EAAU,CAI5B,MAAMU,EAAkB,IAAV3I,GAAoC,cAArBsI,EAAQgB,UAC7BpP,KAAKyH,eAAe4H,mBAAmDjB,EAA9BpO,KAAK6H,KAAKsD,kBAC3DnL,KAAKyH,eAAewE,aAAanG,IAAS,EAC1C,IAAK,MAAM4I,KAAiBQ,EACxBlP,KAAKyH,eAAe6H,SAASxJ,EAAO9F,KAAK6H,KAAKE,YAAYiD,KAAK0D,EAAcN,QAASM,EAAcE,UAAWF,EAAcG,OAAQJ,GAE7I,CACAzO,KAAKyH,eAAe0H,yBAAyB3D,OAAO1F,EAAO,EAC/D,CAEA,MAAMgI,EAAoB9N,KAAKyH,eAAeqG,kBAAkBhI,GAChE,GAAIgI,EAAmB,CAEfA,EAAkBvM,OAAS,GAAe,IAAVuE,GAChC9F,KAAKyH,eAAe8H,UAAU,IAAIpJ,EAAwBgD,WAAW,iDAAkDhD,EAAwBiD,YAAYoG,qBAG/J,MAAMC,EAA0BzP,KAAKyH,eAAeiI,yBAAyB5J,EAAQ,GACrF,IAAK,MAAM6J,KAAc7B,EACrB2B,EAAwBlM,KAAKoM,UAE1B3P,KAAKyH,eAAeqG,kBAAkBhI,EACjD,CACJ,CAQA,iBAAM6G,CAAYxL,EAAM2E,EAAOuG,GAC3B,IAAK,MAAMS,KAAgB5G,EAAa6G,eACpC,SAAUD,EAAa8C,SAAS5P,KAAKyH,eAAgBzH,KAAK6H,KAAM1G,EAAM2E,EAAOuG,GACzE,MAAO,CAAEO,OAAO,EAAML,SAAUF,GAAcS,EAAa+C,qBAGnE,MAAO,CAAEjD,OAAO,EAAOL,UAAU,EACrC,CAMA,yBAAA9D,GAEIzI,KAAKgI,WAAWrE,QAAWzD,IACvB,MAAM4F,EAAQ9F,KAAKgI,WAAWrH,MAAMY,OAC9BJ,EAAQ,IAAIkM,MAAMvH,EAAQ,GAAGgK,KAAK,GAAIC,KAAI,CAACC,EAAG3O,IACzCA,IAAMyE,EAAQ9F,KAAKgI,WAAWvH,IAAMT,KAAKgI,WAAWrH,MAAMU,GAAGZ,MAExE,IAAKT,KAAKiQ,sBAAsBnK,GAAQ,CACpC,MAAMoK,EAAa,IAAMlQ,KAAK2K,cAAcxJ,EAAMjB,EAAO4F,GAAO,GAChE,GAAK9F,KAAKyH,eAAesB,kBACjB/I,KAAKyH,eAAe0I,YAAY5K,WAAWpE,EAAKyK,MAAM,GAAI,IAmB9D5L,KAAKsI,eAAiBtI,KAAKsI,eAAe1C,KAAKsK,QAb/C,GAAoB,aAAhB/O,EAAK2E,GAAuB,CAC5B,IAAIsK,EAAOpQ,KAAKiI,YAAYnC,GACvBsK,IACDA,EAAOpQ,KAAKiI,YAAYnC,GAAS,IAErCsK,EAAK7M,KAAK2M,EACd,MAEIlQ,KAAKmI,oBAAoB5E,KAAK,CAAE8M,IAAKH,EAAY/O,OAAM2E,UAQ1D9F,KAAKyH,eAAesB,kBAA8B,IAAVjD,IACzC9F,KAAKsI,eAAiBtI,KAAKsI,eACtB1C,MAAK,IAAM5F,KAAKsQ,wBAE7B,GAEJtQ,KAAKgI,WAAWrG,QAAWwB,IACvBnD,KAAK0D,KAAK,QAASP,EAAM,CAEjC,CAMA,qBAAA8M,CAAsBnK,GAClB,IAAK,IAAIzE,EAAIyE,EAAOzE,EAAI,EAAGA,IACvB,GAAyC,aAArCrB,KAAKgI,WAAWrH,MAAMU,EAAI,GAAGZ,IAC7B,OAAO,EAGf,OAAO,CACX,CAKA,yBAAM6P,GAEF,IAAK,MAAMF,KAAQpQ,KAAKiI,YACpB,GAAImI,EACA,IAAK,MAAMC,KAAOD,QACRC,IAKlBrQ,KAAKyH,eAAe+F,2BAA2BhC,OAAO,GACtD,MAAMrD,EAAsB,GAC5B,IAAK,MAAMkI,KAAOrQ,KAAKmI,oBACsE,gBAA9EnI,KAAK6H,KAAKiE,eAAeuE,EAAIlP,KAAKkP,EAAIvK,OAAQuK,EAAIlP,KAAMkP,EAAIvK,OAAO,IACxC,kBAAxBuK,EAAIlP,KAAKkP,EAAIvK,QAAoH,gBAAtF9F,KAAK6H,KAAKiE,eAAeuE,EAAIlP,KAAKkP,EAAIvK,MAAQ,GAAIuK,EAAIlP,KAAMkP,EAAIvK,MAAQ,GAAG,GAEhI9F,KAAKkI,SAAS3E,KAAK,CAAE8M,IAAKA,EAAIA,IAAKlP,KAAMkP,EAAIlP,KAAKyK,MAAM,EAAGyE,EAAIlP,KAAKI,OAAS,KAG7E4G,EAAoB5E,KAAK8M,GAIjC,IAAK,MAAMA,KAAOlI,EAAqB,CAGnC,GAAInI,KAAKkI,SAAS3G,OAAS,EAAG,CAE1B,MAAMgP,EAAqB,GACrBC,EAAuB,GAC7B,IAAK,IAAInP,EAAI,EAAGA,EAAIrB,KAAKkI,SAAS3G,OAAQF,IAAK,CAC3C,MAAMoP,EAAUzQ,KAAKkI,SAAS7G,GAC1B6F,EAAOY,KAAK4I,cAAcD,EAAQtP,KAAMkP,EAAIlP,QAC5CoP,EAAmBhN,KAAKkN,GACxBD,EAAqBjN,KAAKlC,GAElC,CAEA,MAAMsP,EAAiBJ,EAAmBK,MAAK,CAACC,EAAMC,IAASD,EAAK1P,KAAKI,OAASuP,EAAK3P,KAAKI,SAE5F,IAAK,MAAMkP,KAAWE,QACZF,EAAQJ,MAIlB,MAAMU,EAA6BP,EAAqBI,OAAO9B,UAC/D,IAAK,MAAMkC,KAASD,EAChB/Q,KAAKkI,SAASsD,OAAOwF,EAAO,EAEpC,OACMX,EAAIA,KACd,CACJ,EAEJnK,EAAa+K,wBAA0B,MACvC/K,EAAa6G,eAAiB,CAC1B,IAAI1G,EAAyB6K,uBAC7B,IAAIzK,EAA6B0K,2BACjC,IAAIxK,EAAwByK,sBAC5B,IAAIxK,EAA8ByK,4BAClC,IAAI3K,EAA2B4K,yBAC/B,IAAIzK,EAA0B0K,wBAC9B,IAAIzK,EAA0B0K,wBAC9B,IAAIxK,EAA2ByK,yBAC/B,IAAIrK,EAAgCsK,8BACpC,IAAIpL,EAAwBmF,sBAC5B,IAAI1E,EAAqC4K,mCACzC,IAAInL,EAAwBoL,sBAC5B,IAAIrL,EAA8BsL,6BAEtC3N,EAAQgC,aAAeA,C,qCCnevB9E,OAAO2D,eAAeb,EAAS,aAAc,CAAEhE,OAAO,IACtDgE,EAAQwD,oBAAiB,EACzB,MAAMvB,EAA0B,EAAQ,OAClC2L,EAAe,EAAQ,OACvBC,EAAgB,EAAQ,MACxBC,EAAiB,EAAQ,OAI/B,MAAMtK,EACF,WAAArC,CAAYiC,GAERtH,KAAKiS,cAAgB,IAAI9L,EAAwB+L,cAAc,CAAEC,eAAgB7K,EAAQ6K,eAAgBC,eAAgB9K,EAAQ+K,wBACjIrS,KAAK+I,mBAAqBzB,EAAQyB,iBAClC/I,KAAK4I,QAAUtB,EAAQsB,QACvB5I,KAAKsS,wBAA0BhL,EAAQgL,sBACvCtS,KAAKuS,mBAAqBjL,EAAQiL,iBAClCvS,KAAKwS,eAAiBlL,EAAQkL,gBAAkBR,EAAe9L,aAAa+K,wBAC5EjR,KAAKyS,eAAiBnL,EAAQmL,aAC9BzS,KAAKuN,uBAAyBjG,EAAQiG,qBACtCvN,KAAK0S,aAAepL,EAAQoL,aAC5B1S,KAAK2S,aAAerL,EAAQqL,aAC5B3S,KAAK4S,sBAAwBtL,EAAQsL,sBACrC5S,KAAK6S,yCAA2CvL,EAAQuL,yCACxD7S,KAAK8S,SAA8B,IAApBxL,EAAQwL,QACvB9S,KAAK+S,yBAA2BzL,EAAQyL,yBACxC/S,KAAKqP,oBAAqB,EAC1BrP,KAAKgT,qBAAuBC,WAAWjT,KAAKwS,gBAE5CxS,KAAKoN,gBAAkB,GACvBpN,KAAKyN,eAAiB,GACtBzN,KAAKiM,aAAe,GACpBjM,KAAKsL,QAAU,GACftL,KAAK0N,WAAa,GAClB1N,KAAK2N,wBAA0B,GAC/B3N,KAAK+K,iBAAmB,GACxB/K,KAAKmQ,YAAc,IAAI4B,EAAc3M,YACrCpF,KAAK6N,aAAe,GACpB7N,KAAKsM,gBAAkB,GACvBtM,KAAKwN,2BAA6B,GAClCxN,KAAK4N,iBAAmB,GACxB5N,KAAKmO,yBAA2B,GAChCnO,KAAKmP,yBAA2B,GAChCnP,KAAK8N,kBAAoB,GACzB9N,KAAK2L,6BAA+B,GACpC3L,KAAK4H,OAASN,EAAQM,OAClBN,EAAQzB,SACR7F,KAAKkT,YAAclT,KAAKmT,aAAa7L,EAAQzB,SAC7C7F,KAAKkT,YAAYtN,MAAMC,GAAY7F,KAAKoT,gBAAgBvN,MAGxD7F,KAAKkT,YAAc3K,QAAQC,QAAQ,IAAIrC,EAAwBkN,wBAAwBrT,KAAK4I,QAAU,CAAE,QAAS5I,KAAK4I,QAAS,mBAAmB,GAAS,CAAC,GAEpK,CAQA,kBAAMuK,CAAatN,EAASyN,EAAeC,GACvC,OAAOvT,KAAKiS,cAAcxI,MAAM5D,EAAS,CACrC+C,QAAS5I,KAAK4I,QACd2K,mBACAX,sBAAuB5S,KAAK4S,sBAC5BU,gBACAd,eAAgBxS,KAAKgT,sBAE7B,CAMA,eAAAI,CAAgBvN,GACZ,MAAM2N,EAAgB3N,EAAQ4N,gBAAgB,YAC9C,GAAID,EAAe,CACf,GAAIxT,KAAKgT,sBAAwBQ,EAAgBxT,KAAKgT,qBAClD,MAAM,IAAIlB,EAAa3I,WAAW,gCAAgCqK,mCAA+CxT,KAAKgT,wBAAyBlB,EAAa1I,YAAYsK,0BAGxK,GAAI1T,KAAKgT,sBAAwBQ,EAAgBxT,KAAKgT,qBAClD,MAAM,IAAIlB,EAAa3I,WAAW,2BAA2BqK,kCAA8CxT,KAAKgT,wBAAyBlB,EAAa1I,YAAYuK,uBAEtK3T,KAAKgT,qBAAuBQ,CAEpC,CACJ,CAOA,gBAAMjO,CAAWpE,EAAMH,EAAS,GAC5B,MAAM4S,EAAezS,EAErB,MAAwC,kBAA1BA,EAAKA,EAAKI,OAAS,GAC7BJ,EAAOA,EAAKyK,MAAM,EAAGzK,EAAKI,OAAS,GAGnCP,IACAG,EAAOA,EAAKyK,MAAM,GAAI5K,IAG1B,MAAM6S,QAAoB7T,KAAK8T,2BAA2B3S,GACpD0E,EAAUgO,EAAYhO,QAE5B,IAAIkO,EAAalO,EAAQ4N,gBACzB,IAAK,IAAIpS,EAAIwS,EAAY/N,MAAOzE,EAAIuS,EAAarS,OAASP,EAAQK,IAAK,CACnE,MAAMZ,EAAMmT,EAAavS,GACnB2S,EAAkBD,EAAWtT,GACnC,GAAIuT,GAA8C,kBAApBA,GAAgC,aAAcA,EAAiB,CACzF,MAAMC,SAAuBjU,KAAKmT,aAAaa,EAAiBD,GAAY,IAAON,gBAC7ES,IAAczT,KAAOwT,IACpBA,EAAcxT,GAAK,YAAY,eACpB,IAAdyT,GAAuB7S,IAAMuS,EAAarS,OAAS,EAAIP,IACvD+S,EAAa3S,OAAOuG,OAAO,CAAC,EAAGsM,UAExBF,EAAW,cAClBA,EAAWtT,GAAOW,OAAOuG,OAAO,CAAC,EAAGoM,EAAWtT,IAC3C,QAASuT,IACTD,EAAWtT,GAAK,OAASuT,EAAgB,eAEtCD,EAAWtT,GAAK,aACL,IAAdyT,GACAlU,KAAKmQ,YAAYpK,WAAW6N,EAAahI,MAAM,EAAGvK,EAAIL,GAASuH,QAAQC,QAAQ,IAAIrC,EAAwBkN,wBAAwBU,KAG/I,CACJ,CACA,OAAO,IAAI5N,EAAwBkN,wBAAwBU,EAC/D,CAaA,gCAAMD,CAA2B3S,GAC7B,MAAMgT,EAAgBhT,EAAKI,OAC3B,IACI6S,EADAP,EAAc,KAElB,EAAG,CACCO,GAAqC,EACjCP,GAAe,yBAA0BA,EAAYhO,QAAQ4N,gBAG7DI,EAAYhO,QAAU,IAAIM,EAAwBkN,wBAAwBQ,EAAYhO,QAAQ4N,gBAAgB,0BAG1GI,IAIA1S,EAAOA,EAAKyK,MAAM,EAAGiI,EAAY/N,MAAQ,IAE7C+N,QAAoB7T,KAAKmQ,YAAY5K,WAAWpE,IAAS,CAAE0E,cAAe7F,KAAKkT,YAAapN,MAAO,IAKvG,MAAMuO,EAAUlT,EAAKA,EAAKI,OAAS,GACnC,GAAI8S,KAAWR,EAAYhO,QAAQ4N,gBAAiB,CAChD,MAAMa,EAAeT,EAAYhO,QAAQ4N,gBAAgBY,GACrDC,GAAwC,kBAAjBA,GAA6B,aAAcA,IAClEF,GAAqC,EAE7C,CACJ,OAASP,EAAY/N,MAAQ,IACgC,IAAtD+N,EAAYhO,QAAQ4N,gBAAgB,eACpCI,EAAY/N,QAAUqO,IACrBC,GAQR,OAL0B,IAAtBP,EAAY/N,QAC6C,IAAtD+N,EAAYhO,QAAQ4N,gBAAgB,eACpCI,EAAY/N,QAAUqO,IACzBN,EAAYhO,QAAU,IAAIM,EAAwBkN,wBAAwB,CAAC,IAExEQ,CACX,CASA,mBAAMlJ,CAAcxJ,EAAMjB,EAAO4F,EAAO8E,SAC9B5K,KAAK4H,OAAO+C,cAAcxJ,EAAMjB,EAAO4F,EAAO8E,EACxD,CAKA,wCAAM2J,GACF,GAAIvU,KAAK2L,6BAA6BpK,OAAS,EAAG,CAC9C,IAAK,MAAMiT,KAAsBxU,KAAK2L,mCAC5B3L,KAAK4H,OAAOiE,YAAY2I,EAAmB1O,MAAO0O,EAAmBrT,MAC3EnB,KAAK4H,OAAOiD,YAAY2J,EAAmB1O,OAG/C,OADA9F,KAAK2L,6BAA6BH,OAAO,EAAGxL,KAAK2L,6BAA6BpK,SACvE,CACX,CAEI,OAAO,CAEf,CAMA,QAAA+N,CAASxJ,EAAOkF,GACE,IAAVlF,IACA9F,KAAKqP,oBAAqB,GAE9BrP,KAAK4H,OAAOrE,KAAKyH,EACrB,CAKA,SAAAuE,CAAUpM,GACNnD,KAAK4H,OAAOlE,KAAK,QAASP,EAC9B,CAKA,WAAAsR,CAAY5O,GACR7F,KAAK4H,OAAOlE,KAAK,UAAWmC,EAChC,CAOA,8BAAA6O,CAA+B5O,GAC3B,IAAIhE,EAAS9B,KAAKmO,yBAAyBrI,GAK3C,OAJKhE,IACDA,EAAS,GACT9B,KAAKmO,yBAAyBrI,GAAShE,GAEpCA,CACX,CAOA,8BAAAmN,CAA+BnJ,GAC3B,IAAIhE,EAAS9B,KAAKmP,yBAAyBrJ,GAK3C,OAJKhE,IACDA,EAAS,GACT9B,KAAKmP,yBAAyBrJ,GAAShE,GAEpCA,CACX,CAMA,wBAAA4N,CAAyB5J,GACrB,IAAIhE,EAAS9B,KAAK8N,kBAAkBhI,GAKpC,OAJKhE,IACDA,EAAS,GACT9B,KAAK8N,kBAAkBhI,GAAShE,GAE7BA,CACX,CAIA,gBAAA6S,GACI,OAAOjN,EAAekN,eAAe5U,KAAKgT,qBAC9C,CAUA,UAAA6B,CAAW/O,EAAOgP,GAEd,MAAMC,EAAgB/U,KAAKsL,QAAQxF,EAAQgP,GAO3C,GANIC,IACA/U,KAAKsL,QAAQxF,GAASiP,EACtB/U,KAAKiM,aAAanG,IAAS,SACpB9F,KAAKsL,QAAQxF,EAAQgP,IAG5B9U,KAAK2L,6BAA6BpK,OAClC,IAAK,MAAMO,KAAU9B,KAAK2L,6BAClB7J,EAAOgE,OAASA,EAAQgP,IACxBhT,EAAOgE,OAASgP,EAChBhT,EAAOX,KAAKqK,OAAO1F,EAAOgP,IAKlC9U,KAAKmO,yBAAyBrI,EAAQgP,KACtC9U,KAAKmO,yBAAyBrI,GAAS9F,KAAKmO,yBAAyBrI,EAAQgP,UACtE9U,KAAKmO,yBAAyBrI,EAAQgP,IAE7C9U,KAAK8N,kBAAkBhI,EAAQgP,EAAc,KACxC9U,KAAK8N,kBAAkBhI,EAAQ,KAChC9F,KAAK8N,kBAAkBhI,EAAQ,GAAK,IAExC9F,KAAK8N,kBAAkBhI,EAAQ,GAAK,IAC7B9F,KAAK8N,kBAAkBhI,EAAQ,MAC/B9F,KAAK8N,kBAAkBhI,EAAQgP,EAAc,WAE7C9U,KAAK8N,kBAAkBhI,EAAQgP,EAAc,GAG5D,EAEJpN,EAAekN,eAAiB,CAC5B,EAAK,CACDI,oBAAoB,EACpBC,yBAAyB,EACzBC,0BAA0B,GAE9B,IAAK,CACDF,oBAAoB,EACpBC,yBAAyB,EACzBC,0BAA0B,IAGlChR,EAAQwD,eAAiBA,C,qCCzVzBtG,OAAO2D,eAAeb,EAAS,aAAc,CAAEhE,OAAO,IACtDgE,EAAQ4D,UAAO,EACf,MAAM3B,EAA0B,EAAQ,OAClCgP,EAAqB,EAAQ,OAC7B7O,EAA0B,EAAQ,OAElC8O,EAAmB,EAAQ,OAIjC,MAAMtN,EACF,WAAAzC,CAAYiC,GACRtH,KAAKyH,eAAiBH,EAAQG,eAC9BzH,KAAK+H,YAAcT,EAAQS,aAAe,IAAIoN,EAAmBE,YACjErV,KAAKsV,SAAWtV,KAAK+H,YAAYwN,UAAUzN,EAAK0N,IAAM,SACtDxV,KAAKiL,QAAUjL,KAAK+H,YAAYwN,UAAUzN,EAAK0N,IAAM,QACrDxV,KAAKkL,OAASlL,KAAK+H,YAAYwN,UAAUzN,EAAK0N,IAAM,OACpDxV,KAAKyV,QAAUzV,KAAK+H,YAAYwN,UAAUzN,EAAK0N,IAAM,QACrDxV,KAAK0V,QAAU1V,KAAK+H,YAAYwN,UAAUzN,EAAK0N,IAAM,OACzD,CAYA,sBAAOG,CAAgB9P,EAAS+P,EAAYnV,EAAKoV,GAC7C,MAAMC,EAAQjQ,EAAQ4N,gBAAgBhT,GACtC,IAAKqV,EACD,OAAOD,EAEX,MAAME,EAAOD,EAAMF,GACnB,YAAgBzV,IAAT4V,EAAqBF,EAAWE,CAC3C,CAYA,+BAAOC,CAAyBnQ,EAASpF,GACrC,OAAOqH,EAAK6N,gBAAgB9P,EAAS,aAAcpF,EAAK,CAAE,QAAQ,GACtE,CAOA,0BAAOwV,CAAoBpQ,EAASpF,GAChC,MAAMyV,EAAYpO,EAAK6N,gBAAgB9P,EAAS,QAASpF,EAAK,MAC9D,MAAkB,UAAdyV,EACO,KAEJA,CACX,CAOA,8BAAOC,CAAwBtQ,EAASpF,GACpC,OAAOqH,EAAK6N,gBAAgB9P,EAAS,YAAapF,EAAKoF,EAAQ4N,gBAAgB,cAAgB,KACnG,CAOA,+BAAO2C,CAAyBvQ,EAASpF,GACrC,OAAOqH,EAAK6N,gBAAgB9P,EAAS,aAAcpF,EAAKoF,EAAQ4N,gBAAgB,eAAiB,KACrG,CAOA,4BAAO4C,CAAsBxQ,EAASpF,GAClC,QAASqH,EAAK6N,gBAAgB9P,EAAS,WAAYpF,EAAK,KAC5D,CAOA,2BAAO6V,CAAqBzQ,EAASpF,GACjC,OAAOqH,EAAK6N,gBAAgB9P,EAAS,SAAUpF,EAAKoF,EAAQ4N,gBAAgB,WAAa,KAC7F,CAQA,wBAAO8C,CAAkB1Q,EAASpF,EAAKsL,GAEnC,MAAqB,aAAdA,IAA6BjE,EAAKuO,sBAAsBxQ,EAASpF,EAC5E,CAMA,+BAAO+V,CAAyBzK,GAC5B,MAAqB,QAAdA,CACX,CAMA,mCAAO0K,CAA6B1K,GAChC,MAAqB,gBAAdA,CACX,CAMA,iBAAO2K,CAAWC,GACd,OAAe,OAARA,GAAgBxQ,EAAwB2B,KAAK4O,WAAWC,EACnE,CAMA,oBAAOjG,CAAckG,EAAQC,GACzB,GAAID,EAAOrV,OAASsV,EAAStV,OACzB,OAAO,EAEX,IAAK,IAAIF,EAAI,EAAGA,EAAIuV,EAAOrV,OAAQF,IAC/B,GAAIuV,EAAOvV,KAAOwV,EAASxV,GACvB,OAAO,EAGf,OAAO,CACX,CAOA,0BAAMkM,CAAqBrN,GACvB,GAAIF,KAAKyH,eAAe8F,qBAAsB,CAC1C,MAAMuJ,EAAc,CAAC,EACrB,IAAK,MAAMhB,KAAS5V,EAChB,GAAI4V,GAA0B,kBAAVA,EAAoB,CACpC,MAAMiB,EAAKjB,EAAM,OACXkB,EAAQlB,EAAM,UACpB,GAAIiB,GAAMC,EAAO,CACb,MAAMC,EAAqBH,EAAYC,GACvC,GAAIE,GAAsBA,IAAuBD,EAC7C,MAAM,IAAI7Q,EAAwBgD,WAAW,gCAAgC4N,IAAM5Q,EAAwBiD,YAAY8N,qBAE3HJ,EAAYC,GAAMC,CACtB,CACJ,CAER,CACJ,CAUA,iBAAMG,CAAYtR,EAASpF,EAAKP,EAAO4F,EAAO3E,GAE1C,GAA+C,UAA3C2G,EAAKmO,oBAAoBpQ,EAASpF,GAClC,MAAO,CAACT,KAAK+H,YAAYqP,QAAQpX,KAAKqX,kBAAkBnX,GAAQF,KAAK0V,UAEzE,MAAMK,SAAc7V,EACpB,OAAQ6V,GACJ,IAAK,SAED,GAAc,OAAV7V,QAA4BC,IAAVD,EAClB,MAAO,GAGX,GAAImN,MAAMC,QAAQpN,GAGd,MAAI,UAAW4H,EAAKkO,yBAAyBnQ,EAASpF,GAC7B,IAAjBP,EAAMqB,OACC,CAACvB,KAAKkL,QAGNlL,KAAKyH,eAAe6D,QAAQxF,EAAQ,IAAM,UAGnD9F,KAAKuN,qBAAqBrN,GACzB,IAUX,GAPA2F,QAAgB7F,KAAKsX,+BAA+BzR,EAASpF,GAEzD,aAAcP,IACd2F,QAAgB7F,KAAKyH,eAAe0L,aAAajT,EAAM,mBAAoBF,KAAKyH,eAAelC,WAAWpE,EAAM,IAAIsS,kBAGxHvT,QAAcF,KAAKuX,gBAAgBrX,EAAOiB,EAAM2E,EAAOD,GACnD,WAAY3F,EAAO,CACnB,IAAIsX,EACAC,EACAC,EACAxB,EACAyB,EACJ,IAAKlX,KAAOP,EAAO,CACf,MAAM0X,EAAW1X,EAAMO,GACvB,OAAQA,GACJ,IAAK,SACD+W,EAAMI,EACN,MACJ,IAAK,YACDH,EAAgBG,EAChB,MACJ,IAAK,aACDF,EAAiBE,EACjB,MACJ,IAAK,QACD1B,EAAY0B,EACZ,MACJ,IAAK,SACDD,EAAaC,EACb,MACJ,IAAK,cAED,MACJ,QACI,MAAM,IAAIzR,EAAwBgD,WAAW,wBAAwB1I,iBAAmBuB,KAAKC,UAAU/B,KAAUiG,EAAwBiD,YAAYyO,sBAEjK,CAEA,GAAyE,gBAA/D7X,KAAK8L,eAAeoK,EAAW/U,EAAM2E,GAAO,EAAMD,GACxD,MAAO,CAAC7F,KAAK+H,YAAYqP,QAAQpX,KAAKqX,kBAAkBG,GAAMxX,KAAK0V,UAGvE,GAAY,OAAR8B,EACA,MAAO,GAEX,GAAmB,kBAARA,EACP,MAAM,IAAIrR,EAAwBgD,WAAW,uDAAuDnH,KAAKC,UAAUuV,MAASrR,EAAwBiD,YAAY0O,4BAGpK,GAAI9X,KAAKyH,eAAe8F,sBAAwBoK,GAAoC,kBAAfA,EACjE,MAAM,IAAIxR,EAAwBgD,WAAW,mDAAmDnH,KAAKC,UAAU0V,MAAgBxR,EAAwBiD,YAAY2O,qBAGvK,GAAIN,EAAe,CACf,GAAmB,kBAARD,EACP,MAAM,IAAIrR,EAAwBgD,WAAW,4EAA4EnH,KAAKC,UAAUuV,MAASrR,EAAwBiD,YAAY4O,+BAEzL,IAAK7R,EAAwB+L,cAAc+F,iBAAiBR,EAAezX,KAAKyH,eAAegL,aAActM,EAAwBiD,YAAY8O,gCAC7I,MAAO,IAGPlY,KAAKyH,eAAemL,uBAAsE,IAA7C5S,KAAKyH,eAAeuL,wBACjEyE,EAAgBA,EAAcU,cAEtC,CACA,GAAIT,EAAgB,CAChB,GAAmB,kBAARF,EACP,MAAM,IAAIzV,MAAM,6EAA6EC,KAAKC,UAAUuV,OAEhH,IAAKrR,EAAwB+L,cAAckG,kBAAkBV,EAAgB1X,KAAKyH,eAAegL,cAC7F,MAAO,EAEf,CAEA,GAAIgF,GAAiBC,GAAkB1X,KAAKyH,eAAekL,aAAc,CACrE,GAAIuD,EACA,MAAM,IAAI/P,EAAwBgD,WAAW,mEAAmEnH,KAC3GC,UAAU/B,MAAWiG,EAAwBiD,YAAYyO,sBAElE,OAAO7X,KAAKqY,oBAAoBrY,KAC3BsY,+BAA+BxS,EAAO0R,EAAKC,EAAeC,GACnE,CACK,GAAID,EAAe,CACpB,GAAIvB,EACA,MAAM,IAAI/P,EAAwBgD,WAAW,0DAA0DnH,KAAKC,UAAU/B,MAAWiG,EAAwBiD,YAAYyO,sBAEzK,MAAO,CAAC7X,KAAK+H,YAAYqP,QAAQI,EAAKC,GAC1C,CACK,GAAIC,GAAkB1X,KAAKyH,eAAekL,aAAc,CACzD,GAAIuD,EACA,MAAM,IAAI/P,EAAwBgD,WAAW,2DAA2DnH,KAAKC,UAAU/B,MAAWiG,EAAwBiD,YAAYyO,sBAE1K,OAAO7X,KAAKqY,oBAAoBrY,KAC3BsY,+BAA+BxS,EAAO0R,EAAKC,EAAeC,GACnE,CACK,GAAIxB,EAAW,CAChB,GAAyB,kBAAdA,EACP,MAAM,IAAI/P,EAAwBgD,WAAW,kDAAkDnH,KAAKC,UAAUiU,MAAe/P,EAAwBiD,YAAYmP,qBAErK,MAAMC,EAAWxY,KAAKyY,sBAAsB5S,EAASqQ,GACrD,IAAKsC,EACD,MAAM,IAAIrS,EAAwBgD,WAAW,+BAA+BnH,KAAKC,UAAUiU,MAAe/P,EAAwBiD,YAAYmP,qBAElJ,GAA0B,cAAtBC,EAASpJ,SACT,MAAM,IAAIjJ,EAAwBgD,WAAW,uBAAuBqP,EAASpJ,cAAc8G,IAAa/P,EAAwBiD,YAAYmP,qBAEhJ,MAAO,CAACvY,KAAK+H,YAAYqP,QAAQI,EAAKgB,GAC1C,CAEA,aAAaxY,KAAKmX,YAAY,IAAIhR,EAAwBkN,wBAAwB,CAAC,GAAI5S,EAAK+W,EAAK1R,EAAO3E,EAC5G,CACK,GAAI,SAAUjB,EAAO,CAEtB,GAAIkB,OAAOD,KAAKjB,GAAOqB,OAAS,EAC5B,MAAM,IAAI4E,EAAwBgD,WAAW,6DAA6D1I,KAAQ0F,EAAwBiD,YAAYsP,4BAG1J,MAAO,EACX,CACK,GAAI,UAAWxY,EAAO,CAEvB,GAAIkB,OAAOD,KAAKjB,GAAOqB,OAAS,EAC5B,MAAM,IAAI4E,EAAwBgD,WAAW,8DAA8D1I,KAAQ0F,EAAwBiD,YAAYsP,4BAE3J,MAAMC,EAAYzY,EAAM,SAGxB,OAAImN,MAAMC,QAAQqL,GACW,IAArBA,EAAUpX,OACH,CAACvB,KAAKkL,QAGNlL,KAAKyH,eAAe6D,QAAQxF,EAAQ,IAAM,SAKxC9F,KAAKmX,kBAAkBnX,KAAKyH,eAAelC,WAAWpE,GAAOV,EAAKkY,EAAW7S,EAAQ,EAAG3E,EAAKyK,MAAM,GAAI,GAE5H,CACK,GAAI,aAAc1L,GAAsC,mBAAtBA,EAAM,YAGzC,MAAO,GAEN,GAAI,WAAY4H,EAAKkO,+BAA+BhW,KAAKyH,eAAelC,WAAWpE,GAAOV,GAAM,CAEjG,MAAMmY,EAAwB5Y,KAAKyH,eAAekG,wBAAwB7H,EAAQ,GAClF,OAAO8S,EAAwBxX,OAAOyX,OAAOD,GAAyB,CAAC5Y,KAAK+H,YAAYkG,YAC5F,CACK,GAAI,QAAS/N,EAAO,CASrB,GAPIkB,OAAOD,KAAKjB,GAAOqB,OAAS,IAC5BsE,QAAgB7F,KAAKyH,eAAelC,WAAWpE,EAAM,IAGrD,aAAcjB,IACd2F,QAAgB7F,KAAKyH,eAAe0L,aAAajT,EAAM,YAAa2F,EAAQ4N,kBAEzD,WAAnBvT,EAAM,SACN,OAAOF,KAAKqY,oBAAoBrY,KAAKyY,sBAAsB5S,EAAS3F,EAAM,SAEzE,CACD,MAAM4Y,EAAU5Y,EAAM,OACtB,IAAI6Y,EACJ,GAAuB,kBAAZD,EAAsB,CAC7B,IAAI9Y,KAAKyH,eAAeqL,QAIpB,MAAM,IAAI3M,EAAwBgD,WAAW,sBAAsBjJ,KAAUiG,EAAwBiD,YAAY4P,kBAHjHD,EAAY/Y,KAAKyH,eAAe6D,QAAQxF,EAAQ,GAAG,EAK3D,MAEIiT,EAAY/Y,KAAKiZ,eAAepT,EAASiT,GAE7C,OAAO9Y,KAAKqY,oBAAoBU,EACpC,CACJ,CAGI,OAAI/Y,KAAKyH,eAAewE,aAAanG,EAAQ,IACrC5F,GAA0B,kBAAVA,GAAoD,IAA9BkB,OAAOD,KAAKjB,GAAOqB,OACrDvB,KAAKyH,eAAe6D,QAAQxF,EAAQ,KACpC9F,KAAKyH,eAAe6D,QAAQxF,EAAQ,GAAK,CAAC9F,KAAK+H,YAAYkG,cAG5D,GAGnB,IAAK,SACD,OAAOjO,KAAKqY,oBAAoBrY,KAAKkZ,kBAAkBpT,QAAa9F,KAAKsX,+BAA+BzR,EAASpF,GAAMA,EAAKP,EAAO,OACvI,IAAK,UACD,OAAOF,KAAKqY,oBAAoBrY,KAAKkZ,kBAAkBpT,QAAa9F,KAAKsX,+BAA+BzR,EAASpF,GAAMA,EAAK0Y,QAAQjZ,GAAOsB,WAAYxB,KAAK+H,YAAYwN,UAAUzN,EAAKsR,eAC3L,IAAK,SACD,OAAOpZ,KAAKqY,oBAAoBrY,KAAKkZ,kBAAkBpT,QAAa9F,KAAKsX,+BAA+BzR,EAASpF,GAAMA,EAAKP,EAAOF,KAAK+H,YAAYwN,UAAUrV,EAAQ,IAAM,GAAKA,EAAQ,KAAO4H,EAAKuR,YAAcvR,EAAKwR,cAC5N,QAEI,OADAtZ,KAAKyH,eAAe8H,UAAU,IAAIxN,MAAM,yCAAyCgU,MAC1E,GAEnB,CAUA,oCAAMuB,CAA+BzR,EAASpF,GAC1C,MAAMuT,EAAkBnO,EAAQ4N,gBAAgBhT,GAIhD,OAHIuT,GAA8C,kBAApBA,GAAgC,aAAcA,IACxEnO,QAAgB7F,KAAKyH,eAAe0L,aAAaa,EAAiBnO,EAAQ4N,iBAAiB,IAExF5N,CACX,CAKA,mBAAAwS,CAAoBkB,GAChB,OAAOA,EAAO,CAACA,GAAQ,EAC3B,CAQA,eAAAC,CAAgB3T,EAASpF,GACrB,MAAMgZ,EAAW5T,EAAQ6T,WAAWjZ,GAAK,EAAMT,KAAKyH,eAAekN,oBAEnE,OAAK8E,EAIe,MAAhBA,EAAS,IAA8B,MAAhBA,EAAS,GAC5BzZ,KAAKyH,eAAe6K,sBACbtS,KAAK+H,YAAYkG,UAAUwL,EAASE,OAAO,IAG3C,KAIX7R,EAAK4O,WAAW+C,GACTzZ,KAAK+H,YAAYwN,UAAUkE,GAG9BA,GAAYzZ,KAAKyH,eAAegL,cAChCzS,KAAKyH,eAAe8H,UAAU,IAAIpJ,EAAwBgD,WAAW,0BAA0BsQ,IAAYtT,EAAwBiD,YAAYwQ,sBAMhJ,MAHQ,KApBJ,IAwBf,CAQA,cAAAX,CAAepT,EAASpF,GACpB,GAAIA,EAAIoZ,WAAW,MACf,OAAO7Z,KAAK+H,YAAYkG,UAAUxN,EAAIkZ,OAAO,IAEjD,MAAMhD,EAAM9Q,EAAQ6T,WAAWjZ,GAAK,EAAOT,KAAKyH,eAAekN,oBAC/D,IAAK7M,EAAK4O,WAAWC,GAAM,CACvB,IAAIA,IAAO3W,KAAKyH,eAAegL,aAI3B,OAAO,KAHPzS,KAAKyH,eAAe8H,UAAU,IAAIxN,MAAM,yBAAyB4U,KAKzE,CACA,OAAO3W,KAAK+H,YAAYwN,UAAUoB,EACtC,CASA,qBAAA8B,CAAsB5S,EAASpF,GAC3B,GAAIA,EAAIoZ,WAAW,MACf,OAAO7Z,KAAK+H,YAAYkG,UAAUxN,EAAIkZ,OAAO,IAEjD,MAAMG,EAAgB9Z,KAAKyH,eAAekN,mBAC1C,IAAI8E,EAAW5T,EAAQ6T,WAAWjZ,GAAK,EAAMqZ,GAI7C,GAHIL,IAAahZ,IACbgZ,EAAW5T,EAAQ6T,WAAWjZ,GAAK,EAAOqZ,KAEzChS,EAAK4O,WAAW+C,GAAW,CAC5B,IAAIA,IAAYzZ,KAAKyH,eAAegL,cAAiBgH,EAASI,WAAW,KAIrE,OAAO,KAHP7Z,KAAKyH,eAAe8H,UAAU,IAAIxN,MAAM,qBAAqB0X,KAKrE,CACA,OAAOzZ,KAAK+H,YAAYwN,UAAUkE,EACtC,CAOA,WAAAM,CAAY7Z,EAAO8Z,GACf,GAAqB,kBAAV9Z,EAAoB,CAC3B,GAAI4D,OAAOmW,SAAS/Z,GAAQ,CACxB,MAAMga,EAAYha,EAAQ,IAAM,EAChC,OAAIga,GAAeF,GAAYA,EAAS9Z,QAAU4H,EAAKwR,WAI5CpZ,EAAMia,cAAc,IAAIC,QAAQ,aAAc,OAH9CtW,OAAO5D,GAAOsB,UAK7B,CAEI,OAAOtB,EAAQ,EAAI,MAAQ,MAEnC,CAEI,OAAOA,CAEf,CAUA,iBAAAgZ,CAAkBpT,EAAOD,EAASpF,EAAKP,EAAOma,GAE1C,MAAMC,EAAcxS,EAAKmO,oBAAoBpQ,EAASpF,GACtD,GAAI6Z,EACA,GAAoB,QAAhBA,GACA,IAAKD,EACD,OAAOra,KAAKiZ,eAAepT,EAAS7F,KAAK+Z,YAAY7Z,EAAOma,SAG/D,GAAoB,WAAhBC,GACL,IAAKD,EACD,OAAOra,KAAKyY,sBAAsB5S,EAAS7F,KAAK+Z,YAAY7Z,EAAOma,SAIvEA,EAAkBra,KAAK+H,YAAYwN,UAAU+E,GAIrD,IAAKD,EAAiB,CAClB,MAAME,EAAkBzS,EAAKqO,wBAAwBtQ,EAASpF,GACxD+Z,EAAmB1S,EAAKsO,yBAAyBvQ,EAASpF,GAChE,OAAI+Z,GAAoBxa,KAAKyH,eAAekL,aACjC3S,KAAKsY,+BAA+BxS,EAAO9F,KAAK+Z,YAAY7Z,EAAOma,GAAkBE,EAAiBC,GAGtGxa,KAAK+H,YAAYqP,QAAQpX,KAAK+Z,YAAY7Z,EAAOma,GAAkBE,EAElF,CAEA,OAAOva,KAAK+H,YAAYqP,QAAQpX,KAAK+Z,YAAY7Z,EAAOma,GAAkBA,EAC9E,CAUA,8BAAA/B,CAA+BxS,EAAO5F,EAAOua,EAAUC,GACnD,GAAyC,kBAArC1a,KAAKyH,eAAekL,aAKpB,OAHK8H,IACDA,EAAW,IAERza,KAAK+H,YAAYqP,QAAQlX,EAAOF,KAAK+H,YAAYwN,UAAU,8BAA8BkF,KAAYC,MAE3G,CAED,MAAMC,EAAY3a,KAAK+H,YAAYkG,YAC7BQ,EAAQzO,KAAKmL,kBAMnB,OALAnL,KAAKyH,eAAe6H,SAASxJ,EAAO9F,KAAK+H,YAAYiD,KAAK2P,EAAW3a,KAAK+H,YAAYwN,UAAUzN,EAAK0N,IAAM,SAAUxV,KAAK+H,YAAYqP,QAAQlX,GAAQuO,IAClJgM,GACAza,KAAKyH,eAAe6H,SAASxJ,EAAO9F,KAAK+H,YAAYiD,KAAK2P,EAAW3a,KAAK+H,YAAYwN,UAAUzN,EAAK0N,IAAM,YAAaxV,KAAK+H,YAAYqP,QAAQqD,GAAWhM,IAEhKzO,KAAKyH,eAAe6H,SAASxJ,EAAO9F,KAAK+H,YAAYiD,KAAK2P,EAAW3a,KAAK+H,YAAYwN,UAAUzN,EAAK0N,IAAM,aAAcxV,KAAK+H,YAAYqP,QAAQsD,GAAYjM,IACvJkM,CACX,CACJ,CAMA,iBAAAtD,CAAkBnX,GACd,OAAOkV,EAAiBlV,EAC5B,CAYA,oBAAM4L,CAAerL,EAAKU,EAAM2E,EAAO8U,EAAc/U,GAEjD,GAAI/B,OAAOoW,UAAUzZ,GACjB,OAAOA,EAGX,IAAKma,EAAc,CACf,MAAMC,EAAyB7a,KAAKyH,eAAe+F,2BAA2B1H,GAC9E,GAAI+U,EACA,OAAOA,CAEf,CACA,IAAK1U,EAAwB2B,KAAKgT,mBAAmBra,GAAM,CACvDoF,EAAUA,SAAiB7F,KAAKyH,eAAelC,WAAWpE,GAC1D,IAAI4Z,EAAWlV,EAAQ4N,gBAAgBhT,GACnCsa,GAAgC,kBAAbA,IACnBA,EAAWA,EAAS,QAEpB5U,EAAwB2B,KAAKqE,eAAe4O,KAC5Cta,EAAMsa,EAEd,CACA,OAAOH,EAAena,EAAOT,KAAKyH,eAAe+F,2BAA2B1H,GAASrF,CACzF,CAQA,0BAAMuL,CAAqB7K,EAAM2E,GAC7B,aAAa9F,KAAK8L,eAAehG,EAAQ,GAAK3E,EAAK2E,EAAQ,GAAI3E,EAAM2E,EAAQ,EACjF,CAUA,qBAAMyR,CAAgByD,EAAM7Z,EAAM2E,EAAOD,GACrC,MAAMoV,EAAU,CAAC,EACjB,IAAK,MAAMxa,KAAOua,EACdC,QAAcjb,KAAK8L,eAAerL,EAAKU,EAAM2E,EAAQ,GAAG,EAAMD,IAAYmV,EAAKva,GAEnF,OAAOwa,CACX,CAUA,eAAMpO,CAAU1L,EAAM2E,GAClB,IAAK,IAAIzE,EAAIyE,EAAOzE,GAAK,EAAGA,IAAK,CAC7B,GAAoD,sBAA1CrB,KAAK8L,eAAe3K,EAAKE,GAAIF,EAAME,GAEzC,OAAO,EAEX,GAAIrB,KAAKyH,eAAeoG,aAAaxM,IAAMrB,KAAKyH,eAAemG,iBAAiBvM,GAC5E,OAAO,CAEf,CACA,OAAO,CACX,CAQA,yBAAMiN,CAAoBxI,EAAO3E,GAC7B,IAAK,IAAIE,EAAIyE,EAAQ,EAAGzE,EAAI,EAAGA,IAC3B,GAAoD,iBAA1CrB,KAAK8L,eAAe3K,EAAKE,GAAIF,EAAME,GAAiB,CAE1D,MAAM6Z,SAAoB5U,EAAwBmF,sBAAsB0P,oBAAoBnb,KAAKyH,eAAgBtG,EAAME,IAAI6Z,WAC3H,OAAI5U,EAAwBmF,sBAAsB2P,wBAAwBF,IAC9D,EAELpV,EAAQzE,EAAI,CACvB,CAEJ,OAAQ,CACZ,CAMA,sBAAAga,CAAuBjN,GACnB,GAAyB,YAArBA,EAAQgB,SACR,MAAM,IAAIjJ,EAAwBgD,WAAW,8CAA8CiF,EAAQlO,QAASiG,EAAwBiD,YAAYkS,+BAExJ,CAKA,eAAAnQ,GACI,OAAOnL,KAAKyH,eAAeiL,cAAgB1S,KAAK+H,YAAY2K,cAChE,CAOA,4BAAMlE,CAAuBrN,EAAM2E,GAE/B,IAAI2I,EAAQzO,KAAKmL,kBAEjB,MAAM,WAAE+P,EAAYpV,MAAOyV,SAAyBjV,EAAwBmF,sBACvE0P,oBAAoBnb,KAAKyH,eAAgBtG,EAAM2E,GACpD,GAAI,WAAYoV,EAAY,CAExB,MAAMM,EAAsBlV,EAAwBmF,sBAAsBgQ,uBAAuBP,EAAYK,EAAgBpa,GACvH2U,EAAQ9V,KAAKyH,eAAekG,wBAAwB4N,GAG1D,GAFA9M,EAAQqH,EAAQA,EAAM0F,GAAuB,MAExC/M,EAAO,CACR,IAAIiN,EAAU,KACd,GAAI,QAASR,EAAY,CACrB,MAAMS,QAAqB3b,KAAK4b,gBAAgBza,EAAKoa,GAAiBpa,EAAMoa,GACvD,OAAjBI,IACAD,QAAgB1b,KAAKiZ,qBAAqBjZ,KAAKyH,eAAelC,WAAWpE,GAAOwa,GAExF,CACKD,IACDA,EAAU1b,KAAK+H,YAAYkG,aAE1BjO,KAAKyH,eAAekG,wBAAwB4N,KAC7Cvb,KAAKyH,eAAekG,wBAAwB4N,GAAkB,CAAC,GAEnE9M,EAAQzO,KAAKyH,eAAekG,wBAAwB4N,GAAgBC,GAAuBE,CAC/F,CACJ,CACA,OAAOjN,CACX,CAeA,wBAAMoN,CAAmB1a,EAAM2E,GAC3B,IAAIgW,EAAiBhW,EACrB,IAAK,IAAIzE,EAAIyE,EAAQ,EAAGzE,EAAI,EAAGA,IAC3B,GAAuB,kBAAZF,EAAKE,GAAiB,CAC7B,MAAM0K,QAAkB/L,KAAK8L,eAAe3K,EAAKE,GAAIF,EAAME,GAC3D,GAAkB,aAAd0K,EACA,OAAO1K,EAEN,GAAkB,UAAd0K,EAIL,OAAO+P,EAHPA,EAAiBza,CAKzB,CAEJ,OAAOya,CACX,CASA,qBAAMF,CAAgBnb,EAAKU,EAAM2E,GAC7B,MAAM6V,QAAqB3b,KAAK8L,eAAerL,EAAKU,EAAM2E,GAC1D,MAAwB,UAAjB6V,EAA2B,KAAOA,CAC7C,CAOA,6BAAAI,CAA8Btb,EAAKqO,EAASC,GACxC,GAAIA,GAAcD,IAAY9O,KAAKyH,eAAesL,yBAC9C,MAAM,IAAI5M,EAAwBgD,WAAW,gDAAgD1I,IAAO0F,EAAwBiD,YAAY4S,sBAEhJ,CAWA,eAAArN,CAAgB7I,EAAOsI,EAASQ,EAAWC,EAAQJ,EAAOK,EAASC,GAE/D,IAAI/D,EASJ,GARI8D,GACA9O,KAAKqb,uBAAuBxM,GAC5B7D,EAAOhL,KAAK+H,YAAYiD,KAAK6D,EAAQD,EAAWR,EAASK,IAGzDzD,EAAOhL,KAAK+H,YAAYiD,KAAKoD,EAASQ,EAAWC,EAAQJ,GAGzDM,EAAY,CAMZ,GAJ4B,iBAAxB/D,EAAKyD,MAAMW,WACXpE,EAAOhL,KAAK+H,YAAYiD,KAAKA,EAAKoD,QAASpD,EAAK4D,UAAW5D,EAAK6D,SAGhE7O,KAAKyH,eAAe6D,QAAQxF,EAAQ,GACpC,MAAM,IAAIK,EAAwBgD,WAAW,kDAAmDhD,EAAwBiD,YAAY4S,uBAExIhc,KAAKyH,eAAe6D,QAAQxF,EAAQ,GAAK,CAACkF,EAC9C,MAEIhL,KAAKyH,eAAe6H,SAASxJ,EAAOkF,GAGxC,MAAM8C,EAAoB9N,KAAKyH,eAAeqG,kBAAkBhI,GAChE,GAAIgI,EAAmB,CACnB,IAAK,MAAM6B,KAAc7B,EACrB9N,KAAKic,eAAenW,EAAOkF,EAAM2E,UAE9B3P,KAAKyH,eAAeqG,kBAAkBhI,EACjD,CACJ,CAEA,cAAAmW,CAAenW,EAAOkF,EAAM2E,GAExB,IAAIuM,EACAvM,EAAWb,SACX9O,KAAKqb,uBAAuB1L,EAAWd,QACvCqN,EAAiBlc,KAAK+H,YAAYiD,KAAK2E,EAAWd,OAAQc,EAAWf,UAAW5D,IAGhFkR,EAAiBlc,KAAK+H,YAAYiD,KAAKA,EAAM2E,EAAWf,UAAWe,EAAWd,QAGlF7O,KAAKyH,eAAe6H,SAASxJ,EAAOoW,GAEpC,IAAK,MAAMC,KAAoBxM,EAAWyM,kBACtCpc,KAAKic,eAAenW,EAAOoW,EAAgBC,EAEnD,EAEJrU,EAAKuU,IAAM,oCACXvU,EAAKsR,YAActR,EAAKuU,IAAM,UAC9BvU,EAAKuR,YAAcvR,EAAKuU,IAAM,UAC9BvU,EAAKwR,WAAaxR,EAAKuU,IAAM,SAC7BvU,EAAK0N,IAAM,8CACXtR,EAAQ4D,KAAOA,C,mCC14Bf1G,OAAO2D,eAAeb,EAAS,aAAc,CAAEhE,OAAO,IACtDgE,EAAQoY,gCAA6B,EAOrC,MAAMA,EACF,mBAAAC,GACI,OAAO,CACX,CACA,YAAMrP,CAAOgO,EAAYzT,EAAgBI,EAAM1G,EAAMjB,EAAO4F,GACxD,IAAIiR,EAEJ,GAAItP,EAAewE,aAAanG,EAAQ,IAAM2B,EAAe6D,QAAQxF,EAAQ,GAEzEiR,EAAKtP,EAAe6D,QAAQxF,EAAQ,GAAG,OAEtC,CAED,MAAM6V,QAAqB9T,EAAK+T,gBAAgBza,EAAK2E,GAAQ3E,EAAM2E,GAC7D0W,EAA2B,OAAjBb,QACJ9T,EAAKoR,qBAAqBxR,EAAelC,WAAWpE,GAAOA,EAAK2E,IACtE+B,EAAKE,YAAYkG,YAEvB,IAAKuO,EAED,YADA/U,EAAewE,aAAanG,IAAS,GAGzCiR,EAAKyF,EAEL/U,EAAe6D,QAAQxF,EAAQ,GAAK,CAACiR,EACzC,CAGA,IAAI0F,EAAMhV,EAAe6D,QAAQxF,GAC5B2W,IACDA,EAAMhV,EAAe6D,QAAQxF,GAAS,IAGrC2W,EAAIC,MAAMnD,GAASA,EAAKoD,OAAO5F,MAChC0F,EAAIlZ,KAAKwT,SAGFtP,EAAe8M,uCACtB9M,EAAewE,aAAanG,IAAS,EAE7C,EAEJ5B,EAAQoY,2BAA6BA,C,oCClDrClb,OAAO2D,eAAeb,EAAS,aAAc,CAAEhE,OAAO,IACtDgE,EAAQ0Y,2BAAwB,EAChC,MAAMzW,EAA0B,EAAQ,OAClCK,EAA0B,EAAQ,OAClCU,EAAS,EAAQ,OAMvB,MAAM0V,EACF,mBAAAL,GACI,OAAO,CACX,CACA,YAAMrP,CAAOgO,EAAYzT,EAAgBI,EAAM1G,EAAMjB,EAAO4F,GACxD,IAAKuH,MAAMC,QAAQpN,GAAQ,CACvB,MAAM2c,EAAiB,WAAY3B,EAE7BrV,QAAgB4B,EAAelC,WAAWpE,GAC1C2b,EAAW3b,EAAK2E,EAAQ,GACxBiX,EAAmB7V,EAAOY,KAAKwO,qBAAqBzQ,EAASiX,GACnE,GAAIC,EAAkB,CAElB,GAAI5W,EAAwB2B,KAAKgT,mBAAmBiC,GAChD,MAAM,IAAI5W,EAAwBgD,WAAW,kDAAkD4T,IAAoB5W,EAAwBiD,YAAY4T,yBAE3J,GAAgC,kBAArBD,EACP,MAAM,IAAI5W,EAAwBgD,WAAW,uCAAuC4T,IAAoB5W,EAAwBiD,YAAY4T,yBAGhJ,GAAqB,kBAAV9c,EAAoB,CAE3B,GAA2D,QAAvDgH,EAAOY,KAAKmO,oBAAoBpQ,EAASiX,GACzC,MAAM,IAAI3W,EAAwBgD,WAAW,gGAAgGjJ,IAASiG,EAAwBiD,YAAYyO,sBAG9L,MAAMd,EAAKlP,EAAKoR,eAAepT,EAAS3F,GACpC6W,IACAtP,EAAe6D,QAAQxF,EAAQ,GAAK,CAACiR,GAE7C,CAEA,MAAMkG,EAAgBpV,EAAK4Q,sBAAsB5S,EAASkX,GAC1D,GAAIE,EAAe,CACf,MAAMC,QAAoBrV,EAAKsP,YAAYtR,EAASkX,QAAwBlV,EAAK+T,gBAAgBza,EAAK2E,GAAQ3E,EAAM2E,GAAQA,EAAO3E,GACnI,GAAI0b,EAAgB,CAEhB,MAAMnB,QAAgB7T,EAAK2G,uBAAuBrN,EAAM2E,EAAQ,GAChE,IAAK,MAAMqX,KAAcD,EACrBzV,EAAe6H,SAASxJ,EAAO+B,EAAKE,YAAYiD,KAAK0Q,EAASuB,EAAeE,EAAYtV,EAAKsD,mBAEtG,MAGI,IAAK,MAAMgS,KAAcD,QACf1W,EAAwBoL,sBAAsBwL,sBAAsB3V,EAAgBI,EAAM1G,EAAM2E,EAAQ,EAAGmX,EAAeE,GAAY,GAAO,GAAO,EAGtK,CACJ,CACA,MAAMrI,EAAc+H,EAAiB,EAAI,QACnCpV,EAAekD,cAAcxJ,EAAKyK,MAAM,EAAGzK,EAAKI,OAASuT,GAAc5U,EAAO4F,EAAQgP,GAAa,SAEnGrN,EAAe8M,oCACzB,CACA9M,EAAewE,aAAanG,IAAS,CACzC,EAEJ5B,EAAQ0Y,sBAAwBA,C,qCCpEhCxb,OAAO2D,eAAeb,EAAS,aAAc,CAAEhE,OAAO,IACtDgE,EAAQmZ,8BAA2B,EACnC,MAAMlX,EAA0B,EAAQ,OAOxC,MAAMkX,EACF,mBAAAd,GACI,OAAO,CACX,CACA,YAAMrP,CAAOgO,EAAYzT,EAAgBI,EAAM1G,EAAMjB,EAAO4F,GACxD,MAAM2U,QAAiB5S,EAAK+T,gBAAgBza,EAAK2E,GAAQ3E,EAAM2E,GAC/D,GAAIuH,MAAMC,QAAQpN,GAEdA,EAAQA,EAAM6P,KAAK6H,IAAa,CAAG,SAAUA,EAAU,YAAa6C,UAEnE,CACD,GAAqB,kBAAVva,EACP,MAAM,IAAIiG,EAAwBgD,WAAW,wCAAwCnH,KAAKC,UAAU/B,2BAAgCiG,EAAwBiD,YAAYkU,4BAE5Kpd,EAAQ,CAAE,SAAUA,EAAO,YAAaua,EAC5C,OACMhT,EAAekD,cAAcxJ,EAAKyK,MAAM,EAAGzK,EAAKI,OAAS,GAAIrB,EAAO4F,EAAQ,GAAG,GACrF2B,EAAewE,aAAanG,IAAS,CACzC,EAEJ5B,EAAQmZ,yBAA2BA,C,qCC7BnCjc,OAAO2D,eAAeb,EAAS,aAAc,CAAEhE,OAAO,IACtDgE,EAAQqZ,0BAAuB,EAC/B,MAAM/W,EAA0B,EAAQ,OAClCU,EAAS,EAAQ,OAMvB,MAAMqW,EACF,mBAAAhB,GACI,OAAO,CACX,CACA,YAAMrP,CAAOgO,EAAYzT,EAAgBI,EAAM1G,EAAMjB,EAAO4F,GACxD,IAAKuH,MAAMC,QAAQpN,GAAQ,CACvB,GAAqB,kBAAVA,EAAoB,CAE3B,MAAM2F,QAAgB4B,EAAelC,WAAWpE,GAC1Cqc,EAAoBtW,EAAOY,KAAKmO,oBAAoBpQ,EAAS1E,EAAK2E,EAAQ,IAE1EiR,EAA2B,WAAtByG,QACC3V,EAAK4Q,sBAAsB5S,EAAS3F,SACpC2H,EAAKoR,eAAepT,EAAS3F,GACzC,GAAI6W,EAAI,CAEJ,MAAMa,EAAW,CAAE,MAAuB,cAAhBb,EAAG3H,SAA2B2H,EAAG7W,MAAQA,SAC7DuH,EAAekD,cAAcxJ,EAAKyK,MAAM,EAAGzK,EAAKI,OAAS,GAAIqW,EAAU9R,EAAQ,GAAG,GAExF2B,EAAe6D,QAAQxF,EAAQ,GAAK,CAACiR,EACzC,CACJ,KACK,CAGD,MAAM0G,IAAuBhW,EAAe6D,QAAQxF,EAAQ,GAEvD2X,UACMhW,EAAe6D,QAAQxF,SAE5B2B,EAAekD,cAAcxJ,EAAKyK,MAAM,EAAGzK,EAAKI,OAAS,GAAIrB,EAAO4F,EAAQ,GAAG,GAChF2X,IACDhW,EAAe6D,QAAQxF,EAAQ,GAAK2B,EAAe6D,QAAQxF,GAEnE,CAEA,MAAM4X,QAAoB7V,EAAK+T,gBAAgBza,EAAK2E,GAAQ3E,EAAM2E,GAC5DiQ,EAAuB,OAAhB2H,EACP7V,EAAK4Q,4BAA4BhR,EAAelC,WAAWpE,GAAOuc,GAClE,KACF3H,SAEMvP,EAAwBoL,sBAAsBwL,sBAAsB3V,EAAgBI,EAAM1G,EAAM2E,EAAQ,EAAG+B,EAAK4N,QAASM,GAAM,GAAO,GAAO,SAGjJtO,EAAe8M,oCACzB,CACA9M,EAAewE,aAAanG,IAAS,CACzC,EAEJ5B,EAAQqZ,qBAAuBA,C,oCC3D/Bnc,OAAO2D,eAAeb,EAAS,aAAc,CAAEhE,OAAO,IACtDgE,EAAQgN,4BAAyB,EACjC,MAAMhK,EAAS,EAAQ,OACjBf,EAA0B,EAAQ,OAIxC,MAAM+K,EACF,iBAAArB,GACI,OAAO,CACX,CACA,gBAAA1C,GACI,OAAO,CACX,CACA,cAAMyC,CAASnI,EAAgBI,EAAM1G,EAAM2E,EAAOuG,GAC9C,OAAOrM,KAAKiN,KAAKxF,EAAgBI,EAAM,KAAM1G,EAAM2E,EACvD,CACA,UAAMmH,CAAKxF,EAAgBI,EAAMpH,EAAKU,EAAM2E,GACxC,MAA8B,kBAAhB3E,EAAK2E,EACvB,CACA,YAAMoH,CAAOzF,EAAgBI,EAAMpH,EAAKU,EAAMjB,EAAO4F,GACjD,IAAIiG,QAAkBlE,EAAKmE,qBAAqB7K,EAAM2E,GAEtD,GAAkB,UAAdiG,EAAuB,CAGvB,IAAI4R,EAAc,KACdpS,EAAgB,EACpB,IAAK,IAAIlK,EAAIyE,EAAQ,EAAGzE,EAAI,EAAGA,IAAK,CAChC,MAAMuc,EAAYzc,EAAKE,GACvB,GAAyB,kBAAduc,GAA+C,kBAAdA,EAAwB,CAChErS,EAAgBlK,EAChBsc,EAAcC,EACd,KACJ,CACJ,CACA,GAAoB,OAAhBD,EAAsB,CAEtB,MAAM9E,QAAehR,EAAKsP,kBAAkB1P,EAAelC,WAAWpE,GAAOwc,EAAazd,EAAO4F,EAAO3E,GACxG,IAAK,MAAM0N,KAAUgK,QACX7Y,KAAK6d,kBAAkBpW,EAAgBI,EAAMgH,EAAQ3O,EAAO4F,EAAO3E,EAAKyK,MAAM,EAAGL,GAAgBA,GAGrF,IAAlBsN,EAAOtX,cACDvB,KAAK6d,kBAAkBpW,EAAgBI,EAAM,KAAM3H,EAAO4F,EAAO3E,EAAKyK,MAAM,EAAGL,GAAgBA,EAE7G,CACJ,MACK,GAAkB,SAAdQ,QAECtE,EAAekD,cAAcxJ,EAAKyK,MAAM,GAAI,GAAI1L,EAAO4F,EAAQ,GAAG,QAEvE,QAAkB3F,IAAd4L,GAAyC,UAAdA,EAAuB,CAKvD,IAAK,IAAI1K,EAAIyE,EAAQ,EAAGzE,EAAI,EAAGA,IAC3B,GAAuB,kBAAZF,EAAKE,GAAiB,CAC7B0K,QAAkBlE,EAAKiE,eAAe3K,EAAKE,GAAIF,EAAME,GACrD,KACJ,CAGJ,MAAMiS,QAAsB7L,EAAelC,WAAWpE,EAAKyK,MAAM,GAAI,IACrE,GAAI,UAAW1E,EAAOY,KAAKkO,yBAAyB1C,EAAevH,GAAY,CAG3EtE,EAAewE,aAAanG,EAAQ,IAAK,EACzC,MAAM+S,QAAehR,EAAKsP,kBAAkB1P,EAAelC,WAAWpE,GAAO4K,EAAW7L,EAAO4F,EAAO3E,GACtG,IAAK,MAAM0N,KAAUgK,QACX7Y,KAAK6d,kBAAkBpW,EAAgBI,EAAMgH,EAAQ3O,EAAO4F,EAAO3E,EAAKyK,MAAM,GAAI,GAAI9F,EAAQ,GAGlF,IAAlB+S,EAAOtX,cACDvB,KAAK6d,kBAAkBpW,EAAgBI,EAAM,KAAM3H,EAAO4F,EAAO3E,EAAKyK,MAAM,GAAI,GAAI9F,EAAQ,EAE1G,MAGI2B,EAAeoN,WAAW/O,EAAO,SAE3B2B,EAAekD,cAAcxJ,EAAKyK,MAAM,GAAI,GAAI1L,EAAO4F,EAAQ,GAAG,GAExE2B,EAAe0I,YAAYnK,cAAc7E,EAAKyK,MAAM,GAAI,GAEhE,CACJ,CACA,uBAAMiS,CAAkBpW,EAAgBI,EAAM3H,EAAO4d,EAAehY,EAAOiY,EAAcxS,GAErF,IAAIT,EAAcrD,EAAesD,iBAAiBjF,GAClD,GAAsB,OAAlBgY,GAAyG,cAAxEjW,EAAK0P,gBAAgBuG,EAAeC,EAAcjY,IAAQ,UAAoB,CAC/G,GAAKgF,GAAgBA,EAAY5K,MAI5B,CAID,MAAM8d,EAAcnW,EAAKE,YAAYkG,YACrCxG,EAAe6H,SAASxJ,EAAO+B,EAAKE,YAAYiD,KAAKF,EAAY5K,MAAO2H,EAAKoD,QAAS+S,EAAanW,EAAKsD,oBAExGL,EAAY5K,MAAQ8d,CACxB,KAZwC,CACpC,MAAMC,EAAWpW,EAAKE,YAAYkG,YAClCnD,EAAc,CAAE5K,MAAO+d,EAAU1S,gBAAeH,OAAQ6S,EAC5D,CAYI/d,GACAuH,EAAe6H,SAASxJ,EAAO+B,EAAKE,YAAYiD,KAAKF,EAAY5K,MAAO2H,EAAKyN,SAAUpV,EAAO2H,EAAKsD,mBAE3G,MAISL,IACDA,EAAc,CAAES,gBAAeH,OAAQvD,EAAKqD,SAGpDzD,EAAesD,iBAAiBjF,GAASgF,EAErCrD,EAAeqL,SAAWrL,EAAeqG,kBAAkBhI,IAC3D2B,EAAe8H,UAAU,IAAIpJ,EAAwBgD,WAAW,4CAA6ChD,EAAwBiD,YAAYoG,oBAEzJ,EAEJtL,EAAQgN,uBAAyBA,C,qCC7HjC9P,OAAO2D,eAAeb,EAAS,aAAc,CAAEhE,OAAO,IACtDgE,EAAQuH,2BAAwB,EAChC,MAAMyS,EAA+B,EAAQ,OACvCC,EAA0B,EAAQ,MAClCC,EAA6B,EAAQ,OACrCC,EAAyB,EAAQ,OACjCnX,EAAS,EAAQ,OAKvB,MAAMuE,EAMF,6BAAO6S,CAAuBpD,GAC1B,MAAO,WAAYA,IACV,SAAUA,GAAiD,IAAnC9Z,OAAOD,KAAK+Z,GAAY3Z,QAAoD,IAAnCH,OAAOD,KAAK+Z,GAAY3Z,OACtG,CAMA,8BAAO6Z,CAAwBF,GAC3B,MAAO,WAAYA,IACV,SAAUA,GAAc9Z,OAAOD,KAAK+Z,GAAY3Z,OAAS,KACpD,SAAU2Z,IAAe9Z,OAAOD,KAAK+Z,GAAY3Z,OAAS,EAC5E,CAQA,6BAAOka,CAAuBP,EAAYpV,EAAO3E,GAC7C,IAAImd,EAAyB7S,EAAsB6S,uBAAuBpD,GACtElE,EAAQ,GACZ,IAAK,IAAI3V,EAAIyE,EAAOzE,EAAIF,EAAKI,OAAQF,IAC5Bid,GAA6C,kBAAZnd,EAAKE,KACvC2V,GAAS,IAAM7V,EAAKE,IAGnBid,GAA6C,kBAAZnd,EAAKE,KACvCid,GAAyB,GAGjC,OAAOtH,CACX,CAeA,gCAAamE,CAAoB1T,EAAgBtG,EAAM2E,GACnD,MAAM+P,EAAW,CACbqF,WAAY,CAAE,QAAQ,GACtBpV,QACA+P,UAAU,GAGd,IAAI0I,GAAsB,EAE1B,MAAM1Y,QAAgB4B,EAAelC,WAAWpE,EAAM,GACtD,IAAK,IAAIE,EAAIyE,EAAQ,EAAGzE,GAAK,EAAGA,IAC5B,GAAuB,kBAAZF,EAAKE,GAAiB,CAE7B,MAAMmd,EAAiBtX,EAAOY,KAAK6N,gBAAgB9P,EAAS,aAAc1E,EAAKE,IAAI,GACnF,GAAImd,GAAkB/S,EAAsB6S,uBAAuBE,GAC/D,MAAO,CACHtD,WAAYsD,EACZ1Y,MAAOzE,EAAI,EACXwU,UAAU,GAGlB,MAAM4I,EAAmBvX,EAAOY,KAAK6N,gBAAgB9P,EAAS,aAAc1E,EAAKE,EAAI,IAAI,GACzF,GAAKod,EAQA,CAED,MAAM5B,EAAiB,WAAY4B,EAEnC,IAAK,MAAMC,KAAuBjT,EAAsBkT,mBACpD,GAAIF,EAAiBC,GACjB,OAAI7B,EAEIpR,EAAsBkT,mBAAmBD,GAAqBnC,sBACvD,CACHrB,WAAYuD,EACZ3Y,MAAOzE,EACPwU,UAAU,GAIPA,EAKP0I,EACO1I,EAGA,CACHqF,WAAYuD,EACZ3Y,MAAOzE,EACPwU,UAAU,GAO9B,OAAOA,CACX,CA3CI,GAAI0I,EAEA,OAAO1I,EAGX0I,GAAsB,CAuC9B,CAEJ,OAAO1I,CACX,CAeA,yCAAanK,CAA6BjE,EAAgBtG,EAAM2E,GAC5D,MAAM8Y,QAAgBnT,EAAsB0P,oBAAoB1T,EAAgBtG,EAAM2E,GACtF,OAAQ8Y,EAAQ/I,YAAc,WAAY+I,EAAQ1D,WACtD,CACA,iBAAArL,GACI,OAAO,CACX,CACA,gBAAA1C,GACI,OAAO,CACX,CACA,cAAMyC,CAASnI,EAAgBI,EAAM1G,EAAM2E,EAAOuG,GAC9C,cAAerM,KAAKiN,KAAKxF,EAAgBI,EAAM,KAAM1G,EAAM2E,EAC/D,CACA,UAAMmH,CAAKxF,EAAgBI,EAAMpH,EAAKU,EAAM2E,GACxC,MAAMoV,EAAahU,EAAOY,KAAKkO,+BAA+BvO,EAAelC,WAAWpE,EAAM,GAAIA,EAAK2E,EAAQ,IAC/G,IAAK,MAAM+Y,KAAiBpT,EAAsBkT,mBAC9C,GAAIzD,EAAW2D,GACX,MAAO,CACH3D,aACA0D,QAASnT,EAAsBkT,mBAAmBE,IAI9D,OAAO,IACX,CACA,YAAM3R,CAAOzF,EAAgBI,EAAMpH,EAAKU,EAAMjB,EAAO4F,EAAOkH,GACxD,OAAOA,EAAW4R,QAAQ1R,OAAOF,EAAWkO,WAAYzT,EAAgBI,EAAM1G,EAAMjB,EAAO4F,EAC/F,EAEJ2F,EAAsBkT,mBAAqB,CACvC,MAAO,IAAIT,EAA6B5B,2BACxC,SAAU,IAAI6B,EAAwBvB,sBACtC,YAAa,IAAIwB,EAA2Bf,yBAC5C,QAAS,IAAIgB,EAAuBd,sBAExCrZ,EAAQuH,sBAAwBA,C,kCC1LhCrK,OAAO2D,eAAeb,EAAS,aAAc,CAAEhE,OAAO,IACtDgE,EAAQ2N,iCAA8B,EAKtC,MAAMA,EACF,iBAAAhC,GACI,OAAO,CACX,CACA,gBAAA1C,GACI,OAAO,CACX,CACA,cAAMyC,CAASnI,EAAgBI,EAAM1G,EAAM2E,EAAOuG,GAC9C,OAAO,CACX,CACA,UAAMY,CAAKxF,EAAgBI,EAAMpH,EAAKU,EAAM2E,GACxC,OAAO,CACX,CACA,YAAMoH,CAAOzF,EAAgBI,EAAMpH,EAAKU,EAAMjB,EAAO4F,GACjD2B,EAAewE,aAAanG,IAAS,CACzC,EAEJ5B,EAAQ2N,4BAA8BA,C,qCCvBtCzQ,OAAO2D,eAAeb,EAAS,aAAc,CAAEhE,OAAO,IACtDgE,EAAQ0N,2BAAwB,EAChC,MAAMzL,EAA0B,EAAQ,OAClCe,EAAS,EAAQ,OAKvB,MAAM0K,EAeF,kCAAawL,CAAsB3V,EAAgBI,EAAM1G,EAAM2E,EAAO8I,EAAWC,EAAQC,EAASC,EAAY+P,GAC1G,MAAMC,QAAwBlX,EAAKgU,mBAAmB1a,EAAM2E,GACtDuI,QAAyBxG,EAAKyG,oBAAoBxI,EAAO3E,GACzD6d,EAAuBlZ,EAAQuI,EAC/BN,EAAWtG,EAAe6D,QAAQyT,GACxC,GAAIhR,IAAa+Q,EAEb,IAAK,MAAM1Q,KAAWL,EAAU,CAE5B,MAAMkR,EAAU5Q,GAAoB,EACpC,GAAI4Q,EAAS,CACT,MAAM1Q,EAAS9G,EAAe6D,QAAQ0T,EAAuB,GAC7D,GAAIzQ,EACA,IAAK,MAAME,KAASF,EAEhB1G,EAAK8G,gBAAgB7I,EAAOsI,EAASQ,EAAWC,EAAQJ,EAAOK,EAASC,QAKxED,GACAjH,EAAKwT,uBAAuBxM,GAC5BpH,EAAewH,+BAA+B+P,EAAuB,GAAGzb,KAAK,CAAE6K,QAASS,EAAQD,YAAWC,OAAQT,EAASW,gBAG5HtH,EAAewH,+BAA+B+P,EAAuB,GAChEzb,KAAK,CAAE6K,UAASQ,YAAWC,SAAQE,cAGpD,KACK,CAED,MAAMN,QAAc5G,EAAK2G,uBAAuBrN,EAAM4d,GACtDlX,EAAK8G,gBAAgB7I,EAAOsI,EAASQ,EAAWC,EAAQJ,EAAOK,EAASC,EAC5E,CACJ,MAQA,GAJID,GACAjH,EAAKwT,uBAAuBxM,GAG5BiQ,GAEA,GAAIrX,EAAeqL,QAAS,CAEpBrL,EAAe6D,QAAQxF,IACvB2B,EAAe8H,UAAU,IAAIpJ,EAAwBgD,WAAW,8CAA8C1B,EAAe6D,QAAQxF,GAAO,GAAG5F,QAASiG,EAAwBiD,YAAYoG,qBAGhM,IAAK,IAAInO,EAAI,EAAGA,EAAIyE,EAAOzE,IAC6B,cAA1CwG,EAAKiE,eAAe3K,EAAKE,GAAIF,EAAME,IACzCoG,EAAe8H,UAAU,IAAIpJ,EAAwBgD,WAAW,sDAAuDhD,EAAwBiD,YAAYoG,qBAInK,MAAM1B,EAAoBrG,EAAeiI,yBAAyBqP,GAC5DG,EAAgB,CAAEtQ,YAAWC,SAAQC,UAASsN,kBAAmB,GAAItW,MAAOiZ,GAClFjR,EAAkBvK,KAAK2b,GAGvB,IAAK,IAAI7d,EAAIyM,EAAkBvM,OAAS,EAAGF,GAAK,EAAGA,IAAK,CAEpD,MAAM8d,EAAqBrR,EAAkBzM,GACzC8d,EAAmBrZ,MAAQiZ,IAC3BG,EAAc9C,kBAAkB7Y,KAAK4b,GACrCrR,EAAkBtC,OAAOnK,EAAG,GAEpC,CACJ,OAGAoG,EAAeiN,+BAA+BqK,GAAiBxb,KAAK,CAAEqL,YAAWC,SAAQC,UAASC,cAG9G,CACA,iBAAAc,GACI,OAAO,CACX,CACA,gBAAA1C,GACI,OAAO,CACX,CACA,cAAMyC,CAASnI,EAAgBI,EAAM1G,EAAM2E,EAAOuG,GAC9C,MAAM5L,EAAMU,EAAK2E,GACjB,GAAIrF,EAAK,CACL,MAAMoF,QAAgB4B,EAAelC,WAAWpE,GAChD,IAAKsG,EAAemG,iBAAiB9H,UAAgB+B,EAAK2R,gBAAgB3T,EAAS1E,EAAK2E,IAKpF,MAHsD,UAAlDoB,EAAOY,KAAKmO,oBAAoBpQ,EAASpF,KACzCgH,EAAemG,iBAAiB9H,EAAQ,IAAK,IAE1C,CAEf,CACA,OAAO,CACX,CACA,UAAMmH,CAAKxF,EAAgBI,EAAMpH,EAAKU,EAAM2E,GACxC,OAAO3E,EAAK2E,EAChB,CACA,YAAMoH,CAAOzF,EAAgBI,EAAMpH,EAAKU,EAAMjB,EAAO4F,EAAOkH,GACxD,MAAM0Q,EAAcvc,EAAK2E,GACnBD,QAAgB4B,EAAelC,WAAWpE,GAC1CyN,QAAkB/G,EAAK2R,gBAAgB3T,EAASpF,GACtD,GAAImO,EAAW,CACX,MAAMwQ,QAAgBvX,EAAKsP,YAAYtR,EAASpF,EAAKP,EAAO4F,EAAO3E,GACnE,GAAIie,EAAQ7d,OACR,IAAK,IAAIsN,KAAUuQ,EAAS,CAExB,IAAIrT,QAAkBlE,EAAKmE,qBAAqB7K,EAAM2E,GACtD,MAAMgJ,EAAU5H,EAAOY,KAAKyO,kBAAkB1Q,EAAS6X,EAAa3R,GACpE,IAAIsT,EAAoB,EACxB,MAAqB,aAAdtT,GAAiD,kBAAdA,EAEb,kBAAdA,EACPsT,IAGAvZ,IAEJiG,QAAkBlE,EAAKmE,qBAAqB7K,EAAM2E,EAAQuZ,GAE9D,MAAMtQ,EAAa7H,EAAOY,KAAK0O,yBAAyBzK,GACxDlE,EAAKkU,8BAA8Btb,EAAKqO,EAASC,GACjD,MAAM+P,EAAe5X,EAAOY,KAAK2O,6BAA6B1K,GAC9D,GAAI7L,EAAO,CAGP,MAAMof,EAAqB,UAAWpY,EAAOY,KAAKkO,yBAAyBnQ,EAASpF,GACpF,GAAI6e,GAAsBpf,EAAM,SAAU,CACtC,IAAMof,IAAuBjS,MAAMC,QAAQpN,KAAWA,EAAM,UACpDA,EAAM,WAAamN,MAAMC,QAAQpN,EAAM,YACxC2O,IAAWhH,EAAKqD,OAAQ,CAC3B,MAAMJ,EAAcjD,EAAKE,YAAYkG,YACrCxG,EAAe6H,SAASxJ,EAAO+B,EAAKE,YAAYiD,KAAKF,EAAajD,EAAKoD,QAASpD,EAAKqD,OAAQrD,EAAKsD,oBAClG1D,EAAe6H,SAASxJ,EAAO+B,EAAKE,YAAYiD,KAAKF,EAAajD,EAAKyN,SAAUzG,EAAQhH,EAAKsD,oBAC9F0D,EAAS/D,CACb,CAEA,GAAIgE,IAAYrH,EAAe8K,iBAC3B,MAAM,IAAIpM,EAAwBgD,WAAW,mDAAmD1I,IAAO0F,EAAwBiD,YAAYkS,+BAEnJ,CACJ,OACM1J,EAAsBwL,sBAAsB3V,EAAgBI,EAAM1G,EAAM2E,EAAO8I,EAAWC,EAAQC,EAASC,EAAY+P,EACjI,CAER,CACJ,EAEJ5a,EAAQ0N,sBAAwBA,C,mCC7KhCxQ,OAAO2D,eAAeb,EAAS,aAAc,CAAEhE,OAAO,IACtDgE,EAAQqb,yBAAsB,EAI9B,MAAMA,EACF,WAAAla,CAAYma,GACRxf,KAAKwf,QAAUA,CACnB,CACA,iBAAA3P,GACI,OAAO,CACX,CACA,gBAAA1C,GACI,OAAO,CACX,CACA,cAAMyC,CAASnI,EAAgBI,EAAM1G,EAAM2E,EAAOuG,GAC9C,OAAO,CACX,CACA,UAAMY,CAAKxF,EAAgBI,EAAMpH,EAAKU,EAAM2E,GACxC,OAAOrF,IAAQT,KAAKwf,OACxB,EAEJtb,EAAQqb,oBAAsBA,C,qCCtB9Bne,OAAO2D,eAAeb,EAAS,aAAc,CAAEhE,OAAO,IACtDgE,EAAQwN,mCAAgC,EACxC,MAAM+N,EAAwB,EAAQ,OAChCtZ,EAA0B,EAAQ,OAIxC,MAAMuL,UAAsC+N,EAAsBF,oBAC9D,WAAAla,GACIkC,MAAM,cACV,CACA,YAAM2F,CAAOzF,EAAgBI,EAAMpH,EAAKU,EAAMjB,EAAO4F,IAE5B,kBAAV5F,GAAwC,kBAAVA,GAAsBA,EAAM,YACjEuH,EAAe8H,UAAU,IAAIpJ,EAAwBgD,WAAW,mCAAmCnH,KAAKC,UAAU/B,KAAUiG,EAAwBiD,YAAYoG,oBAGxK,EAEJtL,EAAQwN,8BAAgCA,C,qCCnBxCtQ,OAAO2D,eAAeb,EAAS,aAAc,CAAEhE,OAAO,IACtDgE,EAAQiN,gCAA6B,EACrC,MAAMhL,EAA0B,EAAQ,OAClCsZ,EAAwB,EAAQ,OAItC,MAAMtO,UAAmCsO,EAAsBF,oBAC3D,WAAAla,GACIkC,MAAM,WACV,CACA,gBAAA4F,GACI,OAAO,CACX,CACA,YAAMD,CAAOzF,EAAgBI,EAAMpH,EAAKU,EAAMjB,EAAO4F,GAE7C2B,EAAesB,mBACXtB,EAAe2F,gBAAgBtH,IAC5B2B,EAAegG,eAAe3H,SACI3F,IAAlCsH,EAAe6D,QAAQxF,KAC9B2B,EAAe8H,UAAU,IAAIpJ,EAAwBgD,WAAW,yFAC5BhD,EAAwBiD,YAAYsW,8BAK5E,MAAMpM,EAAgB7L,EAAelC,WAAWpE,GAE1C0E,EAAU4B,EAAe0L,aAAajT,SAAcoT,GAAeG,iBACzEhM,EAAe0I,YAAYpK,WAAW5E,EAAKyK,MAAM,GAAI,GAAI/F,GACzD4B,EAAegN,YAAYvU,SACrBuH,EAAe2L,sBAAsBvN,EAC/C,EAEJ3B,EAAQiN,2BAA6BA,C,qCClCrC/P,OAAO2D,eAAeb,EAAS,aAAc,CAAEhE,OAAO,IACtDgE,EAAQoN,8BAA2B,EACnC,MAAMmO,EAAwB,EAAQ,OAItC,MAAMnO,UAAiCmO,EAAsBF,oBACzD,WAAAla,GACIkC,MAAM,SACV,CACA,YAAM2F,CAAOzF,EAAgBI,EAAMpH,EAAKU,EAAMjB,EAAO4F,GAEjD2B,EAAeiG,WAAW5H,EAAQ,IAAK,CAC3C,EAEJ5B,EAAQoN,yBAA2BA,C,qCCfnClQ,OAAO2D,eAAeb,EAAS,aAAc,CAAEhE,OAAO,IACtDgE,EAAQkN,2BAAwB,EAChC,MAAMjL,EAA0B,EAAQ,OAClCsZ,EAAwB,EAAQ,OAItC,MAAMrO,UAA8BqO,EAAsBF,oBACtD,WAAAla,GACIkC,MAAM,MACV,CACA,gBAAA4F,GACI,OAAO,CACX,CACA,YAAMD,CAAOzF,EAAgBI,EAAMpH,EAAKU,EAAMjB,EAAO4F,GACjD,GAAqB,kBAAV5F,EAAoB,CAE3B,GAAIuH,EAAeqL,SAA4B,kBAAV5S,EAAoB,CACrD,MAAMyf,EAAYve,OAAOD,KAAKjB,GACL,IAArByf,EAAUpe,QAAiC,QAAjBoe,EAAU,IACpClY,EAAe8H,UAAU,IAAIpJ,EAAwBgD,WAAW,mDAAmDjJ,EAAM,SAAUiG,EAAwBiD,YAAY4S,uBAE/K,MAEIvU,EAAe8H,UAAU,IAAIpJ,EAAwBgD,WAAW,sBAAsBjJ,KAAUiG,EAAwBiD,YAAY4P,mBAExI,MACJ,CAGA,MAAM+F,QAAwBlX,EAAKgU,mBAAmB1a,EAAM2E,GAc5D,QAZgD3F,IAA5CsH,EAAe6D,QAAQyT,KACnBtX,EAAe6D,QAAQyT,GAAiB,GAAG1T,SAE3C5D,EAAe8H,UAAU,IAAIpJ,EAAwBgD,WAAW,8DAA8DhI,EAAK2E,EAAQ,MAAOK,EAAwBiD,YAAYsP,6BAItLjR,EAAe8H,UAAU,IAAIpJ,EAAwBgD,WAAW,yBAAyB1B,EACpF6D,QAAQyT,GAAiB,GAAG7e,eAAeA,KAAUiG,EAAwBiD,YAAYwW,sBAIlGnY,EAAeqL,SAAWrL,EAAeqG,kBAAkBhI,GAC3D,IAAK,MAAM6J,KAAclI,EAAeqG,kBAAkBhI,GAClD6J,EAAW7J,QAAUA,GACrB2B,EAAe8H,UAAU,IAAIpJ,EAAwBgD,WAAW,8CAA8CjJ,IAASiG,EAAwBiD,YAAYoG,qBAKvK/H,EAAe6D,QAAQyT,GAAmBlX,EAAKwQ,0BAA0BxQ,EAAKoR,qBAAqBxR,EAAelC,WAAWpE,GAAOjB,GACxI,EAEJgE,EAAQkN,sBAAwBA,C,qCCvDhChQ,OAAO2D,eAAeb,EAAS,aAAc,CAAEhE,OAAO,IACtDgE,EAAQmN,iCAA8B,EACtC,MAAMlL,EAA0B,EAAQ,OAClCsZ,EAAwB,EAAQ,OAItC,MAAMpO,UAAoCoO,EAAsBF,oBAC5D,WAAAla,GACIkC,MAAM,YACV,CACA,YAAM2F,CAAOzF,EAAgBI,EAAMpH,EAAKU,EAAMjB,EAAO4F,GAC5B,kBAAV5F,GACPuH,EAAe8H,UAAU,IAAIpJ,EAAwBgD,WAAW,4BAA4BjJ,KAAUiG,EAAwBiD,YAAYyW,yBAE9I,MAAMC,QAAsBjY,EAAK0P,gBAAgBrX,EAAOiB,EAAM2E,QAAa2B,EAAelC,WAAWpE,IACjG,WAAY2e,GACZrY,EAAe8H,UAAU,IAAIpJ,EAAwBgD,WAAW,2CAA2CnH,KAAKC,UAAU/B,MAAWiG,EAAwBiD,YAAYyW,yBAEzK,UAAWC,GACXrY,EAAe8H,UAAU,IAAIpJ,EAAwBgD,WAAW,0CAA0CnH,KAAKC,UAAU/B,MAAWiG,EAAwBiD,YAAYyW,yBAE5KpY,EAAewE,aAAanG,IAAS,CACzC,EAEJ5B,EAAQmN,4BAA8BA,C,oCCzBtCjQ,OAAO2D,eAAeb,EAAS,aAAc,CAAEhE,OAAO,IACtDgE,EAAQqN,6BAA0B,EAClC,MAAMpL,EAA0B,EAAQ,OAClCsZ,EAAwB,EAAQ,OAItC,MAAMlO,UAAgCkO,EAAsBF,oBACxD,WAAAla,GACIkC,MAAM,QACV,CACA,YAAM2F,CAAOzF,EAAgBI,EAAMpH,EAAKU,EAAMjB,EAAO4F,GAC5B,kBAAV5F,GACPuH,EAAe8H,UAAU,IAAIpJ,EAAwBgD,WAAW,kCAAkC1I,QAAUP,KAAUiG,EAAwBiD,YAAY2W,qBAE1J,iBAAkBlY,EAAK0P,gBAAgBrX,EAAOiB,EAAM2E,QAAa2B,EAAelC,WAAWpE,KAC3FsG,EAAe8H,UAAU,IAAIpJ,EAAwBgD,WAAW,qCAAqC1I,KAAQ0F,EAAwBiD,YAAY2W,qBAErJtY,EAAewE,aAAanG,IAAS,CACzC,EAEJ5B,EAAQqN,wBAA0BA,C,qCCrBlCnQ,OAAO2D,eAAeb,EAAS,aAAc,CAAEhE,OAAO,IACtDgE,EAAQsN,6BAA0B,EAClC,MAAMrL,EAA0B,EAAQ,OAClCe,EAAS,EAAQ,OACjBV,EAA0B,EAAQ,OAClCiZ,EAAwB,EAAQ,OAItC,MAAMjO,UAAgCiO,EAAsBF,oBACxD,WAAAla,GACIkC,MAAM,QACV,CACA,gBAAA4F,GACI,OAAO,CACX,CACA,YAAMD,CAAOzF,EAAgBI,EAAMpH,EAAKU,EAAMjB,EAAO4F,GACjD,MAAM4X,EAAcvc,EAAK2E,GAInBD,QAAgB4B,EAAelC,WAAWpE,GAC1CyN,EAAY/G,EAAK4N,QACjB1J,QAAkBlE,EAAKmE,qBAAqB7K,EAAM2E,GAClDgJ,EAAU5H,EAAOY,KAAKyO,kBAAkB1Q,EAAS6X,EAAa3R,GAC9DgD,EAAa7H,EAAOY,KAAK0O,yBAAyBzK,GACxDlE,EAAKkU,8BAA8Btb,EAAKqO,EAASC,GACjD,MAAM+P,EAAe5X,EAAOY,KAAK2O,6BAA6B1K,GAExDiU,EAAW3S,MAAMC,QAAQpN,GAASA,EAAQ,CAACA,GACjD,IAAK,MAAM+f,KAAWD,EAAU,CACL,kBAAZC,GACPxY,EAAe8H,UAAU,IAAIpJ,EAAwBgD,WAAW,wBAAwB8W,KAAY9Z,EAAwBiD,YAAY8W,qBAE5I,MAAMnK,EAAOlO,EAAK4Q,sBAAsB5S,EAASoa,GAC7ClK,SACMvP,EAAwBoL,sBAAsBwL,sBAAsB3V,EAAgBI,EAAM1G,EAAM2E,EAAO8I,EAAWmH,EAAMjH,EAASC,EAAY+P,EAE3J,CAEA,IAAI7K,EAAgB1L,QAAQC,QAAQ3C,GAChCsa,GAAwB,EAC5B,IAAK,MAAMF,KAAWD,EAASpP,OAAQ,CACnC,MAAMwP,EAAclZ,EAAOY,KAAK6N,gBAAgB9P,EAAS,WAAYoa,EAAS,MAC1EG,IACAD,GAAwB,EACxBlM,EAAgBA,EAAcrO,MAAMya,GAAM5Y,EAAe0L,aAAaiN,EAAaC,EAAE5M,mBAE7F,EAEIhM,EAAesB,mBACXoX,GAA0B1Y,EAAeoL,2CACzCpL,EAAe2F,gBAAgBtH,KAAU2B,EAAe6D,QAAQxF,IACpE2B,EAAe8H,UAAU,IAAIpJ,EAAwBgD,WAAW,qGAC5BhD,EAAwBiD,YAAYsW,8BAGxES,IAEAlM,EAAgBA,EAAcrO,MAAMya,IAIQ,IAApCA,EAAE5M,gBAAgB,cACX,IAAItN,EAAwBkN,wBAAwBjS,OAAOuG,OAAOvG,OAAOuG,OAAO,CAAC,EAAG0Y,EAAE5M,iBAAkB,CAAE,cAAc,EAAO,uBAAwB5N,EAAQ4N,mBAEnK4M,IAGX5Y,EAAe0I,YAAYpK,WAAW5E,EAAKyK,MAAM,EAAGzK,EAAKI,OAAS,GAAI0S,IAG1ExM,EAAegG,eAAe3H,IAAS,CAC3C,EAEJ5B,EAAQsN,wBAA0BA,C,qCC3ElCpQ,OAAO2D,eAAeb,EAAS,aAAc,CAAEhE,OAAO,IACtDgE,EAAQyN,wCAAqC,EAC7C,MAAMxL,EAA0B,EAAQ,OAKxC,MAAMwL,EACF,iBAAA9B,GACI,OAAO,CACX,CACA,gBAAA1C,GACI,OAAO,CACX,CACA,cAAMyC,CAASnI,EAAgBI,EAAM1G,EAAM2E,EAAOuG,GAC9C,MAAM5L,QAAYoH,EAAKiE,eAAe3K,EAAK2E,GAAQ3E,EAAM2E,GACzD,QAAIK,EAAwB2B,KAAKgT,mBAAmBra,OAE3C4L,GACW,UAAR5L,EAOhB,CACA,UAAMwM,CAAKxF,EAAgBI,EAAMpH,EAAKU,EAAM2E,GACxC,OAAOK,EAAwB2B,KAAKgT,mBAAmBra,EAC3D,CACA,YAAMyM,CAAOzF,EAAgBI,EAAMpH,EAAKU,EAAMjB,EAAO4F,GACjD,MAAMwa,EAAc3O,EAAmC4O,qBAAqB9f,QACxDN,IAAhBmgB,EACIA,UAAsBpgB,IAAUogB,EAAYvK,MAC5CtO,EAAe8H,UAAU,IAAIpJ,EAAwBgD,WAAW,2BAA2B1I,kBAAoBP,KAAUogB,EAAYE,YAGpI/Y,EAAegL,cACpBhL,EAAe8H,UAAU,IAAIxN,MAAM,oBAAoBtB,kBAAoBP,OAE/EuH,EAAewE,aAAanG,IAAS,CACzC,EAEJ6L,EAAmC4O,qBAAuB,CACtD,SAAU,CAAExK,KAAM,SAAUyK,UAAWra,EAAwBiD,YAAY2O,qBAC3E,QAAS,KACT,WAAY,CAAEhC,KAAM,SAAUyK,UAAWra,EAAwBiD,YAAYqX,uBAC7E,OAAQ,KACR,SAAU,MAEdvc,EAAQyN,mCAAqCA,C,qCClD7CvQ,OAAO2D,eAAeb,EAAS,aAAc,CAAEhE,OAAO,IACtDgE,EAAQuN,8BAA2B,EACnC,MAAMgO,EAAwB,EAAQ,OAItC,MAAMhO,UAAiCgO,EAAsBF,oBACzD,WAAAla,GACIkC,MAAM,SACV,CACA,cAAMqI,CAASnI,EAAgBI,EAAM1G,EAAM2E,EAAOuG,GAE9C,MAAM5L,EAAMU,EAAK2E,GAIjB,OAHIrF,IAAQgH,EAAeoG,aAAa/H,UAAgB9F,KAAKiN,KAAKxF,EAAgBI,EAAMpH,EAAKU,EAAM2E,KAC/F2B,EAAeoG,aAAa/H,IAAS,GAElCyB,MAAMqI,SAASnI,EAAgBI,EAAM1G,EAAM2E,EAAOuG,EAC7D,CACA,UAAMY,CAAKxF,EAAgBI,EAAMpH,EAAKU,EAAM2E,GACxC,MAAmG,iBAAtF+B,EAAKiE,eAAe3K,EAAK2E,GAAQ3E,EAAKyK,MAAM,EAAGzK,EAAKI,OAAS,GAAIuE,EAAQ,GAAG,EAC7F,CACA,YAAMoH,CAAOzF,EAAgBI,EAAMpH,EAAKU,EAAMjB,EAAO4F,GAMjD2B,EAAeoG,aAAa/H,IAAS,SAE9B2B,EAAe0G,yBAAyBrI,UACxC2B,EAAe0H,yBAAyBrJ,GAE/C2B,EAAewE,aAAanG,IAAS,CACzC,EAEJ5B,EAAQuN,yBAA2BA,C,6IC/BnC,MAAMiP,EAAsB,QAE5B,SAASC,EAAaC,GACpB,OAAOrH,GACiB,cAAlBA,EAAKnK,SACA,KAGJmK,EAAKrZ,MAAM2Z,WAAW6G,GAKpBE,EAAQrL,UAAUgE,EAAKrZ,MAAM0L,MAAM8U,EAAoBnf,SAJrD,IAMb,CAEA,SAASsf,EAAaD,GACpB,MAAME,EAAUH,EAAYC,GAE5B,OAAO5V,IACL,MAAMoD,EAAU0S,EAAQ9V,EAAKoD,SACvBQ,EAAYkS,EAAQ9V,EAAK4D,WACzBC,EAASiS,EAAQ9V,EAAK6D,QACtBJ,EAAQqS,EAAQ9V,EAAKyD,OAE3B,OAAIL,GAAWQ,GAAaC,GAAUJ,EAC7BmS,EAAQ5V,KACboD,GAAWpD,EAAKoD,QAChBQ,GAAa5D,EAAK4D,UAClBC,GAAU7D,EAAK6D,OACfJ,GAASzD,EAAKyD,OAIXzD,EAEX,CAEA,MAAM+V,EACJ,WAAA1b,CAAa2b,GAAO,QAAEpY,EAAU8X,EAAmB,QAAE7a,EAAU,KAAI,eAAEsM,EAAc,QAAEyO,EAAU,KAAQ,CAAC,GACtG,MAAMhZ,EAAS,IAAI,EAAA1B,aAAa,CAC9B0C,UACA/C,UACAkC,YAAa6Y,EACbzO,iBACApJ,kBAAkB,IAGpBiY,EAAM7W,KAAKvC,GAEX,MAAMkZ,EAAUD,EAAYD,GAEtBK,EAAY,IAAI,EAAA5Z,UAAU,CAC9B6Z,YAAY,EACZD,UAAW,CAACjW,EAAMP,EAAUC,KAC1BA,EAAS,KAAMoW,EAAQ9V,GAAK,IAYhC,OARApD,EAAOc,GAAG,WAAW7C,IACnBzE,OAAO+f,QAAQtb,GAAS0D,SAAQ,EAAE6X,EAAQzK,MACxCsK,EAAUvd,KAAK,SAAU0d,EAAQR,EAAQrL,UAAUoB,GAAI,GACxD,IAEH/O,EAAOc,GAAG,SAAS9G,GAAOqf,EAAUI,QAAQzf,KAC5CgG,EAAOuC,KAAK8W,IAEL,OAAWA,EACpB,EAGF,QC1EA,MAAMlhB,UAAe,IACnB,WAAAsF,CAAaiC,GACXC,MAAM,EAAcD,EACtB,EAGF,O,mCCTA,MAAMga,EACJ,WAAAjc,CAAakc,EAAMja,GACjBtH,KAAKuhB,KAAOA,EACZvhB,KAAKsH,QAAUA,CACjB,CAEA,MAAA0C,CAAQgX,EAAO1Z,GACb,MAAM8C,EAAS,IAAIpK,KAAKuhB,KAAKP,EAAO,IAAKhhB,KAAKsH,WAAYA,IAY1D,OAVA0Z,EAAMtY,GAAG,OAAO,KACT0B,EAAOoX,UACVpX,EAAO1G,KAAK,MACd,IAGFsd,EAAMtY,GAAG,SAAS9G,IAChBwI,EAAO1G,KAAK,QAAS9B,EAAG,IAGnBwI,CACT,EAGF,K,mCCvBA,MAAMqX,EAAY,IAAIC,IAAI,CAAC,SAAU,iBAAkB,aAEvD,SAASF,EAAUG,GACjB,OAAO,IAAIC,MAAMD,EAAQ,CACvB,GAAArY,CAAKuY,EAAQphB,GACX,OAAIghB,EAAUnY,IAAI7I,IAIXqhB,QAAQxY,OAAOyY,UACxB,EACA,GAAAjd,CAAK+c,EAAQphB,GACX,GAAIghB,EAAUnY,IAAI7I,GAChB,OAGF,MAAMoD,EAASie,QAAQhd,OAAOid,WAE9B,OAAIle,GAAiC,oBAAhBA,EAAOme,KACnBne,EAAOme,KAAKH,GAGdhe,CACT,EACA,GAAAoe,CAAKJ,EAAQphB,EAAKP,GAChB,IAAIuhB,EAAUnY,IAAI7I,GAIlB,OAAOqhB,QAAQG,OAAOF,UACxB,GAEJ,CAEA,K","sources":["webpack://rapid-triples/./node_modules/@bergos/jsonparse/jsonparse.js","webpack://rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/jsonld-streaming-parser/index.js","webpack://rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/jsonld-streaming-parser/lib/ContextTree.js","webpack://rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/jsonld-streaming-parser/lib/JsonLdParser.js","webpack://rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/jsonld-streaming-parser/lib/ParsingContext.js","webpack://rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/jsonld-streaming-parser/lib/Util.js","webpack://rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/jsonld-streaming-parser/lib/containerhandler/ContainerHandlerIdentifier.js","webpack://rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/jsonld-streaming-parser/lib/containerhandler/ContainerHandlerIndex.js","webpack://rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/jsonld-streaming-parser/lib/containerhandler/ContainerHandlerLanguage.js","webpack://rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/jsonld-streaming-parser/lib/containerhandler/ContainerHandlerType.js","webpack://rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/jsonld-streaming-parser/lib/entryhandler/EntryHandlerArrayValue.js","webpack://rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/jsonld-streaming-parser/lib/entryhandler/EntryHandlerContainer.js","webpack://rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/jsonld-streaming-parser/lib/entryhandler/EntryHandlerInvalidFallback.js","webpack://rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/jsonld-streaming-parser/lib/entryhandler/EntryHandlerPredicate.js","webpack://rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeyword.js","webpack://rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordAnnotation.js","webpack://rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordContext.js","webpack://rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordGraph.js","webpack://rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordId.js","webpack://rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordIncluded.js","webpack://rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordNest.js","webpack://rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordType.js","webpack://rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordUnknownFallback.js","webpack://rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordValue.js","webpack://rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/@rdfjs/parser-jsonld/lib/ParserStream.js","webpack://rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/@rdfjs/parser-jsonld/index.js","webpack://rapid-triples/./node_modules/@zazuko/formats-lazy/node_modules/@rdfjs/sink/index.js","webpack://rapid-triples/./node_modules/duplex-to/readable.js"],"sourcesContent":["var { Buffer } = require('buffer')\n// Named constants with unique integer values\nvar C = {};\n// Tokens\nvar LEFT_BRACE    = C.LEFT_BRACE    = 0x1;\nvar RIGHT_BRACE   = C.RIGHT_BRACE   = 0x2;\nvar LEFT_BRACKET  = C.LEFT_BRACKET  = 0x3;\nvar RIGHT_BRACKET = C.RIGHT_BRACKET = 0x4;\nvar COLON         = C.COLON         = 0x5;\nvar COMMA         = C.COMMA         = 0x6;\nvar TRUE          = C.TRUE          = 0x7;\nvar FALSE         = C.FALSE         = 0x8;\nvar NULL          = C.NULL          = 0x9;\nvar STRING        = C.STRING        = 0xa;\nvar NUMBER        = C.NUMBER        = 0xb;\n// Tokenizer States\nvar START   = C.START   = 0x11;\nvar STOP    = C.STOP    = 0x12;\nvar TRUE1   = C.TRUE1   = 0x21;\nvar TRUE2   = C.TRUE2   = 0x22;\nvar TRUE3   = C.TRUE3   = 0x23;\nvar FALSE1  = C.FALSE1  = 0x31;\nvar FALSE2  = C.FALSE2  = 0x32;\nvar FALSE3  = C.FALSE3  = 0x33;\nvar FALSE4  = C.FALSE4  = 0x34;\nvar NULL1   = C.NULL1   = 0x41;\nvar NULL2   = C.NULL2   = 0x42;\nvar NULL3   = C.NULL3   = 0x43;\nvar NUMBER1 = C.NUMBER1 = 0x51;\nvar NUMBER3 = C.NUMBER3 = 0x53;\nvar STRING1 = C.STRING1 = 0x61;\nvar STRING2 = C.STRING2 = 0x62;\nvar STRING3 = C.STRING3 = 0x63;\nvar STRING4 = C.STRING4 = 0x64;\nvar STRING5 = C.STRING5 = 0x65;\nvar STRING6 = C.STRING6 = 0x66;\n// Parser States\nvar VALUE   = C.VALUE   = 0x71;\nvar KEY     = C.KEY     = 0x72;\n// Parser Modes\nvar OBJECT  = C.OBJECT  = 0x81;\nvar ARRAY   = C.ARRAY   = 0x82;\n// Character constants\nvar BACK_SLASH =      \"\\\\\".charCodeAt(0);\nvar FORWARD_SLASH =   \"\\/\".charCodeAt(0);\nvar BACKSPACE =       \"\\b\".charCodeAt(0);\nvar FORM_FEED =       \"\\f\".charCodeAt(0);\nvar NEWLINE =         \"\\n\".charCodeAt(0);\nvar CARRIAGE_RETURN = \"\\r\".charCodeAt(0);\nvar TAB =             \"\\t\".charCodeAt(0);\n\nvar STRING_BUFFER_SIZE = 64 * 1024;\n\nfunction alloc(size) {\n  return Buffer.alloc ? Buffer.alloc(size) : new Buffer(size);\n}\n\nfunction Parser() {\n  this.tState = START;\n  this.value = undefined;\n\n  this.string = undefined; // string data\n  this.stringBuffer = alloc(STRING_BUFFER_SIZE);\n  this.stringBufferOffset = 0;\n  this.unicode = undefined; // unicode escapes\n  this.highSurrogate = undefined;\n\n  this.key = undefined;\n  this.mode = undefined;\n  this.stack = [];\n  this.state = VALUE;\n  this.bytes_remaining = 0; // number of bytes remaining in multi byte utf8 char to read after split boundary\n  this.bytes_in_sequence = 0; // bytes in multi byte utf8 char to read\n  this.temp_buffs = { \"2\": alloc(2), \"3\": alloc(3), \"4\": alloc(4) }; // for rebuilding chars split before boundary is reached\n\n  // Stream offset\n  this.offset = -1;\n}\n\n// Slow code to string converter (only used when throwing syntax errors)\nParser.toknam = function (code) {\n  var keys = Object.keys(C);\n  for (var i = 0, l = keys.length; i < l; i++) {\n    var key = keys[i];\n    if (C[key] === code) { return key; }\n  }\n  return code && (\"0x\" + code.toString(16));\n};\n\nvar proto = Parser.prototype;\nproto.onError = function (err) { throw err; };\nproto.charError = function (buffer, i) {\n  this.tState = STOP;\n  this.onError(new Error(\"Unexpected \" + JSON.stringify(String.fromCharCode(buffer[i])) + \" at position \" + i + \" in state \" + Parser.toknam(this.tState)));\n};\nproto.appendStringChar = function (char) {\n  if (this.stringBufferOffset >= STRING_BUFFER_SIZE) {\n    this.string += this.stringBuffer.toString('utf8');\n    this.stringBufferOffset = 0;\n  }\n\n  this.stringBuffer[this.stringBufferOffset++] = char;\n};\nproto.appendStringBuf = function (buf, start, end) {\n  var size = buf.length;\n  if (typeof start === 'number') {\n    if (typeof end === 'number') {\n      if (end < 0) {\n        // adding a negative end decreeses the size\n        size = buf.length - start + end;\n      } else {\n        size = end - start;\n      }\n    } else {\n      size = buf.length - start;\n    }\n  }\n\n  if (size < 0) {\n    size = 0;\n  }\n\n  if (this.stringBufferOffset + size > STRING_BUFFER_SIZE) {\n    this.string += this.stringBuffer.toString('utf8', 0, this.stringBufferOffset);\n    this.stringBufferOffset = 0;\n  }\n\n  buf.copy(this.stringBuffer, this.stringBufferOffset, start, end);\n  this.stringBufferOffset += size;\n};\nproto.write = function (buffer) {\n  if (typeof buffer === \"string\") buffer = new Buffer(buffer);\n  var n;\n  for (var i = 0, l = buffer.length; i < l; i++) {\n    if (this.tState === START){\n      n = buffer[i];\n      this.offset++;\n      if(n === 0x7b){ this.onToken(LEFT_BRACE, \"{\"); // {\n      }else if(n === 0x7d){ this.onToken(RIGHT_BRACE, \"}\"); // }\n      }else if(n === 0x5b){ this.onToken(LEFT_BRACKET, \"[\"); // [\n      }else if(n === 0x5d){ this.onToken(RIGHT_BRACKET, \"]\"); // ]\n      }else if(n === 0x3a){ this.onToken(COLON, \":\");  // :\n      }else if(n === 0x2c){ this.onToken(COMMA, \",\"); // ,\n      }else if(n === 0x74){ this.tState = TRUE1;  // t\n      }else if(n === 0x66){ this.tState = FALSE1;  // f\n      }else if(n === 0x6e){ this.tState = NULL1; // n\n      }else if(n === 0x22){ // \"\n        this.string = \"\";\n        this.stringBufferOffset = 0;\n        this.tState = STRING1;\n      }else if(n === 0x2d){ this.string = \"-\"; this.tState = NUMBER1; // -\n      }else{\n        if (n >= 0x30 && n < 0x40) { // 1-9\n          this.string = String.fromCharCode(n); this.tState = NUMBER3;\n        } else if (n === 0x20 || n === 0x09 || n === 0x0a || n === 0x0d) {\n          // whitespace\n        } else {\n          return this.charError(buffer, i);\n        }\n      }\n    }else if (this.tState === STRING1){ // After open quote\n      n = buffer[i]; // get current byte from buffer\n      // check for carry over of a multi byte char split between data chunks\n      // & fill temp buffer it with start of this data chunk up to the boundary limit set in the last iteration\n      if (this.bytes_remaining > 0) {\n        for (var j = 0; j < this.bytes_remaining; j++) {\n          this.temp_buffs[this.bytes_in_sequence][this.bytes_in_sequence - this.bytes_remaining + j] = buffer[j];\n        }\n\n        this.appendStringBuf(this.temp_buffs[this.bytes_in_sequence]);\n        this.bytes_in_sequence = this.bytes_remaining = 0;\n        i = i + j - 1;\n      } else if (this.bytes_remaining === 0 && n >= 128) { // else if no remainder bytes carried over, parse multi byte (>=128) chars one at a time\n        if (n <= 193 || n > 244) {\n          return this.onError(new Error(\"Invalid UTF-8 character at position \" + i + \" in state \" + Parser.toknam(this.tState)));\n        }\n        if ((n >= 194) && (n <= 223)) this.bytes_in_sequence = 2;\n        if ((n >= 224) && (n <= 239)) this.bytes_in_sequence = 3;\n        if ((n >= 240) && (n <= 244)) this.bytes_in_sequence = 4;\n        if ((this.bytes_in_sequence + i) > buffer.length) { // if bytes needed to complete char fall outside buffer length, we have a boundary split\n          for (var k = 0; k <= (buffer.length - 1 - i); k++) {\n            this.temp_buffs[this.bytes_in_sequence][k] = buffer[i + k]; // fill temp buffer of correct size with bytes available in this chunk\n          }\n          this.bytes_remaining = (i + this.bytes_in_sequence) - buffer.length;\n          i = buffer.length - 1;\n        } else {\n          this.appendStringBuf(buffer, i, i + this.bytes_in_sequence);\n          i = i + this.bytes_in_sequence - 1;\n        }\n      } else if (n === 0x22) {\n        this.tState = START;\n        this.string += this.stringBuffer.toString('utf8', 0, this.stringBufferOffset);\n        this.stringBufferOffset = 0;\n        this.onToken(STRING, this.string);\n        this.offset += Buffer.byteLength(this.string, 'utf8') + 1;\n        this.string = undefined;\n      }\n      else if (n === 0x5c) {\n        this.tState = STRING2;\n      }\n      else if (n >= 0x20) { this.appendStringChar(n); }\n      else {\n          return this.charError(buffer, i);\n      }\n    }else if (this.tState === STRING2){ // After backslash\n      n = buffer[i];\n      if(n === 0x22){ this.appendStringChar(n); this.tState = STRING1;\n      }else if(n === 0x5c){ this.appendStringChar(BACK_SLASH); this.tState = STRING1;\n      }else if(n === 0x2f){ this.appendStringChar(FORWARD_SLASH); this.tState = STRING1;\n      }else if(n === 0x62){ this.appendStringChar(BACKSPACE); this.tState = STRING1;\n      }else if(n === 0x66){ this.appendStringChar(FORM_FEED); this.tState = STRING1;\n      }else if(n === 0x6e){ this.appendStringChar(NEWLINE); this.tState = STRING1;\n      }else if(n === 0x72){ this.appendStringChar(CARRIAGE_RETURN); this.tState = STRING1;\n      }else if(n === 0x74){ this.appendStringChar(TAB); this.tState = STRING1;\n      }else if(n === 0x75){ this.unicode = \"\"; this.tState = STRING3;\n      }else{\n        return this.charError(buffer, i);\n      }\n    }else if (this.tState === STRING3 || this.tState === STRING4 || this.tState === STRING5 || this.tState === STRING6){ // unicode hex codes\n      n = buffer[i];\n      // 0-9 A-F a-f\n      if ((n >= 0x30 && n < 0x40) || (n > 0x40 && n <= 0x46) || (n > 0x60 && n <= 0x66)) {\n        this.unicode += String.fromCharCode(n);\n        if (this.tState++ === STRING6) {\n          var intVal = parseInt(this.unicode, 16);\n          this.unicode = undefined;\n          if (this.highSurrogate !== undefined && intVal >= 0xDC00 && intVal < (0xDFFF + 1)) { //<56320,57343> - lowSurrogate\n            this.appendStringBuf(new Buffer(String.fromCharCode(this.highSurrogate, intVal)));\n            this.highSurrogate = undefined;\n          } else if (this.highSurrogate === undefined && intVal >= 0xD800 && intVal < (0xDBFF + 1)) { //<55296,56319> - highSurrogate\n            this.highSurrogate = intVal;\n          } else {\n            if (this.highSurrogate !== undefined) {\n              this.appendStringBuf(new Buffer(String.fromCharCode(this.highSurrogate)));\n              this.highSurrogate = undefined;\n            }\n            this.appendStringBuf(new Buffer(String.fromCharCode(intVal)));\n          }\n          this.tState = STRING1;\n        }\n      } else {\n        return this.charError(buffer, i);\n      }\n    } else if (this.tState === NUMBER1 || this.tState === NUMBER3) {\n        n = buffer[i];\n\n        switch (n) {\n          case 0x30: // 0\n          case 0x31: // 1\n          case 0x32: // 2\n          case 0x33: // 3\n          case 0x34: // 4\n          case 0x35: // 5\n          case 0x36: // 6\n          case 0x37: // 7\n          case 0x38: // 8\n          case 0x39: // 9\n          case 0x2e: // .\n          case 0x65: // e\n          case 0x45: // E\n          case 0x2b: // +\n          case 0x2d: // -\n            this.string += String.fromCharCode(n);\n            this.tState = NUMBER3;\n            break;\n          default:\n            this.tState = START;\n            var error = this.numberReviver(this.string);\n            if (error){\n              return error;\n            }\n\n            this.offset += this.string.length - 1;\n            this.string = undefined;\n            i--;\n            break;\n        }\n    }else if (this.tState === TRUE1){ // r\n      if (buffer[i] === 0x72) { this.tState = TRUE2; }\n      else { return this.charError(buffer, i); }\n    }else if (this.tState === TRUE2){ // u\n      if (buffer[i] === 0x75) { this.tState = TRUE3; }\n      else { return this.charError(buffer, i); }\n    }else if (this.tState === TRUE3){ // e\n      if (buffer[i] === 0x65) { this.tState = START; this.onToken(TRUE, true); this.offset+= 3; }\n      else { return this.charError(buffer, i); }\n    }else if (this.tState === FALSE1){ // a\n      if (buffer[i] === 0x61) { this.tState = FALSE2; }\n      else { return this.charError(buffer, i); }\n    }else if (this.tState === FALSE2){ // l\n      if (buffer[i] === 0x6c) { this.tState = FALSE3; }\n      else { return this.charError(buffer, i); }\n    }else if (this.tState === FALSE3){ // s\n      if (buffer[i] === 0x73) { this.tState = FALSE4; }\n      else { return this.charError(buffer, i); }\n    }else if (this.tState === FALSE4){ // e\n      if (buffer[i] === 0x65) { this.tState = START; this.onToken(FALSE, false); this.offset+= 4; }\n      else { return this.charError(buffer, i); }\n    }else if (this.tState === NULL1){ // u\n      if (buffer[i] === 0x75) { this.tState = NULL2; }\n      else { return this.charError(buffer, i); }\n    }else if (this.tState === NULL2){ // l\n      if (buffer[i] === 0x6c) { this.tState = NULL3; }\n      else { return this.charError(buffer, i); }\n    }else if (this.tState === NULL3){ // l\n      if (buffer[i] === 0x6c) { this.tState = START; this.onToken(NULL, null); this.offset += 3; }\n      else { return this.charError(buffer, i); }\n    }\n  }\n};\nproto.onToken = function (token, value) {\n  // Override this to get events\n};\n\nproto.parseError = function (token, value) {\n  this.tState = STOP;\n  this.onError(new Error(\"Unexpected \" + Parser.toknam(token) + (value ? (\"(\" + JSON.stringify(value) + \")\") : \"\") + \" in state \" + Parser.toknam(this.state)));\n};\nproto.push = function () {\n  this.stack.push({value: this.value, key: this.key, mode: this.mode});\n};\nproto.pop = function () {\n  var value = this.value;\n  var parent = this.stack.pop();\n  this.value = parent.value;\n  this.key = parent.key;\n  this.mode = parent.mode;\n  this.emit(value);\n  if (!this.mode) { this.state = VALUE; }\n};\nproto.emit = function (value) {\n  if (this.mode) { this.state = COMMA; }\n  this.onValue(value);\n};\nproto.onValue = function (value) {\n  // Override me\n};\nproto.onToken = function (token, value) {\n  if(this.state === VALUE){\n    if(token === STRING || token === NUMBER || token === TRUE || token === FALSE || token === NULL){\n      if (this.value) {\n        this.value[this.key] = value;\n      }\n      this.emit(value);\n    }else if(token === LEFT_BRACE){\n      this.push();\n      if (this.value) {\n        this.value = this.value[this.key] = {};\n      } else {\n        this.value = {};\n      }\n      this.key = undefined;\n      this.state = KEY;\n      this.mode = OBJECT;\n    }else if(token === LEFT_BRACKET){\n      this.push();\n      if (this.value) {\n        this.value = this.value[this.key] = [];\n      } else {\n        this.value = [];\n      }\n      this.key = 0;\n      this.mode = ARRAY;\n      this.state = VALUE;\n    }else if(token === RIGHT_BRACE){\n      if (this.mode === OBJECT) {\n        this.pop();\n      } else {\n        return this.parseError(token, value);\n      }\n    }else if(token === RIGHT_BRACKET){\n      if (this.mode === ARRAY) {\n        this.pop();\n      } else {\n        return this.parseError(token, value);\n      }\n    }else{\n      return this.parseError(token, value);\n    }\n  }else if(this.state === KEY){\n    if (token === STRING) {\n      this.key = value;\n      this.state = COLON;\n    } else if (token === RIGHT_BRACE) {\n      this.pop();\n    } else {\n      return this.parseError(token, value);\n    }\n  }else if(this.state === COLON){\n    if (token === COLON) { this.state = VALUE; }\n    else { return this.parseError(token, value); }\n  }else if(this.state === COMMA){\n    if (token === COMMA) {\n      if (this.mode === ARRAY) { this.key++; this.state = VALUE; }\n      else if (this.mode === OBJECT) { this.state = KEY; }\n\n    } else if (token === RIGHT_BRACKET && this.mode === ARRAY || token === RIGHT_BRACE && this.mode === OBJECT) {\n      this.pop();\n    } else {\n      return this.parseError(token, value);\n    }\n  }else{\n    return this.parseError(token, value);\n  }\n};\n\n// Override to implement your own number reviver.\n// Any value returned is treated as error and will interrupt parsing.\nproto.numberReviver = function (text) {\n  var result = Number(text);\n\n  if (isNaN(result)) {\n    return this.charError(buffer, i);\n  }\n\n  if ((text.match(/[0-9]+/) == text) && (result.toString() != text)) {\n    // Long string of digits which is an ID string and not valid and/or safe JavaScript integer Number\n    this.onToken(STRING, text);\n  } else {\n    this.onToken(NUMBER, result);\n  }\n}\n\nParser.C = C;\n\nmodule.exports = Parser;\n","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __exportStar = (this && this.__exportStar) || function(m, exports) {\n    for (var p in m) if (p !== \"default\" && !Object.prototype.hasOwnProperty.call(exports, p)) __createBinding(exports, m, p);\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\n__exportStar(require(\"./lib/JsonLdParser\"), exports);\n//# sourceMappingURL=index.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ContextTree = void 0;\n/**\n * A tree structure that holds all contexts,\n * based on their position in the JSON object.\n *\n * Positions are identified by a path of keys.\n */\nclass ContextTree {\n    constructor() {\n        this.subTrees = {};\n    }\n    getContext(keys) {\n        if (keys.length > 0) {\n            const [head, ...tail] = keys;\n            const subTree = this.subTrees[head];\n            if (subTree) {\n                const subContext = subTree.getContext(tail);\n                if (subContext) {\n                    return subContext.then(({ context, depth }) => ({ context, depth: depth + 1 }));\n                }\n            }\n        }\n        return this.context ? this.context.then((context) => ({ context, depth: 0 })) : null;\n    }\n    setContext(keys, context) {\n        if (keys.length === 0) {\n            this.context = context;\n        }\n        else {\n            const [head, ...tail] = keys;\n            let subTree = this.subTrees[head];\n            if (!subTree) {\n                subTree = this.subTrees[head] = new ContextTree();\n            }\n            subTree.setContext(tail, context);\n        }\n    }\n    removeContext(path) {\n        this.setContext(path, null);\n    }\n}\nexports.ContextTree = ContextTree;\n//# sourceMappingURL=ContextTree.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.JsonLdParser = void 0;\n// tslint:disable-next-line:no-var-requires\nconst Parser = require('@bergos/jsonparse');\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\nconst readable_stream_1 = require(\"readable-stream\");\nconst EntryHandlerArrayValue_1 = require(\"./entryhandler/EntryHandlerArrayValue\");\nconst EntryHandlerContainer_1 = require(\"./entryhandler/EntryHandlerContainer\");\nconst EntryHandlerInvalidFallback_1 = require(\"./entryhandler/EntryHandlerInvalidFallback\");\nconst EntryHandlerPredicate_1 = require(\"./entryhandler/EntryHandlerPredicate\");\nconst EntryHandlerKeywordContext_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordContext\");\nconst EntryHandlerKeywordGraph_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordGraph\");\nconst EntryHandlerKeywordId_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordId\");\nconst EntryHandlerKeywordIncluded_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordIncluded\");\nconst EntryHandlerKeywordNest_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordNest\");\nconst EntryHandlerKeywordType_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordType\");\nconst EntryHandlerKeywordUnknownFallback_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordUnknownFallback\");\nconst EntryHandlerKeywordValue_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordValue\");\nconst ParsingContext_1 = require(\"./ParsingContext\");\nconst Util_1 = require(\"./Util\");\nconst http_link_header_1 = require(\"http-link-header\");\nconst EntryHandlerKeywordAnnotation_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordAnnotation\");\n/**\n * A stream transformer that parses JSON-LD (text) streams to an {@link RDF.Stream}.\n */\nclass JsonLdParser extends readable_stream_1.Transform {\n    constructor(options) {\n        super({ readableObjectMode: true });\n        options = options || {};\n        this.options = options;\n        this.parsingContext = new ParsingContext_1.ParsingContext(Object.assign({ parser: this }, options));\n        this.util = new Util_1.Util({ dataFactory: options.dataFactory, parsingContext: this.parsingContext });\n        this.jsonParser = new Parser();\n        this.contextJobs = [];\n        this.typeJobs = [];\n        this.contextAwaitingJobs = [];\n        this.lastDepth = 0;\n        this.lastKeys = [];\n        this.lastOnValueJob = Promise.resolve();\n        this.attachJsonParserListeners();\n        this.on('end', () => {\n            if (typeof this.jsonParser.mode !== 'undefined') {\n                this.emit('error', new Error('Unclosed document'));\n            }\n        });\n    }\n    /**\n     * Construct a JsonLdParser from the given HTTP response.\n     *\n     * This will throw an error if no valid JSON response is received\n     * (application/ld+json, application/json, or something+json).\n     *\n     * For raw JSON responses, exactly one link header pointing to a JSON-LD context is required.\n     *\n     * This method is not responsible for handling redirects.\n     *\n     * @param baseIRI The URI of the received response.\n     * @param mediaType The received content type.\n     * @param headers Optional HTTP headers.\n     * @param options Optional parser options.\n     */\n    static fromHttpResponse(baseIRI, mediaType, headers, options) {\n        let context;\n        let wellKnownMediaTypes = ['application/activity+json'];\n        if (options && options.wellKnownMediaTypes) {\n            wellKnownMediaTypes = options.wellKnownMediaTypes;\n        }\n        // Special cases when receiving something else than the JSON-LD media type or the wellKnownMediaTypes\n        if (mediaType !== 'application/ld+json' && !wellKnownMediaTypes.includes(mediaType)) {\n            // Only accept JSON or JSON extension types\n            if (mediaType !== 'application/json' && !mediaType.endsWith('+json')) {\n                throw new jsonld_context_parser_1.ErrorCoded(`Unsupported JSON-LD media type ${mediaType}`, jsonld_context_parser_1.ERROR_CODES.LOADING_DOCUMENT_FAILED);\n            }\n            // We need exactly one JSON-LD context in the link header\n            if (headers && headers.has('Link')) {\n                headers.forEach((value, key) => {\n                    if (key === 'link') {\n                        const linkHeader = (0, http_link_header_1.parse)(value);\n                        for (const link of linkHeader.get('rel', 'http://www.w3.org/ns/json-ld#context')) {\n                            if (context) {\n                                throw new jsonld_context_parser_1.ErrorCoded('Multiple JSON-LD context link headers were found on ' + baseIRI, jsonld_context_parser_1.ERROR_CODES.MULTIPLE_CONTEXT_LINK_HEADERS);\n                            }\n                            context = link.uri;\n                        }\n                    }\n                });\n            }\n            if (!context && !(options === null || options === void 0 ? void 0 : options.ignoreMissingContextLinkHeader)) {\n                throw new jsonld_context_parser_1.ErrorCoded(`Missing context link header for media type ${mediaType} on ${baseIRI}`, jsonld_context_parser_1.ERROR_CODES.LOADING_DOCUMENT_FAILED);\n            }\n        }\n        // Check if the streaming profile is present\n        let streamingProfile;\n        if (headers && headers.has('Content-Type')) {\n            const contentType = headers.get('Content-Type');\n            const match = /; *profile=([^\"]*)/.exec(contentType);\n            if (match && match[1] === 'http://www.w3.org/ns/json-ld#streaming') {\n                streamingProfile = true;\n            }\n        }\n        return new JsonLdParser(Object.assign({ baseIRI,\n            context,\n            streamingProfile }, options ? options : {}));\n    }\n    /**\n     * Parses the given text stream into a quad stream.\n     * @param {NodeJS.EventEmitter} stream A text stream.\n     * @return {RDF.Stream} A quad stream.\n     */\n    import(stream) {\n        if ('pipe' in stream) {\n            stream.on('error', (error) => parsed.emit('error', error));\n            const parsed = stream.pipe(new JsonLdParser(this.options));\n            return parsed;\n        }\n        else {\n            const output = new readable_stream_1.PassThrough({ readableObjectMode: true });\n            stream.on('error', (error) => parsed.emit('error', error));\n            stream.on('data', (data) => output.push(data));\n            stream.on('end', () => output.push(null));\n            const parsed = output.pipe(new JsonLdParser(this.options));\n            return parsed;\n        }\n    }\n    _transform(chunk, encoding, callback) {\n        this.jsonParser.write(chunk);\n        this.lastOnValueJob\n            .then(() => callback(), (error) => callback(error));\n    }\n    /**\n     * Start a new job for parsing the given value.\n     *\n     * This will let the first valid {@link IEntryHandler} handle the entry.\n     *\n     * @param {any[]} keys The stack of keys.\n     * @param value The value to parse.\n     * @param {number} depth The depth to parse at.\n     * @param {boolean} lastDepthCheck If the lastDepth check should be done for buffer draining.\n     * @return {Promise<void>} A promise resolving when the job is done.\n     */\n    async newOnValueJob(keys, value, depth, lastDepthCheck) {\n        let flushStacks = true;\n        // When we go up the stack, emit all unidentified values\n        // We need to do this before the new job, because the new job may require determined values from the flushed jobs.\n        if (lastDepthCheck && depth < this.lastDepth) {\n            // Check if we had any RDF lists that need to be terminated with an rdf:nil\n            const listPointer = this.parsingContext.listPointerStack[this.lastDepth];\n            if (listPointer) {\n                // Terminate the list if the had at least one value\n                if (listPointer.value) {\n                    this.push(this.util.dataFactory.quad(listPointer.value, this.util.rdfRest, this.util.rdfNil, this.util.getDefaultGraph()));\n                }\n                // Add the list id to the id stack, so it can be used higher up in the stack\n                listPointer.listId.listHead = true;\n                this.parsingContext.idStack[listPointer.listRootDepth + 1] = [listPointer.listId];\n                this.parsingContext.listPointerStack.splice(this.lastDepth, 1);\n            }\n            // Flush the buffer for lastDepth\n            // If the parent key is a special type of container, postpone flushing until that parent is handled.\n            if (await EntryHandlerContainer_1.EntryHandlerContainer.isBufferableContainerHandler(this.parsingContext, this.lastKeys, this.lastDepth)) {\n                this.parsingContext.pendingContainerFlushBuffers\n                    .push({ depth: this.lastDepth, keys: this.lastKeys.slice(0, this.lastKeys.length) });\n                flushStacks = false;\n            }\n            else {\n                await this.flushBuffer(this.lastDepth, this.lastKeys);\n            }\n        }\n        const key = await this.util.unaliasKeyword(keys[depth], keys, depth);\n        const parentKey = await this.util.unaliasKeywordParent(keys, depth);\n        this.parsingContext.emittedStack[depth] = true;\n        let handleKey = true;\n        // Keywords inside @reverse is not allowed apart from @context\n        if (jsonld_context_parser_1.Util.isValidKeyword(key) && parentKey === '@reverse' && key !== '@context') {\n            this.emit('error', new jsonld_context_parser_1.ErrorCoded(`Found the @id '${value}' inside an @reverse property`, jsonld_context_parser_1.ERROR_CODES.INVALID_REVERSE_PROPERTY_MAP));\n        }\n        // Skip further processing if one of the parent nodes are invalid.\n        // We use the validationStack to reuse validation results that were produced before with common key stacks.\n        let inProperty = false;\n        if (this.parsingContext.validationStack.length > 1) {\n            inProperty = this.parsingContext.validationStack[this.parsingContext.validationStack.length - 1].property;\n        }\n        for (let i = Math.max(1, this.parsingContext.validationStack.length - 1); i < keys.length - 1; i++) {\n            const validationResult = this.parsingContext.validationStack[i]\n                || (this.parsingContext.validationStack[i] = await this.validateKey(keys.slice(0, i + 1), i, inProperty));\n            if (!validationResult.valid) {\n                this.parsingContext.emittedStack[depth] = false;\n                handleKey = false;\n                break;\n            }\n            else if (!inProperty && validationResult.property) {\n                inProperty = true;\n            }\n        }\n        // Skip further processing if this node is part of a literal\n        if (await this.util.isLiteral(keys, depth)) {\n            handleKey = false;\n        }\n        // Get handler\n        if (handleKey) {\n            for (const entryHandler of JsonLdParser.ENTRY_HANDLERS) {\n                const testResult = await entryHandler.test(this.parsingContext, this.util, key, keys, depth);\n                if (testResult) {\n                    // Pass processing over to the handler\n                    await entryHandler.handle(this.parsingContext, this.util, key, keys, value, depth, testResult);\n                    // Flag that this depth is processed\n                    if (entryHandler.isStackProcessor()) {\n                        this.parsingContext.processingStack[depth] = true;\n                    }\n                    break;\n                }\n            }\n        }\n        // Validate value indexes on the root.\n        if (depth === 0 && Array.isArray(value)) {\n            await this.util.validateValueIndexes(value);\n        }\n        // When we go up the stack, flush the old stack\n        if (flushStacks && depth < this.lastDepth) {\n            // Reset our stacks\n            this.flushStacks(this.lastDepth);\n        }\n        this.lastDepth = depth;\n        this.lastKeys = keys;\n        // Clear the keyword cache at this depth, and everything underneath.\n        this.parsingContext.unaliasedKeywordCacheStack.splice(depth - 1);\n    }\n    /**\n     * Flush the processing stacks at the given depth.\n     * @param {number} depth A depth.\n     */\n    flushStacks(depth) {\n        this.parsingContext.processingStack.splice(depth, 1);\n        this.parsingContext.processingType.splice(depth, 1);\n        this.parsingContext.emittedStack.splice(depth, 1);\n        this.parsingContext.idStack.splice(depth, 1);\n        this.parsingContext.graphStack.splice(depth + 1, 1);\n        this.parsingContext.graphContainerTermStack.splice(depth, 1);\n        this.parsingContext.jsonLiteralStack.splice(depth, 1);\n        this.parsingContext.validationStack.splice(depth - 1, 2);\n        this.parsingContext.literalStack.splice(depth, this.parsingContext.literalStack.length - depth);\n        this.parsingContext.annotationsBuffer.splice(depth, 1);\n        // TODO: just like the literal stack, splice all other stack until the end as well?\n    }\n    /**\n     * Flush buffers for the given depth.\n     *\n     * This should be called after the last entry at a given depth was processed.\n     *\n     * @param {number} depth A depth.\n     * @param {any[]} keys A stack of keys.\n     * @return {Promise<void>} A promise resolving if flushing is done.\n     */\n    async flushBuffer(depth, keys) {\n        let subjects = this.parsingContext.idStack[depth];\n        const subjectsWasDefined = !!subjects;\n        if (!subjectsWasDefined) {\n            subjects = this.parsingContext.idStack[depth] = [this.util.dataFactory.blankNode()];\n        }\n        // Flush values at this level\n        const valueBuffer = this.parsingContext.unidentifiedValuesBuffer[depth];\n        if (valueBuffer) {\n            for (const subject of subjects) {\n                const depthOffsetGraph = await this.util.getDepthOffsetGraph(depth, keys);\n                const graphs = (this.parsingContext.graphStack[depth] || depthOffsetGraph >= 0)\n                    ? this.parsingContext.idStack[depth - depthOffsetGraph - 1]\n                    : [await this.util.getGraphContainerValue(keys, depth)];\n                if (graphs) {\n                    for (const graph of graphs) {\n                        // Flush values to stream if the graph @id is known\n                        this.parsingContext.emittedStack[depth] = true;\n                        for (const bufferedValue of valueBuffer) {\n                            this.util.emitQuadChecked(depth, subject, bufferedValue.predicate, bufferedValue.object, graph, bufferedValue.reverse, bufferedValue.isEmbedded);\n                        }\n                    }\n                }\n                else {\n                    // Place the values in the graphs buffer if the graph @id is not yet known\n                    const subGraphBuffer = this.parsingContext.getUnidentifiedGraphBufferSafe(depth - await this.util.getDepthOffsetGraph(depth, keys) - 1);\n                    for (const bufferedValue of valueBuffer) {\n                        if (bufferedValue.reverse) {\n                            subGraphBuffer.push({\n                                object: subject,\n                                predicate: bufferedValue.predicate,\n                                subject: bufferedValue.object,\n                                isEmbedded: bufferedValue.isEmbedded,\n                            });\n                        }\n                        else {\n                            subGraphBuffer.push({\n                                object: bufferedValue.object,\n                                predicate: bufferedValue.predicate,\n                                subject,\n                                isEmbedded: bufferedValue.isEmbedded,\n                            });\n                        }\n                    }\n                }\n            }\n            this.parsingContext.unidentifiedValuesBuffer.splice(depth, 1);\n            this.parsingContext.literalStack.splice(depth, 1);\n            this.parsingContext.jsonLiteralStack.splice(depth, 1);\n        }\n        // Flush graphs at this level\n        const graphBuffer = this.parsingContext.unidentifiedGraphsBuffer[depth];\n        if (graphBuffer) {\n            for (const subject of subjects) {\n                // A @graph statement at the root without @id relates to the default graph,\n                // unless there are top-level properties,\n                // others relate to blank nodes.\n                const graph = depth === 1 && subject.termType === 'BlankNode'\n                    && !this.parsingContext.topLevelProperties ? this.util.getDefaultGraph() : subject;\n                this.parsingContext.emittedStack[depth] = true;\n                for (const bufferedValue of graphBuffer) {\n                    this.parsingContext.emitQuad(depth, this.util.dataFactory.quad(bufferedValue.subject, bufferedValue.predicate, bufferedValue.object, graph));\n                }\n            }\n            this.parsingContext.unidentifiedGraphsBuffer.splice(depth, 1);\n        }\n        // Push unhandled annotations up the stack as nested annotations\n        const annotationsBuffer = this.parsingContext.annotationsBuffer[depth];\n        if (annotationsBuffer) {\n            // Throw an error if we reach the top, and still have annotations\n            if (annotationsBuffer.length > 0 && depth === 1) {\n                this.parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Annotations can not be made on top-level nodes`, jsonld_context_parser_1.ERROR_CODES.INVALID_ANNOTATION));\n            }\n            // Pass the annotations buffer up one level in the stack\n            const annotationsBufferParent = this.parsingContext.getAnnotationsBufferSafe(depth - 1);\n            for (const annotation of annotationsBuffer) {\n                annotationsBufferParent.push(annotation);\n            }\n            delete this.parsingContext.annotationsBuffer[depth];\n        }\n    }\n    /**\n     * Check if at least one {@link IEntryHandler} validates the entry to true.\n     * @param {any[]} keys A stack of keys.\n     * @param {number} depth A depth.\n     * @param {boolean} inProperty If the current depth is part of a valid property node.\n     * @return {Promise<{ valid: boolean, property: boolean }>} A promise resolving to true or false.\n     */\n    async validateKey(keys, depth, inProperty) {\n        for (const entryHandler of JsonLdParser.ENTRY_HANDLERS) {\n            if (await entryHandler.validate(this.parsingContext, this.util, keys, depth, inProperty)) {\n                return { valid: true, property: inProperty || entryHandler.isPropertyHandler() };\n            }\n        }\n        return { valid: false, property: false };\n    }\n    /**\n     * Attach all required listeners to the JSON parser.\n     *\n     * This should only be called once.\n     */\n    attachJsonParserListeners() {\n        // Listen to json parser events\n        this.jsonParser.onValue = (value) => {\n            const depth = this.jsonParser.stack.length;\n            const keys = (new Array(depth + 1).fill(0)).map((v, i) => {\n                return i === depth ? this.jsonParser.key : this.jsonParser.stack[i].key;\n            });\n            if (!this.isParsingContextInner(depth)) { // Don't parse inner nodes inside @context\n                const valueJobCb = () => this.newOnValueJob(keys, value, depth, true);\n                if (!this.parsingContext.streamingProfile\n                    && !this.parsingContext.contextTree.getContext(keys.slice(0, -1))) {\n                    // If an out-of-order context is allowed,\n                    // we have to buffer everything.\n                    // We store jobs for @context's and @type's separately,\n                    // because at the end, we have to process them first.\n                    // We also handle @type because these *could* introduce a type-scoped context.\n                    if (keys[depth] === '@context') {\n                        let jobs = this.contextJobs[depth];\n                        if (!jobs) {\n                            jobs = this.contextJobs[depth] = [];\n                        }\n                        jobs.push(valueJobCb);\n                    }\n                    else {\n                        this.contextAwaitingJobs.push({ job: valueJobCb, keys, depth });\n                    }\n                }\n                else {\n                    // Make sure that our value jobs are chained synchronously\n                    this.lastOnValueJob = this.lastOnValueJob.then(valueJobCb);\n                }\n                // Execute all buffered jobs on deeper levels\n                if (!this.parsingContext.streamingProfile && depth === 0) {\n                    this.lastOnValueJob = this.lastOnValueJob\n                        .then(() => this.executeBufferedJobs());\n                }\n            }\n        };\n        this.jsonParser.onError = (error) => {\n            this.emit('error', error);\n        };\n    }\n    /**\n     * Check if the parser is currently parsing an element that is part of an @context entry.\n     * @param {number} depth A depth.\n     * @return {boolean} A boolean.\n     */\n    isParsingContextInner(depth) {\n        for (let i = depth; i > 0; i--) {\n            if (this.jsonParser.stack[i - 1].key === '@context') {\n                return true;\n            }\n        }\n        return false;\n    }\n    /**\n     * Execute all buffered jobs.\n     * @return {Promise<void>} A promise resolving if all jobs are finished.\n     */\n    async executeBufferedJobs() {\n        // Handle context jobs\n        for (const jobs of this.contextJobs) {\n            if (jobs) {\n                for (const job of jobs) {\n                    await job();\n                }\n            }\n        }\n        // Clear the keyword cache.\n        this.parsingContext.unaliasedKeywordCacheStack.splice(0);\n        const contextAwaitingJobs = [];\n        for (const job of this.contextAwaitingJobs) {\n            if ((await this.util.unaliasKeyword(job.keys[job.depth], job.keys, job.depth, true)) === '@type'\n                || typeof job.keys[job.depth] === 'number' && (await this.util.unaliasKeyword(job.keys[job.depth - 1], job.keys, job.depth - 1, true)) === '@type') { // Also capture @type with array values\n                // Remove @type from keys, because we want it to apply to parent later on\n                this.typeJobs.push({ job: job.job, keys: job.keys.slice(0, job.keys.length - 1) });\n            }\n            else {\n                contextAwaitingJobs.push(job);\n            }\n        }\n        // Handle non-context jobs\n        for (const job of contextAwaitingJobs) {\n            // Check if we have a type (with possible type-scoped context) that should be handled before.\n            // We check all possible parent nodes for the current job, from root to leaves.\n            if (this.typeJobs.length > 0) {\n                // First collect all applicable type jobs\n                const applicableTypeJobs = [];\n                const applicableTypeJobIds = [];\n                for (let i = 0; i < this.typeJobs.length; i++) {\n                    const typeJob = this.typeJobs[i];\n                    if (Util_1.Util.isPrefixArray(typeJob.keys, job.keys)) {\n                        applicableTypeJobs.push(typeJob);\n                        applicableTypeJobIds.push(i);\n                    }\n                }\n                // Next, sort the jobs from short to long key length (to ensure types higher up in the tree to be handled first)\n                const sortedTypeJobs = applicableTypeJobs.sort((job1, job2) => job1.keys.length - job2.keys.length);\n                // Finally, execute the jobs in order\n                for (const typeJob of sortedTypeJobs) {\n                    await typeJob.job();\n                }\n                // Remove the executed type jobs\n                // Sort first, so we can efficiently splice\n                const sortedApplicableTypeJobIds = applicableTypeJobIds.sort().reverse();\n                for (const jobId of sortedApplicableTypeJobIds) {\n                    this.typeJobs.splice(jobId, 1);\n                }\n            }\n            await job.job();\n        }\n    }\n}\nJsonLdParser.DEFAULT_PROCESSING_MODE = '1.1';\nJsonLdParser.ENTRY_HANDLERS = [\n    new EntryHandlerArrayValue_1.EntryHandlerArrayValue(),\n    new EntryHandlerKeywordContext_1.EntryHandlerKeywordContext(),\n    new EntryHandlerKeywordId_1.EntryHandlerKeywordId(),\n    new EntryHandlerKeywordIncluded_1.EntryHandlerKeywordIncluded(),\n    new EntryHandlerKeywordGraph_1.EntryHandlerKeywordGraph(),\n    new EntryHandlerKeywordNest_1.EntryHandlerKeywordNest(),\n    new EntryHandlerKeywordType_1.EntryHandlerKeywordType(),\n    new EntryHandlerKeywordValue_1.EntryHandlerKeywordValue(),\n    new EntryHandlerKeywordAnnotation_1.EntryHandlerKeywordAnnotation(),\n    new EntryHandlerContainer_1.EntryHandlerContainer(),\n    new EntryHandlerKeywordUnknownFallback_1.EntryHandlerKeywordUnknownFallback(),\n    new EntryHandlerPredicate_1.EntryHandlerPredicate(),\n    new EntryHandlerInvalidFallback_1.EntryHandlerInvalidFallback(),\n];\nexports.JsonLdParser = JsonLdParser;\n//# sourceMappingURL=JsonLdParser.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ParsingContext = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\nconst ErrorCoded_1 = require(\"jsonld-context-parser/lib/ErrorCoded\");\nconst ContextTree_1 = require(\"./ContextTree\");\nconst JsonLdParser_1 = require(\"./JsonLdParser\");\n/**\n * Data holder for parsing information.\n */\nclass ParsingContext {\n    constructor(options) {\n        // Initialize settings\n        this.contextParser = new jsonld_context_parser_1.ContextParser({ documentLoader: options.documentLoader, skipValidation: options.skipContextValidation });\n        this.streamingProfile = !!options.streamingProfile;\n        this.baseIRI = options.baseIRI;\n        this.produceGeneralizedRdf = !!options.produceGeneralizedRdf;\n        this.allowSubjectList = !!options.allowSubjectList;\n        this.processingMode = options.processingMode || JsonLdParser_1.JsonLdParser.DEFAULT_PROCESSING_MODE;\n        this.strictValues = !!options.strictValues;\n        this.validateValueIndexes = !!options.validateValueIndexes;\n        this.defaultGraph = options.defaultGraph;\n        this.rdfDirection = options.rdfDirection;\n        this.normalizeLanguageTags = options.normalizeLanguageTags;\n        this.streamingProfileAllowOutOfOrderPlainType = options.streamingProfileAllowOutOfOrderPlainType;\n        this.rdfstar = options.rdfstar !== false;\n        this.rdfstarReverseInEmbedded = options.rdfstarReverseInEmbedded;\n        this.topLevelProperties = false;\n        this.activeProcessingMode = parseFloat(this.processingMode);\n        // Initialize stacks\n        this.processingStack = [];\n        this.processingType = [];\n        this.emittedStack = [];\n        this.idStack = [];\n        this.graphStack = [];\n        this.graphContainerTermStack = [];\n        this.listPointerStack = [];\n        this.contextTree = new ContextTree_1.ContextTree();\n        this.literalStack = [];\n        this.validationStack = [];\n        this.unaliasedKeywordCacheStack = [];\n        this.jsonLiteralStack = [];\n        this.unidentifiedValuesBuffer = [];\n        this.unidentifiedGraphsBuffer = [];\n        this.annotationsBuffer = [];\n        this.pendingContainerFlushBuffers = [];\n        this.parser = options.parser;\n        if (options.context) {\n            this.rootContext = this.parseContext(options.context);\n            this.rootContext.then((context) => this.validateContext(context));\n        }\n        else {\n            this.rootContext = Promise.resolve(new jsonld_context_parser_1.JsonLdContextNormalized(this.baseIRI ? { '@base': this.baseIRI, '@__baseDocument': true } : {}));\n        }\n    }\n    /**\n     * Parse the given context with the configured options.\n     * @param {JsonLdContext} context A context to parse.\n     * @param {JsonLdContextNormalized} parentContext An optional parent context.\n     * @param {boolean} ignoreProtection If @protected term checks should be ignored.\n     * @return {Promise<JsonLdContextNormalized>} A promise resolving to the parsed context.\n     */\n    async parseContext(context, parentContext, ignoreProtection) {\n        return this.contextParser.parse(context, {\n            baseIRI: this.baseIRI,\n            ignoreProtection,\n            normalizeLanguageTags: this.normalizeLanguageTags,\n            parentContext,\n            processingMode: this.activeProcessingMode,\n        });\n    }\n    /**\n     * Check if the given context is valid.\n     * If not, an error will be thrown.\n     * @param {JsonLdContextNormalized} context A context.\n     */\n    validateContext(context) {\n        const activeVersion = context.getContextRaw()['@version'];\n        if (activeVersion) {\n            if (this.activeProcessingMode && activeVersion > this.activeProcessingMode) {\n                throw new ErrorCoded_1.ErrorCoded(`Unsupported JSON-LD version '${activeVersion}' under active processing mode ${this.activeProcessingMode}.`, ErrorCoded_1.ERROR_CODES.PROCESSING_MODE_CONFLICT);\n            }\n            else {\n                if (this.activeProcessingMode && activeVersion < this.activeProcessingMode) {\n                    throw new ErrorCoded_1.ErrorCoded(`Invalid JSON-LD version ${activeVersion} under active processing mode ${this.activeProcessingMode}.`, ErrorCoded_1.ERROR_CODES.INVALID_VERSION_VALUE);\n                }\n                this.activeProcessingMode = activeVersion;\n            }\n        }\n    }\n    /**\n     * Get the context at the given path.\n     * @param {keys} keys The path of keys to get the context at.\n     * @param {number} offset The path offset, defaults to 1.\n     * @return {Promise<JsonLdContextNormalized>} A promise resolving to a context.\n     */\n    async getContext(keys, offset = 1) {\n        const keysOriginal = keys;\n        // Ignore array keys at the end\n        while (typeof keys[keys.length - 1] === 'number') {\n            keys = keys.slice(0, keys.length - 1);\n        }\n        // Handle offset on keys\n        if (offset) {\n            keys = keys.slice(0, -offset);\n        }\n        // Determine the closest context\n        const contextData = await this.getContextPropagationAware(keys);\n        const context = contextData.context;\n        // Process property-scoped contexts (high-to-low)\n        let contextRaw = context.getContextRaw();\n        for (let i = contextData.depth; i < keysOriginal.length - offset; i++) {\n            const key = keysOriginal[i];\n            const contextKeyEntry = contextRaw[key];\n            if (contextKeyEntry && typeof contextKeyEntry === 'object' && '@context' in contextKeyEntry) {\n                const scopedContext = (await this.parseContext(contextKeyEntry, contextRaw, true)).getContextRaw();\n                const propagate = !(key in scopedContext)\n                    || scopedContext[key]['@context']['@propagate']; // Propagation is true by default\n                if (propagate !== false || i === keysOriginal.length - 1 - offset) {\n                    contextRaw = Object.assign({}, scopedContext);\n                    // Clean up final context\n                    delete contextRaw['@propagate'];\n                    contextRaw[key] = Object.assign({}, contextRaw[key]);\n                    if ('@id' in contextKeyEntry) {\n                        contextRaw[key]['@id'] = contextKeyEntry['@id'];\n                    }\n                    delete contextRaw[key]['@context'];\n                    if (propagate !== false) {\n                        this.contextTree.setContext(keysOriginal.slice(0, i + offset), Promise.resolve(new jsonld_context_parser_1.JsonLdContextNormalized(contextRaw)));\n                    }\n                }\n            }\n        }\n        return new jsonld_context_parser_1.JsonLdContextNormalized(contextRaw);\n    }\n    /**\n     * Get the context at the given path.\n     * Non-propagating contexts will be skipped,\n     * unless the context at that exact depth is retrieved.\n     *\n     * This ONLY takes into account context propagation logic,\n     * so this should usually not be called directly,\n     * call {@link #getContext} instead.\n     *\n     * @param keys The path of keys to get the context at.\n     * @return {Promise<{ context: JsonLdContextNormalized, depth: number }>} A context and its depth.\n     */\n    async getContextPropagationAware(keys) {\n        const originalDepth = keys.length;\n        let contextData = null;\n        let hasApplicablePropertyScopedContext;\n        do {\n            hasApplicablePropertyScopedContext = false;\n            if (contextData && '@__propagateFallback' in contextData.context.getContextRaw()) {\n                // If a propagation fallback context has been set,\n                // fallback to that context and retry for the same depth.\n                contextData.context = new jsonld_context_parser_1.JsonLdContextNormalized(contextData.context.getContextRaw()['@__propagateFallback']);\n            }\n            else {\n                if (contextData) {\n                    // If we had a previous iteration, jump to the parent of context depth.\n                    // We must do this because once we get here, last context had propagation disabled,\n                    // so we check its first parent instead.\n                    keys = keys.slice(0, contextData.depth - 1);\n                }\n                contextData = await this.contextTree.getContext(keys) || { context: await this.rootContext, depth: 0 };\n            }\n            // Allow non-propagating contexts to propagate one level deeper\n            // if it defines a property-scoped context that is applicable for the current key.\n            // @see https://w3c.github.io/json-ld-api/tests/toRdf-manifest#tc012\n            const lastKey = keys[keys.length - 1];\n            if (lastKey in contextData.context.getContextRaw()) {\n                const lastKeyValue = contextData.context.getContextRaw()[lastKey];\n                if (lastKeyValue && typeof lastKeyValue === 'object' && '@context' in lastKeyValue) {\n                    hasApplicablePropertyScopedContext = true;\n                }\n            }\n        } while (contextData.depth > 0 // Root context has a special case\n            && contextData.context.getContextRaw()['@propagate'] === false // Stop loop if propagation is true\n            && contextData.depth !== originalDepth // Stop loop if requesting exact depth of non-propagating\n            && !hasApplicablePropertyScopedContext);\n        // Special case for root context that does not allow propagation.\n        // Fallback to empty context in that case.\n        if (contextData.depth === 0\n            && contextData.context.getContextRaw()['@propagate'] === false\n            && contextData.depth !== originalDepth) {\n            contextData.context = new jsonld_context_parser_1.JsonLdContextNormalized({});\n        }\n        return contextData;\n    }\n    /**\n     * Start a new job for parsing the given value.\n     * @param {any[]} keys The stack of keys.\n     * @param value The value to parse.\n     * @param {number} depth The depth to parse at.\n     * @param {boolean} lastDepthCheck If the lastDepth check should be done for buffer draining.\n     * @return {Promise<void>} A promise resolving when the job is done.\n     */\n    async newOnValueJob(keys, value, depth, lastDepthCheck) {\n        await this.parser.newOnValueJob(keys, value, depth, lastDepthCheck);\n    }\n    /**\n     * Flush the pending container flush buffers\n     * @return {boolean} If any pending buffers were flushed.\n     */\n    async handlePendingContainerFlushBuffers() {\n        if (this.pendingContainerFlushBuffers.length > 0) {\n            for (const pendingFlushBuffer of this.pendingContainerFlushBuffers) {\n                await this.parser.flushBuffer(pendingFlushBuffer.depth, pendingFlushBuffer.keys);\n                this.parser.flushStacks(pendingFlushBuffer.depth);\n            }\n            this.pendingContainerFlushBuffers.splice(0, this.pendingContainerFlushBuffers.length);\n            return true;\n        }\n        else {\n            return false;\n        }\n    }\n    /**\n     * Emit the given quad into the output stream.\n     * @param {number} depth The depth the quad was generated at.\n     * @param {Quad} quad A quad to emit.\n     */\n    emitQuad(depth, quad) {\n        if (depth === 1) {\n            this.topLevelProperties = true;\n        }\n        this.parser.push(quad);\n    }\n    /**\n     * Emit the given error into the output stream.\n     * @param {Error} error An error to emit.\n     */\n    emitError(error) {\n        this.parser.emit('error', error);\n    }\n    /**\n     * Emit the given context into the output stream under the 'context' event.\n     * @param {JsonLdContext} context A context to emit.\n     */\n    emitContext(context) {\n        this.parser.emit('context', context);\n    }\n    /**\n     * Safely get or create the depth value of {@link ParsingContext.unidentifiedValuesBuffer}.\n     * @param {number} depth A depth.\n     * @return {{predicate: Term; object: Term; reverse: boolean}[]} An element of\n     *                                                               {@link ParsingContext.unidentifiedValuesBuffer}.\n     */\n    getUnidentifiedValueBufferSafe(depth) {\n        let buffer = this.unidentifiedValuesBuffer[depth];\n        if (!buffer) {\n            buffer = [];\n            this.unidentifiedValuesBuffer[depth] = buffer;\n        }\n        return buffer;\n    }\n    /**\n     * Safely get or create the depth value of {@link ParsingContext.unidentifiedGraphsBuffer}.\n     * @param {number} depth A depth.\n     * @return {{predicate: Term; object: Term; reverse: boolean}[]} An element of\n     *                                                               {@link ParsingContext.unidentifiedGraphsBuffer}.\n     */\n    getUnidentifiedGraphBufferSafe(depth) {\n        let buffer = this.unidentifiedGraphsBuffer[depth];\n        if (!buffer) {\n            buffer = [];\n            this.unidentifiedGraphsBuffer[depth] = buffer;\n        }\n        return buffer;\n    }\n    /**\n     * Safely get or create the depth value of {@link ParsingContext.annotationsBuffer}.\n     * @param {number} depth A depth.\n     * @return {} An element of {@link ParsingContext.annotationsBuffer}.\n     */\n    getAnnotationsBufferSafe(depth) {\n        let buffer = this.annotationsBuffer[depth];\n        if (!buffer) {\n            buffer = [];\n            this.annotationsBuffer[depth] = buffer;\n        }\n        return buffer;\n    }\n    /**\n     * @return IExpandOptions The expand options for the active processing mode.\n     */\n    getExpandOptions() {\n        return ParsingContext.EXPAND_OPTIONS[this.activeProcessingMode];\n    }\n    /**\n     * Shift the stack at the given offset to the given depth.\n     *\n     * This will override anything in the stack at `depth`,\n     * and this will remove anything at `depth + depthOffset`\n     *\n     * @param depth The target depth.\n     * @param depthOffset The origin depth, relative to `depth`.\n     */\n    shiftStack(depth, depthOffset) {\n        // Copy the id stack value up one level so that the next job can access the id.\n        const deeperIdStack = this.idStack[depth + depthOffset];\n        if (deeperIdStack) {\n            this.idStack[depth] = deeperIdStack;\n            this.emittedStack[depth] = true;\n            delete this.idStack[depth + depthOffset];\n        }\n        // Shorten key stack\n        if (this.pendingContainerFlushBuffers.length) {\n            for (const buffer of this.pendingContainerFlushBuffers) {\n                if (buffer.depth >= depth + depthOffset) {\n                    buffer.depth -= depthOffset;\n                    buffer.keys.splice(depth, depthOffset);\n                }\n            }\n        }\n        // Splice stacks\n        if (this.unidentifiedValuesBuffer[depth + depthOffset]) {\n            this.unidentifiedValuesBuffer[depth] = this.unidentifiedValuesBuffer[depth + depthOffset];\n            delete this.unidentifiedValuesBuffer[depth + depthOffset];\n        }\n        if (this.annotationsBuffer[depth + depthOffset - 1]) {\n            if (!this.annotationsBuffer[depth - 1]) {\n                this.annotationsBuffer[depth - 1] = [];\n            }\n            this.annotationsBuffer[depth - 1] = [\n                ...this.annotationsBuffer[depth - 1],\n                ...this.annotationsBuffer[depth + depthOffset - 1],\n            ];\n            delete this.annotationsBuffer[depth + depthOffset - 1];\n        }\n        // TODO: also do the same for other stacks\n    }\n}\nParsingContext.EXPAND_OPTIONS = {\n    1.0: {\n        allowPrefixForcing: false,\n        allowPrefixNonGenDelims: false,\n        allowVocabRelativeToBase: false,\n    },\n    1.1: {\n        allowPrefixForcing: true,\n        allowPrefixNonGenDelims: false,\n        allowVocabRelativeToBase: true,\n    },\n};\nexports.ParsingContext = ParsingContext;\n//# sourceMappingURL=ParsingContext.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.Util = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\nconst rdf_data_factory_1 = require(\"rdf-data-factory\");\nconst EntryHandlerContainer_1 = require(\"./entryhandler/EntryHandlerContainer\");\n// tslint:disable-next-line:no-var-requires\nconst canonicalizeJson = require('canonicalize');\n/**\n * Utility functions and methods.\n */\nclass Util {\n    constructor(options) {\n        this.parsingContext = options.parsingContext;\n        this.dataFactory = options.dataFactory || new rdf_data_factory_1.DataFactory();\n        this.rdfFirst = this.dataFactory.namedNode(Util.RDF + 'first');\n        this.rdfRest = this.dataFactory.namedNode(Util.RDF + 'rest');\n        this.rdfNil = this.dataFactory.namedNode(Util.RDF + 'nil');\n        this.rdfType = this.dataFactory.namedNode(Util.RDF + 'type');\n        this.rdfJson = this.dataFactory.namedNode(Util.RDF + 'JSON');\n    }\n    /**\n     * Helper function to get the value of a context entry,\n     * or fallback to a certain value.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} contextKey A pre-defined JSON-LD key in context entries.\n     * @param {string} key A context entry key.\n     * @param {string} fallback A fallback value for when the given contextKey\n     *                          could not be found in the value with the given key.\n     * @return {string} The value of the given contextKey in the entry behind key in the given context,\n     *                  or the given fallback value.\n     */\n    static getContextValue(context, contextKey, key, fallback) {\n        const entry = context.getContextRaw()[key];\n        if (!entry) {\n            return fallback;\n        }\n        const type = entry[contextKey];\n        return type === undefined ? fallback : type;\n    }\n    /**\n     * Get the container type of the given key in the context.\n     *\n     * Should any context-scoping bugs should occur related to this in the future,\n     * it may be required to increase the offset from the depth at which the context is retrieved by one (to 2).\n     * This is because containers act 2 levels deep.\n     *\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} key A context entry key.\n     * @return {string} The container type.\n     */\n    static getContextValueContainer(context, key) {\n        return Util.getContextValue(context, '@container', key, { '@set': true });\n    }\n    /**\n     * Get the value type of the given key in the context.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} key A context entry key.\n     * @return {string} The node type.\n     */\n    static getContextValueType(context, key) {\n        const valueType = Util.getContextValue(context, '@type', key, null);\n        if (valueType === '@none') {\n            return null;\n        }\n        return valueType;\n    }\n    /**\n     * Get the language of the given key in the context.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} key A context entry key.\n     * @return {string} The node type.\n     */\n    static getContextValueLanguage(context, key) {\n        return Util.getContextValue(context, '@language', key, context.getContextRaw()['@language'] || null);\n    }\n    /**\n     * Get the direction of the given key in the context.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} key A context entry key.\n     * @return {string} The node type.\n     */\n    static getContextValueDirection(context, key) {\n        return Util.getContextValue(context, '@direction', key, context.getContextRaw()['@direction'] || null);\n    }\n    /**\n     * Check if the given key in the context is a reversed property.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} key A context entry key.\n     * @return {boolean} If the context value has a @reverse key.\n     */\n    static isContextValueReverse(context, key) {\n        return !!Util.getContextValue(context, '@reverse', key, null);\n    }\n    /**\n     * Get the @index of the given key in the context.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} key A context entry key.\n     * @return {string} The index.\n     */\n    static getContextValueIndex(context, key) {\n        return Util.getContextValue(context, '@index', key, context.getContextRaw()['@index'] || null);\n    }\n    /**\n     * Check if the given key refers to a reversed property.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} key The property key.\n     * @param {string} parentKey The parent key.\n     * @return {boolean} If the property must be reversed.\n     */\n    static isPropertyReverse(context, key, parentKey) {\n        // '!==' is needed because reversed properties in a @reverse container should cancel each other out.\n        return parentKey === '@reverse' !== Util.isContextValueReverse(context, key);\n    }\n    /**\n     * Check if the given key exists inside an embedded node as direct child.\n     * @param {string} parentKey The parent key.\n     * @return {boolean} If the property is embedded.\n     */\n    static isPropertyInEmbeddedNode(parentKey) {\n        return parentKey === '@id';\n    }\n    /**\n     * Check if the given key exists inside an annotation object as direct child.\n     * @param {string} parentKey The parent key.\n     * @return {boolean} If the property is an annotation.\n     */\n    static isPropertyInAnnotationObject(parentKey) {\n        return parentKey === '@annotation';\n    }\n    /**\n     * Check if the given IRI is valid.\n     * @param {string} iri A potential IRI.\n     * @return {boolean} If the given IRI is valid.\n     */\n    static isValidIri(iri) {\n        return iri !== null && jsonld_context_parser_1.Util.isValidIri(iri);\n    }\n    /**\n     * Check if the given first array (needle) is a prefix of the given second array (haystack).\n     * @param needle An array to check if it is a prefix.\n     * @param haystack An array to look in.\n     */\n    static isPrefixArray(needle, haystack) {\n        if (needle.length > haystack.length) {\n            return false;\n        }\n        for (let i = 0; i < needle.length; i++) {\n            if (needle[i] !== haystack[i]) {\n                return false;\n            }\n        }\n        return true;\n    }\n    /**\n     * Make sure that @id-@index pairs are equal over all array values.\n     * Reject otherwise.\n     * @param {any[]} value An array value.\n     * @return {Promise<void>} A promise rejecting if conflicts are present.\n     */\n    async validateValueIndexes(value) {\n        if (this.parsingContext.validateValueIndexes) {\n            const indexHashes = {};\n            for (const entry of value) {\n                if (entry && typeof entry === 'object') {\n                    const id = entry['@id'];\n                    const index = entry['@index'];\n                    if (id && index) {\n                        const existingIndexValue = indexHashes[id];\n                        if (existingIndexValue && existingIndexValue !== index) {\n                            throw new jsonld_context_parser_1.ErrorCoded(`Conflicting @index value for ${id}`, jsonld_context_parser_1.ERROR_CODES.CONFLICTING_INDEXES);\n                        }\n                        indexHashes[id] = index;\n                    }\n                }\n            }\n        }\n    }\n    /**\n     * Convert a given JSON value to an RDF term.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} key The current JSON key.\n     * @param value A JSON value.\n     * @param {number} depth The depth the value is at.\n     * @param {string[]} keys The path of keys.\n     * @return {Promise<RDF.Term[]>} An RDF term array.\n     */\n    async valueToTerm(context, key, value, depth, keys) {\n        // Skip further processing if we have an @type: @json\n        if (Util.getContextValueType(context, key) === '@json') {\n            return [this.dataFactory.literal(this.valueToJsonString(value), this.rdfJson)];\n        }\n        const type = typeof value;\n        switch (type) {\n            case 'object':\n                // Skip if we have a null or undefined object\n                if (value === null || value === undefined) {\n                    return [];\n                }\n                // Special case for arrays\n                if (Array.isArray(value)) {\n                    // We handle arrays at value level so we can emit earlier, so this is handled already when we get here.\n                    // Empty context-based lists are emitted at this place, because our streaming algorithm doesn't detect those.\n                    if ('@list' in Util.getContextValueContainer(context, key)) {\n                        if (value.length === 0) {\n                            return [this.rdfNil];\n                        }\n                        else {\n                            return this.parsingContext.idStack[depth + 1] || [];\n                        }\n                    }\n                    await this.validateValueIndexes(value);\n                    return [];\n                }\n                // Handle property-scoped contexts\n                context = await this.getContextSelfOrPropertyScoped(context, key);\n                // Handle local context in the value\n                if ('@context' in value) {\n                    context = await this.parsingContext.parseContext(value['@context'], (await this.parsingContext.getContext(keys, 0)).getContextRaw());\n                }\n                // In all other cases, we have a hash\n                value = await this.unaliasKeywords(value, keys, depth, context); // Un-alias potential keywords in this hash\n                if ('@value' in value) {\n                    let val;\n                    let valueLanguage;\n                    let valueDirection;\n                    let valueType;\n                    let valueIndex; // We don't use the index, but we need to check its type for spec-compliance\n                    for (key in value) {\n                        const subValue = value[key];\n                        switch (key) {\n                            case '@value':\n                                val = subValue;\n                                break;\n                            case '@language':\n                                valueLanguage = subValue;\n                                break;\n                            case '@direction':\n                                valueDirection = subValue;\n                                break;\n                            case '@type':\n                                valueType = subValue;\n                                break;\n                            case '@index':\n                                valueIndex = subValue;\n                                break;\n                            case '@annotation':\n                                // This keyword is allowed, but is processed like normal nodes\n                                break;\n                            default:\n                                throw new jsonld_context_parser_1.ErrorCoded(`Unknown value entry '${key}' in @value: ${JSON.stringify(value)}`, jsonld_context_parser_1.ERROR_CODES.INVALID_VALUE_OBJECT);\n                        }\n                    }\n                    // Skip further processing if we have an @type: @json\n                    if (await this.unaliasKeyword(valueType, keys, depth, true, context) === '@json') {\n                        return [this.dataFactory.literal(this.valueToJsonString(val), this.rdfJson)];\n                    }\n                    // Validate @value\n                    if (val === null) {\n                        return [];\n                    }\n                    if (typeof val === 'object') {\n                        throw new jsonld_context_parser_1.ErrorCoded(`The value of an '@value' can not be an object, got '${JSON.stringify(val)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_VALUE_OBJECT_VALUE);\n                    }\n                    // Validate @index\n                    if (this.parsingContext.validateValueIndexes && valueIndex && typeof valueIndex !== 'string') {\n                        throw new jsonld_context_parser_1.ErrorCoded(`The value of an '@index' must be a string, got '${JSON.stringify(valueIndex)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_INDEX_VALUE);\n                    }\n                    // Validate @language and @direction\n                    if (valueLanguage) {\n                        if (typeof val !== 'string') {\n                            throw new jsonld_context_parser_1.ErrorCoded(`When an '@language' is set, the value of '@value' must be a string, got '${JSON.stringify(val)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_LANGUAGE_TAGGED_VALUE);\n                        }\n                        if (!jsonld_context_parser_1.ContextParser.validateLanguage(valueLanguage, this.parsingContext.strictValues, jsonld_context_parser_1.ERROR_CODES.INVALID_LANGUAGE_TAGGED_STRING)) {\n                            return [];\n                        }\n                        // Language tags are always normalized to lowercase in 1.0.\n                        if (this.parsingContext.normalizeLanguageTags || this.parsingContext.activeProcessingMode === 1.0) {\n                            valueLanguage = valueLanguage.toLowerCase();\n                        }\n                    }\n                    if (valueDirection) {\n                        if (typeof val !== 'string') {\n                            throw new Error(`When an '@direction' is set, the value of '@value' must be a string, got '${JSON.stringify(val)}'`);\n                        }\n                        if (!jsonld_context_parser_1.ContextParser.validateDirection(valueDirection, this.parsingContext.strictValues)) {\n                            return [];\n                        }\n                    }\n                    // Check @language and @direction\n                    if (valueLanguage && valueDirection && this.parsingContext.rdfDirection) {\n                        if (valueType) {\n                            throw new jsonld_context_parser_1.ErrorCoded(`Can not have '@language', '@direction' and '@type' in a value: '${JSON\n                                .stringify(value)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_VALUE_OBJECT);\n                        }\n                        return this.nullableTermToArray(this\n                            .createLanguageDirectionLiteral(depth, val, valueLanguage, valueDirection));\n                    }\n                    else if (valueLanguage) { // Check @language\n                        if (valueType) {\n                            throw new jsonld_context_parser_1.ErrorCoded(`Can not have both '@language' and '@type' in a value: '${JSON.stringify(value)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_VALUE_OBJECT);\n                        }\n                        return [this.dataFactory.literal(val, valueLanguage)];\n                    }\n                    else if (valueDirection && this.parsingContext.rdfDirection) { // Check @direction\n                        if (valueType) {\n                            throw new jsonld_context_parser_1.ErrorCoded(`Can not have both '@direction' and '@type' in a value: '${JSON.stringify(value)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_VALUE_OBJECT);\n                        }\n                        return this.nullableTermToArray(this\n                            .createLanguageDirectionLiteral(depth, val, valueLanguage, valueDirection));\n                    }\n                    else if (valueType) { // Validate @type\n                        if (typeof valueType !== 'string') {\n                            throw new jsonld_context_parser_1.ErrorCoded(`The value of an '@type' must be a string, got '${JSON.stringify(valueType)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_TYPED_VALUE);\n                        }\n                        const typeTerm = this.createVocabOrBaseTerm(context, valueType);\n                        if (!typeTerm) {\n                            throw new jsonld_context_parser_1.ErrorCoded(`Invalid '@type' value, got '${JSON.stringify(valueType)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_TYPED_VALUE);\n                        }\n                        if (typeTerm.termType !== 'NamedNode') {\n                            throw new jsonld_context_parser_1.ErrorCoded(`Illegal value type (${typeTerm.termType}): ${valueType}`, jsonld_context_parser_1.ERROR_CODES.INVALID_TYPED_VALUE);\n                        }\n                        return [this.dataFactory.literal(val, typeTerm)];\n                    }\n                    // We don't pass the context, because context-based things like @language should be ignored\n                    return await this.valueToTerm(new jsonld_context_parser_1.JsonLdContextNormalized({}), key, val, depth, keys);\n                }\n                else if ('@set' in value) {\n                    // No other entries are allow in this value\n                    if (Object.keys(value).length > 1) {\n                        throw new jsonld_context_parser_1.ErrorCoded(`Found illegal neighbouring entries next to @set for key: '${key}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_SET_OR_LIST_OBJECT);\n                    }\n                    // No need to do anything here, this is handled at the deeper level.\n                    return [];\n                }\n                else if ('@list' in value) {\n                    // No other entries are allowed in this value\n                    if (Object.keys(value).length > 1) {\n                        throw new jsonld_context_parser_1.ErrorCoded(`Found illegal neighbouring entries next to @list for key: '${key}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_SET_OR_LIST_OBJECT);\n                    }\n                    const listValue = value[\"@list\"];\n                    // We handle lists at value level so we can emit earlier, so this is handled already when we get here.\n                    // Empty anonymous lists are emitted at this place, because our streaming algorithm doesn't detect those.\n                    if (Array.isArray(listValue)) {\n                        if (listValue.length === 0) {\n                            return [this.rdfNil];\n                        }\n                        else {\n                            return this.parsingContext.idStack[depth + 1] || [];\n                        }\n                    }\n                    else {\n                        // We only have a single list element here, so emit this directly as single element\n                        return await this.valueToTerm(await this.parsingContext.getContext(keys), key, listValue, depth - 1, keys.slice(0, -1));\n                    }\n                }\n                else if ('@reverse' in value && typeof value['@reverse'] === 'boolean') {\n                    // We handle reverse properties at value level so we can emit earlier,\n                    // so this is handled already when we get here.\n                    return [];\n                }\n                else if ('@graph' in Util.getContextValueContainer(await this.parsingContext.getContext(keys), key)) {\n                    // We are processing a graph container\n                    const graphContainerEntries = this.parsingContext.graphContainerTermStack[depth + 1];\n                    return graphContainerEntries ? Object.values(graphContainerEntries) : [this.dataFactory.blankNode()];\n                }\n                else if (\"@id\" in value) {\n                    // Use deeper context if the value node contains other properties next to @id.\n                    if (Object.keys(value).length > 1) {\n                        context = await this.parsingContext.getContext(keys, 0);\n                    }\n                    // Handle local context in the value\n                    if ('@context' in value) {\n                        context = await this.parsingContext.parseContext(value['@context'], context.getContextRaw());\n                    }\n                    if (value[\"@type\"] === '@vocab') {\n                        return this.nullableTermToArray(this.createVocabOrBaseTerm(context, value[\"@id\"]));\n                    }\n                    else {\n                        const valueId = value[\"@id\"];\n                        let valueTerm;\n                        if (typeof valueId === 'object') {\n                            if (this.parsingContext.rdfstar) {\n                                valueTerm = this.parsingContext.idStack[depth + 1][0];\n                            }\n                            else {\n                                throw new jsonld_context_parser_1.ErrorCoded(`Found illegal @id '${value}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_ID_VALUE);\n                            }\n                        }\n                        else {\n                            valueTerm = this.resourceToTerm(context, valueId);\n                        }\n                        return this.nullableTermToArray(valueTerm);\n                    }\n                }\n                else {\n                    // Only make a blank node if at least one triple was emitted at the value's level.\n                    if (this.parsingContext.emittedStack[depth + 1]\n                        || (value && typeof value === 'object' && Object.keys(value).length === 0)) {\n                        return (this.parsingContext.idStack[depth + 1]\n                            || (this.parsingContext.idStack[depth + 1] = [this.dataFactory.blankNode()]));\n                    }\n                    else {\n                        return [];\n                    }\n                }\n            case 'string':\n                return this.nullableTermToArray(this.stringValueToTerm(depth, await this.getContextSelfOrPropertyScoped(context, key), key, value, null));\n            case 'boolean':\n                return this.nullableTermToArray(this.stringValueToTerm(depth, await this.getContextSelfOrPropertyScoped(context, key), key, Boolean(value).toString(), this.dataFactory.namedNode(Util.XSD_BOOLEAN)));\n            case 'number':\n                return this.nullableTermToArray(this.stringValueToTerm(depth, await this.getContextSelfOrPropertyScoped(context, key), key, value, this.dataFactory.namedNode(value % 1 === 0 && value < 1e21 ? Util.XSD_INTEGER : Util.XSD_DOUBLE)));\n            default:\n                this.parsingContext.emitError(new Error(`Could not determine the RDF type of a ${type}`));\n                return [];\n        }\n    }\n    /**\n     * If the context defines a property-scoped context for the given key,\n     * that context will be returned.\n     * Otherwise, the given context will be returned as-is.\n     *\n     * This should be used for valueToTerm cases that are not objects.\n     * @param context A context.\n     * @param key A JSON key.\n     */\n    async getContextSelfOrPropertyScoped(context, key) {\n        const contextKeyEntry = context.getContextRaw()[key];\n        if (contextKeyEntry && typeof contextKeyEntry === 'object' && '@context' in contextKeyEntry) {\n            context = await this.parsingContext.parseContext(contextKeyEntry, context.getContextRaw(), true);\n        }\n        return context;\n    }\n    /**\n     * If the given term is null, return an empty array, otherwise return an array with the single given term.\n     * @param term A term.\n     */\n    nullableTermToArray(term) {\n        return term ? [term] : [];\n    }\n    /**\n     * Convert a given JSON key to an RDF predicate term,\n     * based on @vocab.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param key A JSON key.\n     * @return {RDF.NamedNode} An RDF named node.\n     */\n    predicateToTerm(context, key) {\n        const expanded = context.expandTerm(key, true, this.parsingContext.getExpandOptions());\n        // Immediately return if the predicate was disabled in the context\n        if (!expanded) {\n            return null;\n        }\n        // Check if the predicate is a blank node\n        if (expanded[0] === '_' && expanded[1] === ':') {\n            if (this.parsingContext.produceGeneralizedRdf) {\n                return this.dataFactory.blankNode(expanded.substr(2));\n            }\n            else {\n                return null;\n            }\n        }\n        // Check if the predicate is a valid IRI\n        if (Util.isValidIri(expanded)) {\n            return this.dataFactory.namedNode(expanded);\n        }\n        else {\n            if (expanded && this.parsingContext.strictValues) {\n                this.parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Invalid predicate IRI: ${expanded}`, jsonld_context_parser_1.ERROR_CODES.INVALID_IRI_MAPPING));\n            }\n            else {\n                return null;\n            }\n        }\n        return null;\n    }\n    /**\n     * Convert a given JSON key to an RDF resource term or blank node,\n     * based on @base.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param key A JSON key.\n     * @return {RDF.NamedNode} An RDF named node or null.\n     */\n    resourceToTerm(context, key) {\n        if (key.startsWith('_:')) {\n            return this.dataFactory.blankNode(key.substr(2));\n        }\n        const iri = context.expandTerm(key, false, this.parsingContext.getExpandOptions());\n        if (!Util.isValidIri(iri)) {\n            if (iri && this.parsingContext.strictValues) {\n                this.parsingContext.emitError(new Error(`Invalid resource IRI: ${iri}`));\n            }\n            else {\n                return null;\n            }\n        }\n        return this.dataFactory.namedNode(iri);\n    }\n    /**\n     * Convert a given JSON key to an RDF resource term.\n     * It will do this based on the @vocab,\n     * and fallback to @base.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param key A JSON key.\n     * @return {RDF.NamedNode} An RDF named node or null.\n     */\n    createVocabOrBaseTerm(context, key) {\n        if (key.startsWith('_:')) {\n            return this.dataFactory.blankNode(key.substr(2));\n        }\n        const expandOptions = this.parsingContext.getExpandOptions();\n        let expanded = context.expandTerm(key, true, expandOptions);\n        if (expanded === key) {\n            expanded = context.expandTerm(key, false, expandOptions);\n        }\n        if (!Util.isValidIri(expanded)) {\n            if (expanded && this.parsingContext.strictValues && !expanded.startsWith('@')) {\n                this.parsingContext.emitError(new Error(`Invalid term IRI: ${expanded}`));\n            }\n            else {\n                return null;\n            }\n        }\n        return this.dataFactory.namedNode(expanded);\n    }\n    /**\n     * Ensure that the given value becomes a string.\n     * @param {string | number} value A string or number.\n     * @param {NamedNode} datatype The intended datatype.\n     * @return {string} The returned string.\n     */\n    intToString(value, datatype) {\n        if (typeof value === 'number') {\n            if (Number.isFinite(value)) {\n                const isInteger = value % 1 === 0;\n                if (isInteger && (!datatype || datatype.value !== Util.XSD_DOUBLE)) {\n                    return Number(value).toString();\n                }\n                else {\n                    return value.toExponential(15).replace(/(\\d)0*e\\+?/, '$1E');\n                }\n            }\n            else {\n                return value > 0 ? 'INF' : '-INF';\n            }\n        }\n        else {\n            return value;\n        }\n    }\n    /**\n     * Convert a given JSON string value to an RDF term.\n     * @param {number} depth The current stack depth.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} key The current JSON key.\n     * @param {string} value A JSON value.\n     * @param {NamedNode} defaultDatatype The default datatype for the given value.\n     * @return {RDF.Term} An RDF term or null.\n     */\n    stringValueToTerm(depth, context, key, value, defaultDatatype) {\n        // Check the datatype from the context\n        const contextType = Util.getContextValueType(context, key);\n        if (contextType) {\n            if (contextType === '@id') {\n                if (!defaultDatatype) {\n                    return this.resourceToTerm(context, this.intToString(value, defaultDatatype));\n                }\n            }\n            else if (contextType === '@vocab') {\n                if (!defaultDatatype) {\n                    return this.createVocabOrBaseTerm(context, this.intToString(value, defaultDatatype));\n                }\n            }\n            else {\n                defaultDatatype = this.dataFactory.namedNode(contextType);\n            }\n        }\n        // If we don't find such a datatype, check the language from the context\n        if (!defaultDatatype) {\n            const contextLanguage = Util.getContextValueLanguage(context, key);\n            const contextDirection = Util.getContextValueDirection(context, key);\n            if (contextDirection && this.parsingContext.rdfDirection) {\n                return this.createLanguageDirectionLiteral(depth, this.intToString(value, defaultDatatype), contextLanguage, contextDirection);\n            }\n            else {\n                return this.dataFactory.literal(this.intToString(value, defaultDatatype), contextLanguage);\n            }\n        }\n        // If all else fails, make a literal based on the default content type\n        return this.dataFactory.literal(this.intToString(value, defaultDatatype), defaultDatatype);\n    }\n    /**\n     * Create a literal for the given value with the given language and direction.\n     * Auxiliary quads may be emitted.\n     * @param {number} depth The current stack depth.\n     * @param {string} value A string value.\n     * @param {string} language A language tag.\n     * @param {string} direction A direction.\n     * @return {Term} An RDF term.\n     */\n    createLanguageDirectionLiteral(depth, value, language, direction) {\n        if (this.parsingContext.rdfDirection === 'i18n-datatype') {\n            // Create a datatyped literal, by encoding the language and direction into https://www.w3.org/ns/i18n#.\n            if (!language) {\n                language = '';\n            }\n            return this.dataFactory.literal(value, this.dataFactory.namedNode(`https://www.w3.org/ns/i18n#${language}_${direction}`));\n        }\n        else {\n            // Reify the literal.\n            const valueNode = this.dataFactory.blankNode();\n            const graph = this.getDefaultGraph();\n            this.parsingContext.emitQuad(depth, this.dataFactory.quad(valueNode, this.dataFactory.namedNode(Util.RDF + 'value'), this.dataFactory.literal(value), graph));\n            if (language) {\n                this.parsingContext.emitQuad(depth, this.dataFactory.quad(valueNode, this.dataFactory.namedNode(Util.RDF + 'language'), this.dataFactory.literal(language), graph));\n            }\n            this.parsingContext.emitQuad(depth, this.dataFactory.quad(valueNode, this.dataFactory.namedNode(Util.RDF + 'direction'), this.dataFactory.literal(direction), graph));\n            return valueNode;\n        }\n    }\n    /**\n     * Stringify the given JSON object to a canonical JSON string.\n     * @param value Any valid JSON value.\n     * @return {string} A canonical JSON string.\n     */\n    valueToJsonString(value) {\n        return canonicalizeJson(value);\n    }\n    /**\n     * If the key is not a keyword, try to check if it is an alias for a keyword,\n     * and if so, un-alias it.\n     * @param {string} key A key, can be falsy.\n     * @param {string[]} keys The path of keys.\n     * @param {number} depth The depth to\n     * @param {boolean} disableCache If the cache should be disabled\n     * @param {JsonLdContextNormalized} context A context to unalias with,\n     *                                           will fallback to retrieving the context for the given keys.\n     * @return {Promise<string>} A promise resolving to the key itself, or another key.\n     */\n    async unaliasKeyword(key, keys, depth, disableCache, context) {\n        // Numbers can not be an alias\n        if (Number.isInteger(key)) {\n            return key;\n        }\n        // Try to grab from cache if it was already un-aliased before.\n        if (!disableCache) {\n            const cachedUnaliasedKeyword = this.parsingContext.unaliasedKeywordCacheStack[depth];\n            if (cachedUnaliasedKeyword) {\n                return cachedUnaliasedKeyword;\n            }\n        }\n        if (!jsonld_context_parser_1.Util.isPotentialKeyword(key)) {\n            context = context || await this.parsingContext.getContext(keys);\n            let unliased = context.getContextRaw()[key];\n            if (unliased && typeof unliased === 'object') {\n                unliased = unliased['@id'];\n            }\n            if (jsonld_context_parser_1.Util.isValidKeyword(unliased)) {\n                key = unliased;\n            }\n        }\n        return disableCache ? key : (this.parsingContext.unaliasedKeywordCacheStack[depth] = key);\n    }\n    /**\n     * Unalias the keyword of the parent.\n     * This adds a safety check if no parent exist.\n     * @param {any[]} keys A stack of keys.\n     * @param {number} depth The current depth.\n     * @return {Promise<any>} A promise resolving to the parent key, or another key.\n     */\n    async unaliasKeywordParent(keys, depth) {\n        return await this.unaliasKeyword(depth > 0 && keys[depth - 1], keys, depth - 1);\n    }\n    /**\n     * Un-alias all keywords in the given hash.\n     * @param {{[p: string]: any}} hash A hash object.\n     * @param {string[]} keys The path of keys.\n     * @param {number} depth The depth.\n     * @param {JsonLdContextNormalized} context A context to unalias with,\n     *                                           will fallback to retrieving the context for the given keys.\n     * @return {Promise<{[p: string]: any}>} A promise resolving to the new hash.\n     */\n    async unaliasKeywords(hash, keys, depth, context) {\n        const newHash = {};\n        for (const key in hash) {\n            newHash[await this.unaliasKeyword(key, keys, depth + 1, true, context)] = hash[key];\n        }\n        return newHash;\n    }\n    /**\n     * Check if we are processing a literal (including JSON literals) at the given depth.\n     * This will also check higher levels,\n     * because if a parent is a literal,\n     * then the deeper levels are definitely a literal as well.\n     * @param {any[]} keys The keys.\n     * @param {number} depth The depth.\n     * @return {boolean} If we are processing a literal.\n     */\n    async isLiteral(keys, depth) {\n        for (let i = depth; i >= 0; i--) {\n            if (await this.unaliasKeyword(keys[i], keys, i) === '@annotation') {\n                // Literals may have annotations, which require processing of inner nodes.\n                return false;\n            }\n            if (this.parsingContext.literalStack[i] || this.parsingContext.jsonLiteralStack[i]) {\n                return true;\n            }\n        }\n        return false;\n    }\n    /**\n     * Check how many parents should be skipped for checking the @graph for the given node.\n     *\n     * @param {number} depth The depth of the node.\n     * @param {any[]} keys An array of keys.\n     * @return {number} The graph depth offset.\n     */\n    async getDepthOffsetGraph(depth, keys) {\n        for (let i = depth - 1; i > 0; i--) {\n            if (await this.unaliasKeyword(keys[i], keys, i) === '@graph') {\n                // Skip further processing if we are already in an @graph-@id or @graph-@index container\n                const containers = (await EntryHandlerContainer_1.EntryHandlerContainer.getContainerHandler(this.parsingContext, keys, i)).containers;\n                if (EntryHandlerContainer_1.EntryHandlerContainer.isComplexGraphContainer(containers)) {\n                    return -1;\n                }\n                return depth - i - 1;\n            }\n        }\n        return -1;\n    }\n    /**\n     * Check if the given subject is of a valid type.\n     * This should be called when applying @reverse'd properties.\n     * @param {Term} subject A subject.\n     */\n    validateReverseSubject(subject) {\n        if (subject.termType === 'Literal') {\n            throw new jsonld_context_parser_1.ErrorCoded(`Found illegal literal in subject position: ${subject.value}`, jsonld_context_parser_1.ERROR_CODES.INVALID_REVERSE_PROPERTY_VALUE);\n        }\n    }\n    /**\n     * Get the default graph.\n     * @return {Term} An RDF term.\n     */\n    getDefaultGraph() {\n        return this.parsingContext.defaultGraph || this.dataFactory.defaultGraph();\n    }\n    /**\n     * Get the current graph, while taking into account a graph that can be defined via @container: @graph.\n     * If not within a graph container, the default graph will be returned.\n     * @param keys The current keys.\n     * @param depth The current depth.\n     */\n    async getGraphContainerValue(keys, depth) {\n        // Default to default graph\n        let graph = this.getDefaultGraph();\n        // Check if we are in an @container: @graph.\n        const { containers, depth: depthContainer } = await EntryHandlerContainer_1.EntryHandlerContainer\n            .getContainerHandler(this.parsingContext, keys, depth);\n        if ('@graph' in containers) {\n            // Get the graph from the stack.\n            const graphContainerIndex = EntryHandlerContainer_1.EntryHandlerContainer.getContainerGraphIndex(containers, depthContainer, keys);\n            const entry = this.parsingContext.graphContainerTermStack[depthContainer];\n            graph = entry ? entry[graphContainerIndex] : null;\n            // Set the graph in the stack if none has been set yet.\n            if (!graph) {\n                let graphId = null;\n                if ('@id' in containers) {\n                    const keyUnaliased = await this.getContainerKey(keys[depthContainer], keys, depthContainer);\n                    if (keyUnaliased !== null) {\n                        graphId = await this.resourceToTerm(await this.parsingContext.getContext(keys), keyUnaliased);\n                    }\n                }\n                if (!graphId) {\n                    graphId = this.dataFactory.blankNode();\n                }\n                if (!this.parsingContext.graphContainerTermStack[depthContainer]) {\n                    this.parsingContext.graphContainerTermStack[depthContainer] = {};\n                }\n                graph = this.parsingContext.graphContainerTermStack[depthContainer][graphContainerIndex] = graphId;\n            }\n        }\n        return graph;\n    }\n    /**\n     * Get the properties depth for retrieving properties.\n     *\n     * Typically, the properties depth will be identical to the given depth.\n     *\n     * The following exceptions apply:\n     * * When the parent is @reverse, the depth is decremented by one.\n     * * When @nest parents are found, the depth is decremented by the number of @nest parents.\n     * If in combination with the exceptions above an intermediary array is discovered,\n     * the depth is also decremented by this number of arrays.\n     *\n     * @param keys The current key chain.\n     * @param depth The current depth.\n     */\n    async getPropertiesDepth(keys, depth) {\n        let lastValidDepth = depth;\n        for (let i = depth - 1; i > 0; i--) {\n            if (typeof keys[i] !== 'number') { // Skip array keys\n                const parentKey = await this.unaliasKeyword(keys[i], keys, i);\n                if (parentKey === '@reverse') {\n                    return i;\n                }\n                else if (parentKey === '@nest') {\n                    lastValidDepth = i;\n                }\n                else {\n                    return lastValidDepth;\n                }\n            }\n        }\n        return lastValidDepth;\n    }\n    /**\n     * Get the key for the current container entry.\n     * @param key A key, can be falsy.\n     * @param keys The key chain.\n     * @param depth The current depth to get the key from.\n     * @return Promise resolving to the key.\n     *         Null will be returned for @none entries, with aliasing taken into account.\n     */\n    async getContainerKey(key, keys, depth) {\n        const keyUnaliased = await this.unaliasKeyword(key, keys, depth);\n        return keyUnaliased === '@none' ? null : keyUnaliased;\n    }\n    /**\n     * Check if no reverse properties are present in embedded nodes.\n     * @param key The current key.\n     * @param reverse If a reverse property is active.\n     * @param isEmbedded If we're in an embedded node.\n     */\n    validateReverseInEmbeddedNode(key, reverse, isEmbedded) {\n        if (isEmbedded && reverse && !this.parsingContext.rdfstarReverseInEmbedded) {\n            throw new jsonld_context_parser_1.ErrorCoded(`Illegal reverse property in embedded node in ${key}`, jsonld_context_parser_1.ERROR_CODES.INVALID_EMBEDDED_NODE);\n        }\n    }\n    /**\n     * Emit a quad, with checks.\n     * @param depth The current depth.\n     * @param subject S\n     * @param predicate P\n     * @param object O\n     * @param graph G\n     * @param reverse If a reverse property is active.\n     * @param isEmbedded If we're in an embedded node.\n     */\n    emitQuadChecked(depth, subject, predicate, object, graph, reverse, isEmbedded) {\n        // Create a quad\n        let quad;\n        if (reverse) {\n            this.validateReverseSubject(object);\n            quad = this.dataFactory.quad(object, predicate, subject, graph);\n        }\n        else {\n            quad = this.dataFactory.quad(subject, predicate, object, graph);\n        }\n        // Emit the quad, unless it was created in an embedded node\n        if (isEmbedded) {\n            // Embedded nodes don't inherit the active graph\n            if (quad.graph.termType !== 'DefaultGraph') {\n                quad = this.dataFactory.quad(quad.subject, quad.predicate, quad.object);\n            }\n            // Multiple embedded nodes are not allowed\n            if (this.parsingContext.idStack[depth - 1]) {\n                throw new jsonld_context_parser_1.ErrorCoded(`Illegal multiple properties in an embedded node`, jsonld_context_parser_1.ERROR_CODES.INVALID_EMBEDDED_NODE);\n            }\n            this.parsingContext.idStack[depth - 1] = [quad];\n        }\n        else {\n            this.parsingContext.emitQuad(depth, quad);\n        }\n        // Flush annotations\n        const annotationsBuffer = this.parsingContext.annotationsBuffer[depth];\n        if (annotationsBuffer) {\n            for (const annotation of annotationsBuffer) {\n                this.emitAnnotation(depth, quad, annotation);\n            }\n            delete this.parsingContext.annotationsBuffer[depth];\n        }\n    }\n    // This is a separate function to enable recursion\n    emitAnnotation(depth, quad, annotation) {\n        // Construct annotation quad\n        let annotationQuad;\n        if (annotation.reverse) {\n            this.validateReverseSubject(annotation.object);\n            annotationQuad = this.dataFactory.quad(annotation.object, annotation.predicate, quad);\n        }\n        else {\n            annotationQuad = this.dataFactory.quad(quad, annotation.predicate, annotation.object);\n        }\n        // Emit annotated quad\n        this.parsingContext.emitQuad(depth, annotationQuad);\n        // Also emit nested annotations\n        for (const nestedAnnotation of annotation.nestedAnnotations) {\n            this.emitAnnotation(depth, annotationQuad, nestedAnnotation);\n        }\n    }\n}\nUtil.XSD = 'http://www.w3.org/2001/XMLSchema#';\nUtil.XSD_BOOLEAN = Util.XSD + 'boolean';\nUtil.XSD_INTEGER = Util.XSD + 'integer';\nUtil.XSD_DOUBLE = Util.XSD + 'double';\nUtil.RDF = 'http://www.w3.org/1999/02/22-rdf-syntax-ns#';\nexports.Util = Util;\n//# sourceMappingURL=Util.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ContainerHandlerIdentifier = void 0;\n/**\n * Container handler for @id.\n *\n * It assumes that the current key is the identifier of the current value.\n * This will add this value to the parent node.\n */\nclass ContainerHandlerIdentifier {\n    canCombineWithGraph() {\n        return true;\n    }\n    async handle(containers, parsingContext, util, keys, value, depth) {\n        let id;\n        // First check if the child node already has a defined id.\n        if (parsingContext.emittedStack[depth + 1] && parsingContext.idStack[depth + 1]) {\n            // Use the existing identifier\n            id = parsingContext.idStack[depth + 1][0];\n        }\n        else {\n            // Create the identifier\n            const keyUnaliased = await util.getContainerKey(keys[depth], keys, depth);\n            const maybeId = keyUnaliased !== null\n                ? await util.resourceToTerm(await parsingContext.getContext(keys), keys[depth])\n                : util.dataFactory.blankNode();\n            // Do nothing if the id is invalid\n            if (!maybeId) {\n                parsingContext.emittedStack[depth] = false; // Don't emit the predicate owning this container.\n                return;\n            }\n            id = maybeId;\n            // Insert the id into the stack so that buffered children can make us of it.\n            parsingContext.idStack[depth + 1] = [id];\n        }\n        // Insert the id into the stack so that parents can make use of it.\n        // Insert it as an array because multiple id container entries may exist\n        let ids = parsingContext.idStack[depth];\n        if (!ids) {\n            ids = parsingContext.idStack[depth] = [];\n        }\n        // Only insert the term if it does not exist yet in the array.\n        if (!ids.some((term) => term.equals(id))) {\n            ids.push(id);\n        }\n        // Flush any pending flush buffers\n        if (!await parsingContext.handlePendingContainerFlushBuffers()) {\n            parsingContext.emittedStack[depth] = false; // Don't emit the predicate owning this container.\n        }\n    }\n}\nexports.ContainerHandlerIdentifier = ContainerHandlerIdentifier;\n//# sourceMappingURL=ContainerHandlerIdentifier.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ContainerHandlerIndex = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\nconst EntryHandlerPredicate_1 = require(\"../entryhandler/EntryHandlerPredicate\");\nconst Util_1 = require(\"../Util\");\n/**\n * Container handler for @index.\n *\n * This will ignore the current key and add this entry to the parent node.\n */\nclass ContainerHandlerIndex {\n    canCombineWithGraph() {\n        return true;\n    }\n    async handle(containers, parsingContext, util, keys, value, depth) {\n        if (!Array.isArray(value)) {\n            const graphContainer = '@graph' in containers;\n            // Check if the container is a property-based container by checking if there is a valid @index.\n            const context = await parsingContext.getContext(keys);\n            const indexKey = keys[depth - 1];\n            const indexPropertyRaw = Util_1.Util.getContextValueIndex(context, indexKey);\n            if (indexPropertyRaw) {\n                // Validate the @index value\n                if (jsonld_context_parser_1.Util.isPotentialKeyword(indexPropertyRaw)) {\n                    throw new jsonld_context_parser_1.ErrorCoded(`Keywords can not be used as @index value, got: ${indexPropertyRaw}`, jsonld_context_parser_1.ERROR_CODES.INVALID_TERM_DEFINITION);\n                }\n                if (typeof indexPropertyRaw !== 'string') {\n                    throw new jsonld_context_parser_1.ErrorCoded(`@index values must be strings, got: ${indexPropertyRaw}`, jsonld_context_parser_1.ERROR_CODES.INVALID_TERM_DEFINITION);\n                }\n                // When @index is used, values must be node values, unless @type: @id is defined in the context\n                if (typeof value !== 'object') {\n                    // Error if we don't have @type: @id\n                    if (Util_1.Util.getContextValueType(context, indexKey) !== '@id') {\n                        throw new jsonld_context_parser_1.ErrorCoded(`Property-based index containers require nodes as values or strings with @type: @id, but got: ${value}`, jsonld_context_parser_1.ERROR_CODES.INVALID_VALUE_OBJECT);\n                    }\n                    // Add an @id to the stack, so our expanded @index value can make use of it\n                    const id = util.resourceToTerm(context, value);\n                    if (id) {\n                        parsingContext.idStack[depth + 1] = [id];\n                    }\n                }\n                // Expand the @index value\n                const indexProperty = util.createVocabOrBaseTerm(context, indexPropertyRaw);\n                if (indexProperty) {\n                    const indexValues = await util.valueToTerm(context, indexPropertyRaw, await util.getContainerKey(keys[depth], keys, depth), depth, keys);\n                    if (graphContainer) {\n                        // When we're in a graph container, attach the index to the graph identifier\n                        const graphId = await util.getGraphContainerValue(keys, depth + 1);\n                        for (const indexValue of indexValues) {\n                            parsingContext.emitQuad(depth, util.dataFactory.quad(graphId, indexProperty, indexValue, util.getDefaultGraph()));\n                        }\n                    }\n                    else {\n                        // Otherwise, attach the index to the node identifier\n                        for (const indexValue of indexValues) {\n                            await EntryHandlerPredicate_1.EntryHandlerPredicate.handlePredicateObject(parsingContext, util, keys, depth + 1, indexProperty, indexValue, false, false, false);\n                        }\n                    }\n                }\n            }\n            const depthOffset = graphContainer ? 2 : 1;\n            await parsingContext.newOnValueJob(keys.slice(0, keys.length - depthOffset), value, depth - depthOffset, true);\n            // Flush any pending flush buffers\n            await parsingContext.handlePendingContainerFlushBuffers();\n        }\n        parsingContext.emittedStack[depth] = false; // We have emitted a level higher\n    }\n}\nexports.ContainerHandlerIndex = ContainerHandlerIndex;\n//# sourceMappingURL=ContainerHandlerIndex.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ContainerHandlerLanguage = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\n/**\n * Container handler for @language.\n *\n * It assumes that the current key is the language of the current value.\n * This will add this value to the parent node.\n */\nclass ContainerHandlerLanguage {\n    canCombineWithGraph() {\n        return false;\n    }\n    async handle(containers, parsingContext, util, keys, value, depth) {\n        const language = await util.getContainerKey(keys[depth], keys, depth);\n        if (Array.isArray(value)) {\n            // No type-checking needed, will be handled on each value when this handler is called recursively.\n            value = value.map((subValue) => ({ '@value': subValue, '@language': language }));\n        }\n        else {\n            if (typeof value !== 'string') {\n                throw new jsonld_context_parser_1.ErrorCoded(`Got invalid language map value, got '${JSON.stringify(value)}', but expected string`, jsonld_context_parser_1.ERROR_CODES.INVALID_LANGUAGE_MAP_VALUE);\n            }\n            value = { '@value': value, '@language': language };\n        }\n        await parsingContext.newOnValueJob(keys.slice(0, keys.length - 1), value, depth - 1, true);\n        parsingContext.emittedStack[depth] = false; // We have emitted a level higher\n    }\n}\nexports.ContainerHandlerLanguage = ContainerHandlerLanguage;\n//# sourceMappingURL=ContainerHandlerLanguage.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ContainerHandlerType = void 0;\nconst EntryHandlerPredicate_1 = require(\"../entryhandler/EntryHandlerPredicate\");\nconst Util_1 = require(\"../Util\");\n/**\n * Container handler for @type.\n *\n * This will add this entry to the parent node, and use the current key as an rdf:type value.\n */\nclass ContainerHandlerType {\n    canCombineWithGraph() {\n        return false;\n    }\n    async handle(containers, parsingContext, util, keys, value, depth) {\n        if (!Array.isArray(value)) {\n            if (typeof value === 'string') {\n                // Determine the @type of the container\n                const context = await parsingContext.getContext(keys);\n                const containerTypeType = Util_1.Util.getContextValueType(context, keys[depth - 1]);\n                // String values refer to node references\n                const id = containerTypeType === '@vocab'\n                    ? await util.createVocabOrBaseTerm(context, value)\n                    : await util.resourceToTerm(context, value);\n                if (id) {\n                    // Handle the value of this node as @id, which will also cause the predicate from above to be emitted.\n                    const subValue = { '@id': id.termType === 'NamedNode' ? id.value : value };\n                    await parsingContext.newOnValueJob(keys.slice(0, keys.length - 1), subValue, depth - 1, true);\n                    // Set the id in the stack so it can be used for the rdf:type handling later on\n                    parsingContext.idStack[depth + 1] = [id];\n                }\n            }\n            else {\n                // Other values are handled by handling them as a proper job\n                // Check needed for cases where entries don't have an explicit @id\n                const entryHasIdentifier = !!parsingContext.idStack[depth + 1];\n                // Handle the value of this node, which will also cause the predicate from above to be emitted.\n                if (!entryHasIdentifier) {\n                    delete parsingContext.idStack[depth]; // Force new (blank node) identifier\n                }\n                await parsingContext.newOnValueJob(keys.slice(0, keys.length - 1), value, depth - 1, true);\n                if (!entryHasIdentifier) {\n                    parsingContext.idStack[depth + 1] = parsingContext.idStack[depth]; // Copy the id to the child node, for @type\n                }\n            }\n            // Identify the type to emit.\n            const keyOriginal = await util.getContainerKey(keys[depth], keys, depth);\n            const type = keyOriginal !== null\n                ? util.createVocabOrBaseTerm(await parsingContext.getContext(keys), keyOriginal)\n                : null;\n            if (type) {\n                // Push the type to the stack using the rdf:type predicate\n                await EntryHandlerPredicate_1.EntryHandlerPredicate.handlePredicateObject(parsingContext, util, keys, depth + 1, util.rdfType, type, false, false, false);\n            }\n            // Flush any pending flush buffers\n            await parsingContext.handlePendingContainerFlushBuffers();\n        }\n        parsingContext.emittedStack[depth] = false; // Don't emit the predicate owning this container.\n    }\n}\nexports.ContainerHandlerType = ContainerHandlerType;\n//# sourceMappingURL=ContainerHandlerType.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerArrayValue = void 0;\nconst Util_1 = require(\"../Util\");\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\n/**\n * Handles values that are part of an array.\n */\nclass EntryHandlerArrayValue {\n    isPropertyHandler() {\n        return false;\n    }\n    isStackProcessor() {\n        return true;\n    }\n    async validate(parsingContext, util, keys, depth, inProperty) {\n        return this.test(parsingContext, util, null, keys, depth);\n    }\n    async test(parsingContext, util, key, keys, depth) {\n        return typeof keys[depth] === 'number';\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        let parentKey = await util.unaliasKeywordParent(keys, depth);\n        // Check if we have an anonymous list\n        if (parentKey === '@list') {\n            // Our value is part of an array\n            // Determine the list root key\n            let listRootKey = null;\n            let listRootDepth = 0;\n            for (let i = depth - 2; i > 0; i--) {\n                const keyOption = keys[i];\n                if (typeof keyOption === 'string' || typeof keyOption === 'number') {\n                    listRootDepth = i;\n                    listRootKey = keyOption;\n                    break;\n                }\n            }\n            if (listRootKey !== null) {\n                // Emit the given objects as list elements\n                const values = await util.valueToTerm(await parsingContext.getContext(keys), listRootKey, value, depth, keys);\n                for (const object of values) {\n                    await this.handleListElement(parsingContext, util, object, value, depth, keys.slice(0, listRootDepth), listRootDepth);\n                }\n                // If no values were found, emit a falsy list element to force an empty RDF list to be emitted.\n                if (values.length === 0) {\n                    await this.handleListElement(parsingContext, util, null, value, depth, keys.slice(0, listRootDepth), listRootDepth);\n                }\n            }\n        }\n        else if (parentKey === '@set') {\n            // Our value is part of a set, so we just add it to the parent-parent\n            await parsingContext.newOnValueJob(keys.slice(0, -2), value, depth - 2, false);\n        }\n        else if (parentKey !== undefined && parentKey !== '@type') {\n            // Buffer our value using the parent key as predicate\n            // Determine the first parent key that is *not* an array key\n            // This is needed in case we have an @list container with nested arrays,\n            // where each of them should produce nested RDF lists.\n            for (let i = depth - 1; i > 0; i--) {\n                if (typeof keys[i] !== 'number') {\n                    parentKey = await util.unaliasKeyword(keys[i], keys, i);\n                    break;\n                }\n            }\n            // Check if the predicate is marked as an @list in the context\n            const parentContext = await parsingContext.getContext(keys.slice(0, -1));\n            if ('@list' in Util_1.Util.getContextValueContainer(parentContext, parentKey)) {\n                // Our value is part of an array\n                // Emit the given objects as list elements\n                parsingContext.emittedStack[depth + 1] = true; // Ensure the creation of bnodes for empty nodes\n                const values = await util.valueToTerm(await parsingContext.getContext(keys), parentKey, value, depth, keys);\n                for (const object of values) {\n                    await this.handleListElement(parsingContext, util, object, value, depth, keys.slice(0, -1), depth - 1);\n                }\n                // If no values were found, emit a falsy list element to force an empty RDF list to be emitted.\n                if (values.length === 0) {\n                    await this.handleListElement(parsingContext, util, null, value, depth, keys.slice(0, -1), depth - 1);\n                }\n            }\n            else {\n                // Copy the stack values up one level so that the next job can access them.\n                parsingContext.shiftStack(depth, 1);\n                // Execute the job one level higher\n                await parsingContext.newOnValueJob(keys.slice(0, -1), value, depth - 1, false);\n                // Remove any defined contexts at this level to avoid it to propagate to the next array element.\n                parsingContext.contextTree.removeContext(keys.slice(0, -1));\n            }\n        }\n    }\n    async handleListElement(parsingContext, util, value, valueOriginal, depth, listRootKeys, listRootDepth) {\n        // Buffer our value as an RDF list using the listRootKey as predicate\n        let listPointer = parsingContext.listPointerStack[depth];\n        if (valueOriginal !== null && (await util.unaliasKeywords(valueOriginal, listRootKeys, depth))['@value'] !== null) {\n            if (!listPointer || !listPointer.value) {\n                const linkTerm = util.dataFactory.blankNode();\n                listPointer = { value: linkTerm, listRootDepth, listId: linkTerm };\n            }\n            else {\n                // rdf:rest links are always emitted before the next element,\n                // as the blank node identifier is only created at that point.\n                // Because of this reason, the final rdf:nil is emitted when the stack depth is decreased.\n                const newLinkTerm = util.dataFactory.blankNode();\n                parsingContext.emitQuad(depth, util.dataFactory.quad(listPointer.value, util.rdfRest, newLinkTerm, util.getDefaultGraph()));\n                // Update the list pointer for the next element\n                listPointer.value = newLinkTerm;\n            }\n            // Emit a list element for the current value\n            // Omit rdf:first if the value is invalid\n            if (value) {\n                parsingContext.emitQuad(depth, util.dataFactory.quad(listPointer.value, util.rdfFirst, value, util.getDefaultGraph()));\n            }\n        }\n        else {\n            // A falsy list element if found.\n            // Mark it as an rdf:nil list until another valid list element comes in\n            if (!listPointer) {\n                listPointer = { listRootDepth, listId: util.rdfNil };\n            }\n        }\n        parsingContext.listPointerStack[depth] = listPointer;\n        // Error if an annotation was defined\n        if (parsingContext.rdfstar && parsingContext.annotationsBuffer[depth]) {\n            parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found an illegal annotation inside a list`, jsonld_context_parser_1.ERROR_CODES.INVALID_ANNOTATION));\n        }\n    }\n}\nexports.EntryHandlerArrayValue = EntryHandlerArrayValue;\n//# sourceMappingURL=EntryHandlerArrayValue.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerContainer = void 0;\nconst ContainerHandlerIdentifier_1 = require(\"../containerhandler/ContainerHandlerIdentifier\");\nconst ContainerHandlerIndex_1 = require(\"../containerhandler/ContainerHandlerIndex\");\nconst ContainerHandlerLanguage_1 = require(\"../containerhandler/ContainerHandlerLanguage\");\nconst ContainerHandlerType_1 = require(\"../containerhandler/ContainerHandlerType\");\nconst Util_1 = require(\"../Util\");\n/**\n * Handles values that are part of a container type (like @index),\n * as specified by {@link IContainerHandler}.\n */\nclass EntryHandlerContainer {\n    /**\n     * Check fit the given container is a simple @graph container.\n     * Concretely, it will check if no @index or @id is active as well.\n     * @param containers A container hash.\n     */\n    static isSimpleGraphContainer(containers) {\n        return '@graph' in containers\n            && (('@set' in containers && Object.keys(containers).length === 2) || Object.keys(containers).length === 1);\n    }\n    /**\n     * Check fit the given container is a complex @graph container.\n     * Concretely, it will check if @index or @id is active as well next to @graph.\n     * @param containers A container hash.\n     */\n    static isComplexGraphContainer(containers) {\n        return '@graph' in containers\n            && (('@set' in containers && Object.keys(containers).length > 2)\n                || (!('@set' in containers) && Object.keys(containers).length > 1));\n    }\n    /**\n     * Create an graph container index that can be used for identifying a graph term inside the graphContainerTermStack.\n     * @param containers The applicable containers.\n     * @param depth The container depth.\n     * @param keys The array of keys.\n     * @return The graph index.\n     */\n    static getContainerGraphIndex(containers, depth, keys) {\n        let isSimpleGraphContainer = EntryHandlerContainer.isSimpleGraphContainer(containers);\n        let index = '';\n        for (let i = depth; i < keys.length; i++) {\n            if (!isSimpleGraphContainer || typeof keys[i] === 'number') {\n                index += ':' + keys[i];\n            }\n            // Only allow a second 'real' key if in a non-simple graph container.\n            if (!isSimpleGraphContainer && typeof keys[i] !== 'number') {\n                isSimpleGraphContainer = true;\n            }\n        }\n        return index;\n    }\n    /**\n     * Return the applicable container type at the given depth.\n     *\n     * This will ignore any arrays in the key chain.\n     *\n     * @param {ParsingContext} parsingContext A parsing context.\n     * @param {any[]} keys The array of keys.\n     * @param {number} depth The current depth.\n     * @return {Promise<{ containers: {[typeName: string]: boolean}, depth: number, fallback: boolean }>}\n     *          All applicable containers for the given depth,\n     *          the `depth` of the container root (can change when arrays are in the key chain),\n     *          and the `fallback` flag that indicates if the default container type was returned\n     *            (i.e., no dedicated container type is defined).\n     */\n    static async getContainerHandler(parsingContext, keys, depth) {\n        const fallback = {\n            containers: { '@set': true },\n            depth,\n            fallback: true,\n        };\n        // A flag that is enabled when @graph container should be tested in next iteration\n        let checkGraphContainer = false;\n        // Iterate from deeper to higher\n        const context = await parsingContext.getContext(keys, 2);\n        for (let i = depth - 1; i >= 0; i--) {\n            if (typeof keys[i] !== 'number') { // Skip array keys\n                // @graph containers without any other types are one level less deep, and require special handling\n                const containersSelf = Util_1.Util.getContextValue(context, '@container', keys[i], false);\n                if (containersSelf && EntryHandlerContainer.isSimpleGraphContainer(containersSelf)) {\n                    return {\n                        containers: containersSelf,\n                        depth: i + 1,\n                        fallback: false,\n                    };\n                }\n                const containersParent = Util_1.Util.getContextValue(context, '@container', keys[i - 1], false);\n                if (!containersParent) { // If we have the fallback container value\n                    if (checkGraphContainer) {\n                        // Return false if we were already expecting a @graph-@id of @graph-@index container\n                        return fallback;\n                    }\n                    // Check parent-parent, we may be in a @graph-@id of @graph-@index container, which have two levels\n                    checkGraphContainer = true;\n                }\n                else {\n                    // We had an invalid container next iteration, so we now have to check if we were in an @graph container\n                    const graphContainer = '@graph' in containersParent;\n                    // We're in a regular container\n                    for (const containerHandleName in EntryHandlerContainer.CONTAINER_HANDLERS) {\n                        if (containersParent[containerHandleName]) {\n                            if (graphContainer) {\n                                // Only accept graph containers if their combined handlers can handle them.\n                                if (EntryHandlerContainer.CONTAINER_HANDLERS[containerHandleName].canCombineWithGraph()) {\n                                    return {\n                                        containers: containersParent,\n                                        depth: i,\n                                        fallback: false,\n                                    };\n                                }\n                                else {\n                                    return fallback;\n                                }\n                            }\n                            else {\n                                // Only accept if we were not expecting a @graph-@id of @graph-@index container\n                                if (checkGraphContainer) {\n                                    return fallback;\n                                }\n                                else {\n                                    return {\n                                        containers: containersParent,\n                                        depth: i,\n                                        fallback: false,\n                                    };\n                                }\n                            }\n                        }\n                    }\n                    // Fail if no valid container handlers were found\n                    return fallback;\n                }\n            }\n        }\n        return fallback;\n    }\n    /**\n     * Check if we are handling a value at the given depth\n     * that is part of something that should be handled as a container,\n     * AND if this container should be buffered, so that it can be handled by a dedicated container handler.\n     *\n     * For instance, any container with @graph will NOT be buffered.\n     *\n     * This will ignore any arrays in the key chain.\n     *\n     * @param {ParsingContext} parsingContext A parsing context.\n     * @param {any[]} keys The array of keys.\n     * @param {number} depth The current depth.\n     * @return {Promise<boolean>} If we are in the scope of a container handler.\n     */\n    static async isBufferableContainerHandler(parsingContext, keys, depth) {\n        const handler = await EntryHandlerContainer.getContainerHandler(parsingContext, keys, depth);\n        return !handler.fallback && !('@graph' in handler.containers);\n    }\n    isPropertyHandler() {\n        return false;\n    }\n    isStackProcessor() {\n        return true;\n    }\n    async validate(parsingContext, util, keys, depth, inProperty) {\n        return !!await this.test(parsingContext, util, null, keys, depth);\n    }\n    async test(parsingContext, util, key, keys, depth) {\n        const containers = Util_1.Util.getContextValueContainer(await parsingContext.getContext(keys, 2), keys[depth - 1]);\n        for (const containerName in EntryHandlerContainer.CONTAINER_HANDLERS) {\n            if (containers[containerName]) {\n                return {\n                    containers,\n                    handler: EntryHandlerContainer.CONTAINER_HANDLERS[containerName],\n                };\n            }\n        }\n        return null;\n    }\n    async handle(parsingContext, util, key, keys, value, depth, testResult) {\n        return testResult.handler.handle(testResult.containers, parsingContext, util, keys, value, depth);\n    }\n}\nEntryHandlerContainer.CONTAINER_HANDLERS = {\n    '@id': new ContainerHandlerIdentifier_1.ContainerHandlerIdentifier(),\n    '@index': new ContainerHandlerIndex_1.ContainerHandlerIndex(),\n    '@language': new ContainerHandlerLanguage_1.ContainerHandlerLanguage(),\n    '@type': new ContainerHandlerType_1.ContainerHandlerType(),\n};\nexports.EntryHandlerContainer = EntryHandlerContainer;\n//# sourceMappingURL=EntryHandlerContainer.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerInvalidFallback = void 0;\n/**\n * A catch-all for properties, that will either emit an error or ignore,\n * depending on whether or not the `strictValues` property is set.\n */\nclass EntryHandlerInvalidFallback {\n    isPropertyHandler() {\n        return false;\n    }\n    isStackProcessor() {\n        return true;\n    }\n    async validate(parsingContext, util, keys, depth, inProperty) {\n        return false;\n    }\n    async test(parsingContext, util, key, keys, depth) {\n        return true;\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        parsingContext.emittedStack[depth] = false;\n    }\n}\nexports.EntryHandlerInvalidFallback = EntryHandlerInvalidFallback;\n//# sourceMappingURL=EntryHandlerInvalidFallback.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerPredicate = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\nconst Util_1 = require(\"../Util\");\n/**\n * Interprets keys as predicates.\n * The most common case in JSON-LD processing.\n */\nclass EntryHandlerPredicate {\n    /**\n     * Handle the given predicate-object by either emitting it,\n     * or by placing it in the appropriate stack for later emission when no @graph and/or @id has been defined.\n     * @param {ParsingContext} parsingContext A parsing context.\n     * @param {Util} util A utility instance.\n     * @param {any[]} keys A stack of keys.\n     * @param {number} depth The current depth.\n     * @param {Term} predicate The predicate.\n     * @param {Term} object The object.\n     * @param {boolean} reverse If the property is reversed.\n     * @param {boolean} isEmbedded If the property exists in an embedded node as direct child.\n     * @param {boolean} isAnnotation If the property exists in an annotation object.\n     * @return {Promise<void>} A promise resolving when handling is done.\n     */\n    static async handlePredicateObject(parsingContext, util, keys, depth, predicate, object, reverse, isEmbedded, isAnnotation) {\n        const depthProperties = await util.getPropertiesDepth(keys, depth);\n        const depthOffsetGraph = await util.getDepthOffsetGraph(depth, keys);\n        const depthPropertiesGraph = depth - depthOffsetGraph;\n        const subjects = parsingContext.idStack[depthProperties];\n        if (subjects && !isAnnotation) {\n            // Emit directly if the @id was already defined\n            for (const subject of subjects) {\n                // Check if we're in a @graph context\n                const atGraph = depthOffsetGraph >= 0;\n                if (atGraph) {\n                    const graphs = parsingContext.idStack[depthPropertiesGraph - 1];\n                    if (graphs) {\n                        for (const graph of graphs) {\n                            // Emit our quad if graph @id is known\n                            util.emitQuadChecked(depth, subject, predicate, object, graph, reverse, isEmbedded);\n                        }\n                    }\n                    else {\n                        // Buffer our triple if graph @id is not known yet.\n                        if (reverse) {\n                            util.validateReverseSubject(object);\n                            parsingContext.getUnidentifiedGraphBufferSafe(depthPropertiesGraph - 1).push({ subject: object, predicate, object: subject, isEmbedded });\n                        }\n                        else {\n                            parsingContext.getUnidentifiedGraphBufferSafe(depthPropertiesGraph - 1)\n                                .push({ subject, predicate, object, isEmbedded });\n                        }\n                    }\n                }\n                else {\n                    // Emit if no @graph was applicable\n                    const graph = await util.getGraphContainerValue(keys, depthProperties);\n                    util.emitQuadChecked(depth, subject, predicate, object, graph, reverse, isEmbedded);\n                }\n            }\n        }\n        else {\n            // Buffer until our @id becomes known, or we go up the stack\n            if (reverse) {\n                util.validateReverseSubject(object);\n            }\n            // Either push to the annotations or the actual value buffer\n            if (isAnnotation) {\n                // Only add to buffer if rdfstar is enabled\n                if (parsingContext.rdfstar) {\n                    // Error if an @id was defined\n                    if (parsingContext.idStack[depth]) {\n                        parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found an illegal @id inside an annotation: ${parsingContext.idStack[depth][0].value}`, jsonld_context_parser_1.ERROR_CODES.INVALID_ANNOTATION));\n                    }\n                    // Error if we're in an embedded node\n                    for (let i = 0; i < depth; i++) {\n                        if (await util.unaliasKeyword(keys[i], keys, i) === '@id') {\n                            parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found an illegal annotation inside an embedded node`, jsonld_context_parser_1.ERROR_CODES.INVALID_ANNOTATION));\n                        }\n                    }\n                    // Store new annotation in the buffer\n                    const annotationsBuffer = parsingContext.getAnnotationsBufferSafe(depthProperties);\n                    const newAnnotation = { predicate, object, reverse, nestedAnnotations: [], depth: depthProperties };\n                    annotationsBuffer.push(newAnnotation);\n                    // Check in the buffer if any annotations were defined at a deeper depth,\n                    // if so, they are considered nested annotations.\n                    for (let i = annotationsBuffer.length - 2; i >= 0; i--) {\n                        // We iterate in reverse order, to enable easy item removal from the back.\n                        const existingAnnotation = annotationsBuffer[i];\n                        if (existingAnnotation.depth > depthProperties) {\n                            newAnnotation.nestedAnnotations.push(existingAnnotation);\n                            annotationsBuffer.splice(i, 1);\n                        }\n                    }\n                }\n            }\n            else {\n                parsingContext.getUnidentifiedValueBufferSafe(depthProperties).push({ predicate, object, reverse, isEmbedded });\n            }\n        }\n    }\n    isPropertyHandler() {\n        return true;\n    }\n    isStackProcessor() {\n        return true;\n    }\n    async validate(parsingContext, util, keys, depth, inProperty) {\n        const key = keys[depth];\n        if (key) {\n            const context = await parsingContext.getContext(keys);\n            if (!parsingContext.jsonLiteralStack[depth] && await util.predicateToTerm(context, keys[depth])) {\n                // If this valid predicate is of type @json, mark it so in the stack so that no deeper handling of nodes occurs.\n                if (Util_1.Util.getContextValueType(context, key) === '@json') {\n                    parsingContext.jsonLiteralStack[depth + 1] = true;\n                }\n                return true;\n            }\n        }\n        return false;\n    }\n    async test(parsingContext, util, key, keys, depth) {\n        return keys[depth];\n    }\n    async handle(parsingContext, util, key, keys, value, depth, testResult) {\n        const keyOriginal = keys[depth];\n        const context = await parsingContext.getContext(keys);\n        const predicate = await util.predicateToTerm(context, key);\n        if (predicate) {\n            const objects = await util.valueToTerm(context, key, value, depth, keys);\n            if (objects.length) {\n                for (let object of objects) {\n                    // Based on parent key, check if reverse, embedded, and annotation.\n                    let parentKey = await util.unaliasKeywordParent(keys, depth);\n                    const reverse = Util_1.Util.isPropertyReverse(context, keyOriginal, parentKey);\n                    let parentDepthOffset = 0;\n                    while (parentKey === '@reverse' || typeof parentKey === 'number') {\n                        // Check parent of parent when checking while we're in an array or in @reverse\n                        if (typeof parentKey === 'number') {\n                            parentDepthOffset++;\n                        }\n                        else {\n                            depth--;\n                        }\n                        parentKey = await util.unaliasKeywordParent(keys, depth - parentDepthOffset);\n                    }\n                    const isEmbedded = Util_1.Util.isPropertyInEmbeddedNode(parentKey);\n                    util.validateReverseInEmbeddedNode(key, reverse, isEmbedded);\n                    const isAnnotation = Util_1.Util.isPropertyInAnnotationObject(parentKey);\n                    if (value) {\n                        // Special case if our term was defined as an @list, but does not occur in an array,\n                        // In that case we just emit it as an RDF list with a single element.\n                        const listValueContainer = '@list' in Util_1.Util.getContextValueContainer(context, key);\n                        if (listValueContainer || value['@list']) {\n                            if (((listValueContainer && !Array.isArray(value) && !value['@list'])\n                                || (value['@list'] && !Array.isArray(value['@list'])))\n                                && object !== util.rdfNil) {\n                                const listPointer = util.dataFactory.blankNode();\n                                parsingContext.emitQuad(depth, util.dataFactory.quad(listPointer, util.rdfRest, util.rdfNil, util.getDefaultGraph()));\n                                parsingContext.emitQuad(depth, util.dataFactory.quad(listPointer, util.rdfFirst, object, util.getDefaultGraph()));\n                                object = listPointer;\n                            }\n                            // Lists are not allowed in @reverse'd properties\n                            if (reverse && !parsingContext.allowSubjectList) {\n                                throw new jsonld_context_parser_1.ErrorCoded(`Found illegal list value in subject position at ${key}`, jsonld_context_parser_1.ERROR_CODES.INVALID_REVERSE_PROPERTY_VALUE);\n                            }\n                        }\n                    }\n                    await EntryHandlerPredicate.handlePredicateObject(parsingContext, util, keys, depth, predicate, object, reverse, isEmbedded, isAnnotation);\n                }\n            }\n        }\n    }\n}\nexports.EntryHandlerPredicate = EntryHandlerPredicate;\n//# sourceMappingURL=EntryHandlerPredicate.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerKeyword = void 0;\n/**\n * An abstract keyword entry handler.\n */\nclass EntryHandlerKeyword {\n    constructor(keyword) {\n        this.keyword = keyword;\n    }\n    isPropertyHandler() {\n        return false;\n    }\n    isStackProcessor() {\n        return true;\n    }\n    async validate(parsingContext, util, keys, depth, inProperty) {\n        return false;\n    }\n    async test(parsingContext, util, key, keys, depth) {\n        return key === this.keyword;\n    }\n}\nexports.EntryHandlerKeyword = EntryHandlerKeyword;\n//# sourceMappingURL=EntryHandlerKeyword.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerKeywordAnnotation = void 0;\nconst EntryHandlerKeyword_1 = require(\"./EntryHandlerKeyword\");\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\n/**\n * Handles @annotation entries.\n */\nclass EntryHandlerKeywordAnnotation extends EntryHandlerKeyword_1.EntryHandlerKeyword {\n    constructor() {\n        super('@annotation');\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        // Validate value\n        if (typeof value === 'string' || (typeof value === 'object' && value['@value'])) {\n            parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found illegal annotation value: ${JSON.stringify(value)}`, jsonld_context_parser_1.ERROR_CODES.INVALID_ANNOTATION));\n        }\n        // Rest of the processing is done as regular nodes\n    }\n}\nexports.EntryHandlerKeywordAnnotation = EntryHandlerKeywordAnnotation;\n//# sourceMappingURL=EntryHandlerKeywordAnnotation.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerKeywordContext = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\nconst EntryHandlerKeyword_1 = require(\"./EntryHandlerKeyword\");\n/**\n * Handles @context entries.\n */\nclass EntryHandlerKeywordContext extends EntryHandlerKeyword_1.EntryHandlerKeyword {\n    constructor() {\n        super('@context');\n    }\n    isStackProcessor() {\n        return false;\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        // Error if an out-of-order context was found when support is not enabled.\n        if (parsingContext.streamingProfile\n            && (parsingContext.processingStack[depth]\n                || parsingContext.processingType[depth]\n                || parsingContext.idStack[depth] !== undefined)) {\n            parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded('Found an out-of-order context, while streaming is enabled.' +\n                '(disable `streamingProfile`)', jsonld_context_parser_1.ERROR_CODES.INVALID_STREAMING_KEY_ORDER));\n        }\n        // Find the parent context to inherit from.\n        // We actually request a context for the current depth (with fallback to parent)\n        // because we want to take into account any property-scoped contexts that are defined for this depth.\n        const parentContext = parsingContext.getContext(keys);\n        // Set the context for this scope\n        const context = parsingContext.parseContext(value, (await parentContext).getContextRaw());\n        parsingContext.contextTree.setContext(keys.slice(0, -1), context);\n        parsingContext.emitContext(value);\n        await parsingContext.validateContext(await context);\n    }\n}\nexports.EntryHandlerKeywordContext = EntryHandlerKeywordContext;\n//# sourceMappingURL=EntryHandlerKeywordContext.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerKeywordGraph = void 0;\nconst EntryHandlerKeyword_1 = require(\"./EntryHandlerKeyword\");\n/**\n * Handles @graph entries.\n */\nclass EntryHandlerKeywordGraph extends EntryHandlerKeyword_1.EntryHandlerKeyword {\n    constructor() {\n        super('@graph');\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        // The current identifier identifies a graph for the deeper level.\n        parsingContext.graphStack[depth + 1] = true;\n    }\n}\nexports.EntryHandlerKeywordGraph = EntryHandlerKeywordGraph;\n//# sourceMappingURL=EntryHandlerKeywordGraph.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerKeywordId = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\nconst EntryHandlerKeyword_1 = require(\"./EntryHandlerKeyword\");\n/**\n * Handles @id entries.\n */\nclass EntryHandlerKeywordId extends EntryHandlerKeyword_1.EntryHandlerKeyword {\n    constructor() {\n        super('@id');\n    }\n    isStackProcessor() {\n        return false;\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        if (typeof value !== 'string') {\n            // JSON-LD-star allows @id object values\n            if (parsingContext.rdfstar && typeof value === 'object') {\n                const valueKeys = Object.keys(value);\n                if (valueKeys.length === 1 && valueKeys[0] === '@id') {\n                    parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Invalid embedded node without property with @id ${value['@id']}`, jsonld_context_parser_1.ERROR_CODES.INVALID_EMBEDDED_NODE));\n                }\n            }\n            else {\n                parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found illegal @id '${value}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_ID_VALUE));\n            }\n            return;\n        }\n        // Determine the canonical place for this id.\n        // For example, @nest parents should be ignored.\n        const depthProperties = await util.getPropertiesDepth(keys, depth);\n        // Error if an @id for this node already existed.\n        if (parsingContext.idStack[depthProperties] !== undefined) {\n            if (parsingContext.idStack[depthProperties][0].listHead) {\n                // Error if an @list was already defined for this node\n                parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found illegal neighbouring entries next to @list for key: '${keys[depth - 1]}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_SET_OR_LIST_OBJECT));\n            }\n            else {\n                // Otherwise, the previous id was just because of an @id entry.\n                parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found duplicate @ids '${parsingContext\n                    .idStack[depthProperties][0].value}' and '${value}'`, jsonld_context_parser_1.ERROR_CODES.COLLIDING_KEYWORDS));\n            }\n        }\n        // Error if an annotation was defined\n        if (parsingContext.rdfstar && parsingContext.annotationsBuffer[depth]) {\n            for (const annotation of parsingContext.annotationsBuffer[depth]) {\n                if (annotation.depth === depth) {\n                    parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found an illegal @id inside an annotation: ${value}`, jsonld_context_parser_1.ERROR_CODES.INVALID_ANNOTATION));\n                }\n            }\n        }\n        // Save our @id on the stack\n        parsingContext.idStack[depthProperties] = util.nullableTermToArray(await util.resourceToTerm(await parsingContext.getContext(keys), value));\n    }\n}\nexports.EntryHandlerKeywordId = EntryHandlerKeywordId;\n//# sourceMappingURL=EntryHandlerKeywordId.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerKeywordIncluded = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\nconst EntryHandlerKeyword_1 = require(\"./EntryHandlerKeyword\");\n/**\n * Handles @included entries.\n */\nclass EntryHandlerKeywordIncluded extends EntryHandlerKeyword_1.EntryHandlerKeyword {\n    constructor() {\n        super('@included');\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        if (typeof value !== 'object') {\n            parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found illegal @included '${value}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_INCLUDED_VALUE));\n        }\n        const valueUnliased = await util.unaliasKeywords(value, keys, depth, await parsingContext.getContext(keys));\n        if ('@value' in valueUnliased) {\n            parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found an illegal @included @value node '${JSON.stringify(value)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_INCLUDED_VALUE));\n        }\n        if ('@list' in valueUnliased) {\n            parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found an illegal @included @list node '${JSON.stringify(value)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_INCLUDED_VALUE));\n        }\n        parsingContext.emittedStack[depth] = false;\n    }\n}\nexports.EntryHandlerKeywordIncluded = EntryHandlerKeywordIncluded;\n//# sourceMappingURL=EntryHandlerKeywordIncluded.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerKeywordNest = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\nconst EntryHandlerKeyword_1 = require(\"./EntryHandlerKeyword\");\n/**\n * Handles @nest entries.\n */\nclass EntryHandlerKeywordNest extends EntryHandlerKeyword_1.EntryHandlerKeyword {\n    constructor() {\n        super('@nest');\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        if (typeof value !== 'object') {\n            parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found invalid @nest entry for '${key}': '${value}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_NEST_VALUE));\n        }\n        if ('@value' in await util.unaliasKeywords(value, keys, depth, await parsingContext.getContext(keys))) {\n            parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found an invalid @value node for '${key}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_NEST_VALUE));\n        }\n        parsingContext.emittedStack[depth] = false;\n    }\n}\nexports.EntryHandlerKeywordNest = EntryHandlerKeywordNest;\n//# sourceMappingURL=EntryHandlerKeywordNest.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerKeywordType = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\nconst Util_1 = require(\"../../Util\");\nconst EntryHandlerPredicate_1 = require(\"../EntryHandlerPredicate\");\nconst EntryHandlerKeyword_1 = require(\"./EntryHandlerKeyword\");\n/**\n * Handles @graph entries.\n */\nclass EntryHandlerKeywordType extends EntryHandlerKeyword_1.EntryHandlerKeyword {\n    constructor() {\n        super('@type');\n    }\n    isStackProcessor() {\n        return false;\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        const keyOriginal = keys[depth];\n        // The current identifier identifies an rdf:type predicate.\n        // But we only emit it once the node closes,\n        // as it's possible that the @type is used to identify the datatype of a literal, which we ignore here.\n        const context = await parsingContext.getContext(keys);\n        const predicate = util.rdfType;\n        const parentKey = await util.unaliasKeywordParent(keys, depth);\n        const reverse = Util_1.Util.isPropertyReverse(context, keyOriginal, parentKey);\n        const isEmbedded = Util_1.Util.isPropertyInEmbeddedNode(parentKey);\n        util.validateReverseInEmbeddedNode(key, reverse, isEmbedded);\n        const isAnnotation = Util_1.Util.isPropertyInAnnotationObject(parentKey);\n        // Handle multiple values if the value is an array\n        const elements = Array.isArray(value) ? value : [value];\n        for (const element of elements) {\n            if (typeof element !== 'string') {\n                parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found illegal @type '${element}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_TYPE_VALUE));\n            }\n            const type = util.createVocabOrBaseTerm(context, element);\n            if (type) {\n                await EntryHandlerPredicate_1.EntryHandlerPredicate.handlePredicateObject(parsingContext, util, keys, depth, predicate, type, reverse, isEmbedded, isAnnotation);\n            }\n        }\n        // Collect type-scoped contexts if they exist\n        let scopedContext = Promise.resolve(context);\n        let hasTypedScopedContext = false;\n        for (const element of elements.sort()) { // Spec requires lexicographical ordering\n            const typeContext = Util_1.Util.getContextValue(context, '@context', element, null);\n            if (typeContext) {\n                hasTypedScopedContext = true;\n                scopedContext = scopedContext.then((c) => parsingContext.parseContext(typeContext, c.getContextRaw()));\n            }\n        }\n        // Error if an out-of-order type-scoped context was found when support is not enabled.\n        if (parsingContext.streamingProfile\n            && (hasTypedScopedContext || !parsingContext.streamingProfileAllowOutOfOrderPlainType)\n            && (parsingContext.processingStack[depth] || parsingContext.idStack[depth])) {\n            parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded('Found an out-of-order type-scoped context, while streaming is enabled.' +\n                '(disable `streamingProfile`)', jsonld_context_parser_1.ERROR_CODES.INVALID_STREAMING_KEY_ORDER));\n        }\n        // If at least least one type-scoped context applies, set them in the tree.\n        if (hasTypedScopedContext) {\n            // Do not propagate by default\n            scopedContext = scopedContext.then((c) => {\n                // Set the original context at this depth as a fallback\n                // This is needed when a context was already defined at the given depth,\n                // and this context needs to remain accessible from child nodes when propagation is disabled.\n                if (c.getContextRaw()['@propagate'] !== true) {\n                    return new jsonld_context_parser_1.JsonLdContextNormalized(Object.assign(Object.assign({}, c.getContextRaw()), { '@propagate': false, '@__propagateFallback': context.getContextRaw() }));\n                }\n                return c;\n            });\n            // Set the new context in the context tree\n            parsingContext.contextTree.setContext(keys.slice(0, keys.length - 1), scopedContext);\n        }\n        // Flag that type has been processed at this depth\n        parsingContext.processingType[depth] = true;\n    }\n}\nexports.EntryHandlerKeywordType = EntryHandlerKeywordType;\n//# sourceMappingURL=EntryHandlerKeywordType.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerKeywordUnknownFallback = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\n/**\n * A catch-all for keywords, that will either emit an error or ignore,\n * depending on whether or not the `strictValues` property is set.\n */\nclass EntryHandlerKeywordUnknownFallback {\n    isPropertyHandler() {\n        return false;\n    }\n    isStackProcessor() {\n        return true;\n    }\n    async validate(parsingContext, util, keys, depth, inProperty) {\n        const key = await util.unaliasKeyword(keys[depth], keys, depth);\n        if (jsonld_context_parser_1.Util.isPotentialKeyword(key)) {\n            // Don't emit anything inside free-floating lists\n            if (!inProperty) {\n                if (key === '@list') {\n                    return false;\n                }\n            }\n            return true;\n        }\n        return false;\n    }\n    async test(parsingContext, util, key, keys, depth) {\n        return jsonld_context_parser_1.Util.isPotentialKeyword(key);\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        const keywordType = EntryHandlerKeywordUnknownFallback.VALID_KEYWORDS_TYPES[key];\n        if (keywordType !== undefined) {\n            if (keywordType && typeof value !== keywordType.type) {\n                parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Invalid value type for '${key}' with value '${value}'`, keywordType.errorCode));\n            }\n        }\n        else if (parsingContext.strictValues) {\n            parsingContext.emitError(new Error(`Unknown keyword '${key}' with value '${value}'`));\n        }\n        parsingContext.emittedStack[depth] = false;\n    }\n}\nEntryHandlerKeywordUnknownFallback.VALID_KEYWORDS_TYPES = {\n    '@index': { type: 'string', errorCode: jsonld_context_parser_1.ERROR_CODES.INVALID_INDEX_VALUE },\n    '@list': null,\n    '@reverse': { type: 'object', errorCode: jsonld_context_parser_1.ERROR_CODES.INVALID_REVERSE_VALUE },\n    '@set': null,\n    '@value': null,\n};\nexports.EntryHandlerKeywordUnknownFallback = EntryHandlerKeywordUnknownFallback;\n//# sourceMappingURL=EntryHandlerKeywordUnknownFallback.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerKeywordValue = void 0;\nconst EntryHandlerKeyword_1 = require(\"./EntryHandlerKeyword\");\n/**\n * Handles @value entries.\n */\nclass EntryHandlerKeywordValue extends EntryHandlerKeyword_1.EntryHandlerKeyword {\n    constructor() {\n        super('@value');\n    }\n    async validate(parsingContext, util, keys, depth, inProperty) {\n        // If this is @value, mark it so in the stack so that no deeper handling of nodes occurs.\n        const key = keys[depth];\n        if (key && !parsingContext.literalStack[depth] && await this.test(parsingContext, util, key, keys, depth)) {\n            parsingContext.literalStack[depth] = true;\n        }\n        return super.validate(parsingContext, util, keys, depth, inProperty);\n    }\n    async test(parsingContext, util, key, keys, depth) {\n        return await util.unaliasKeyword(keys[depth], keys.slice(0, keys.length - 1), depth - 1, true) === '@value';\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        // If the value is valid, indicate that we are processing a literal.\n        // The actual value will be determined at the parent level when the @value is part of an object,\n        // because we may want to take into account additional entries such as @language.\n        // See {@link Util.valueToTerm}\n        // Indicate that we are processing a literal, and that no later predicates should be parsed at this depth.\n        parsingContext.literalStack[depth] = true;\n        // Void any buffers that we may have accumulated up until now\n        delete parsingContext.unidentifiedValuesBuffer[depth];\n        delete parsingContext.unidentifiedGraphsBuffer[depth];\n        // Indicate that we have not emitted at this depth\n        parsingContext.emittedStack[depth] = false;\n    }\n}\nexports.EntryHandlerKeywordValue = EntryHandlerKeywordValue;\n//# sourceMappingURL=EntryHandlerKeywordValue.js.map","import rdf from '@rdfjs/data-model'\nimport toReadable from 'duplex-to/readable.js'\nimport { JsonLdParser } from 'jsonld-streaming-parser'\nimport { Transform } from 'readable-stream'\n\nconst relativeIriProtocol = 'null:'\n\nfunction termCleanup (factory) {\n  return term => {\n    if (term.termType !== 'NamedNode') {\n      return null\n    }\n\n    if (!term.value.startsWith(relativeIriProtocol)) {\n      return null\n    }\n\n    // remove dummy protocol workaround for relative IRIs\n    return factory.namedNode(term.value.slice(relativeIriProtocol.length))\n  }\n}\n\nfunction quadCleanup (factory) {\n  const cleanup = termCleanup(factory)\n\n  return quad => {\n    const subject = cleanup(quad.subject)\n    const predicate = cleanup(quad.predicate)\n    const object = cleanup(quad.object)\n    const graph = cleanup(quad.graph)\n\n    if (subject || predicate || object || graph) {\n      return factory.quad(\n        subject || quad.subject,\n        predicate || quad.predicate,\n        object || quad.object,\n        graph || quad.graph\n      )\n    }\n\n    return quad\n  }\n}\n\nclass ParserStream {\n  constructor (input, { baseIRI = relativeIriProtocol, context = null, documentLoader, factory = rdf } = {}) {\n    const parser = new JsonLdParser({\n      baseIRI,\n      context,\n      dataFactory: factory,\n      documentLoader,\n      streamingProfile: false\n    })\n\n    input.pipe(parser)\n\n    const cleanup = quadCleanup(factory)\n\n    const transform = new Transform({\n      objectMode: true,\n      transform: (quad, encoding, callback) => {\n        callback(null, cleanup(quad))\n      }\n    })\n\n    parser.on('context', context => {\n      Object.entries(context).forEach(([prefix, iri]) => {\n        transform.emit('prefix', prefix, factory.namedNode(iri))\n      })\n    })\n    parser.on('error', err => transform.destroy(err))\n    parser.pipe(transform)\n\n    return toReadable(transform)\n  }\n}\n\nexport default ParserStream\n","import Sink from '@rdfjs/sink'\nimport ParserStream from './lib/ParserStream.js'\n\nclass Parser extends Sink {\n  constructor (options) {\n    super(ParserStream, options)\n  }\n}\n\nexport default Parser\n","class Sink {\n  constructor (Impl, options) {\n    this.Impl = Impl\n    this.options = options\n  }\n\n  import (input, options) {\n    const output = new this.Impl(input, { ...this.options, ...options })\n\n    input.on('end', () => {\n      if (!output.readable) {\n        output.emit('end')\n      }\n    })\n\n    input.on('error', err => {\n      output.emit('error', err)\n    })\n\n    return output\n  }\n}\n\nexport default Sink\n","const blackList = new Set(['_write', '_writableState', 'writable'])\n\nfunction readable (duplex) {\n  return new Proxy(duplex, {\n    has (target, key) {\n      if (blackList.has(key)) {\n        return false\n      }\n\n      return Reflect.has(...arguments)\n    },\n    get (target, key) {\n      if (blackList.has(key)) {\n        return undefined\n      }\n\n      const result = Reflect.get(...arguments)\n\n      if (result && typeof result.bind === 'function') {\n        return result.bind(target)\n      }\n\n      return result\n    },\n    set (target, key, value) {\n      if (blackList.has(key)) {\n        return undefined\n      }\n\n      return Reflect.set(...arguments)\n    }\n  })\n}\n\nexport default readable\n"],"names":["Buffer","C","LEFT_BRACE","RIGHT_BRACE","LEFT_BRACKET","RIGHT_BRACKET","COLON","COMMA","TRUE","FALSE","NULL","STRING","NUMBER","START","STOP","TRUE1","TRUE2","TRUE3","FALSE1","FALSE2","FALSE3","FALSE4","NULL1","NULL2","NULL3","NUMBER1","NUMBER3","STRING1","STRING2","STRING3","STRING4","STRING5","STRING6","VALUE","KEY","OBJECT","ARRAY","BACK_SLASH","charCodeAt","FORWARD_SLASH","BACKSPACE","FORM_FEED","NEWLINE","CARRIAGE_RETURN","TAB","STRING_BUFFER_SIZE","alloc","size","Parser","this","tState","value","undefined","string","stringBuffer","stringBufferOffset","unicode","highSurrogate","key","mode","stack","state","bytes_remaining","bytes_in_sequence","temp_buffs","offset","toknam","code","keys","Object","i","l","length","toString","proto","prototype","onError","err","charError","buffer","Error","JSON","stringify","String","fromCharCode","appendStringChar","char","appendStringBuf","buf","start","end","copy","write","n","onToken","j","k","byteLength","intVal","parseInt","error","numberReviver","token","parseError","push","pop","parent","emit","onValue","text","result","Number","isNaN","match","module","exports","__createBinding","create","o","m","k2","desc","getOwnPropertyDescriptor","__esModule","writable","configurable","enumerable","get","defineProperty","__exportStar","p","hasOwnProperty","call","ContextTree","constructor","subTrees","getContext","head","tail","subTree","subContext","then","context","depth","setContext","removeContext","path","JsonLdParser","jsonld_context_parser_1","readable_stream_1","EntryHandlerArrayValue_1","EntryHandlerContainer_1","EntryHandlerInvalidFallback_1","EntryHandlerPredicate_1","EntryHandlerKeywordContext_1","EntryHandlerKeywordGraph_1","EntryHandlerKeywordId_1","EntryHandlerKeywordIncluded_1","EntryHandlerKeywordNest_1","EntryHandlerKeywordType_1","EntryHandlerKeywordUnknownFallback_1","EntryHandlerKeywordValue_1","ParsingContext_1","Util_1","http_link_header_1","EntryHandlerKeywordAnnotation_1","Transform","options","super","readableObjectMode","parsingContext","ParsingContext","assign","parser","util","Util","dataFactory","jsonParser","contextJobs","typeJobs","contextAwaitingJobs","lastDepth","lastKeys","lastOnValueJob","Promise","resolve","attachJsonParserListeners","on","fromHttpResponse","baseIRI","mediaType","headers","streamingProfile","wellKnownMediaTypes","includes","endsWith","ErrorCoded","ERROR_CODES","LOADING_DOCUMENT_FAILED","has","forEach","linkHeader","parse","link","MULTIPLE_CONTEXT_LINK_HEADERS","uri","ignoreMissingContextLinkHeader","contentType","exec","import","stream","parsed","pipe","output","PassThrough","data","_transform","chunk","encoding","callback","newOnValueJob","lastDepthCheck","flushStacks","listPointer","listPointerStack","quad","rdfRest","rdfNil","getDefaultGraph","listId","listHead","idStack","listRootDepth","splice","EntryHandlerContainer","isBufferableContainerHandler","pendingContainerFlushBuffers","slice","flushBuffer","unaliasKeyword","parentKey","unaliasKeywordParent","emittedStack","handleKey","isValidKeyword","INVALID_REVERSE_PROPERTY_MAP","inProperty","validationStack","property","Math","max","validationResult","validateKey","valid","isLiteral","entryHandler","ENTRY_HANDLERS","testResult","test","handle","isStackProcessor","processingStack","Array","isArray","validateValueIndexes","unaliasedKeywordCacheStack","processingType","graphStack","graphContainerTermStack","jsonLiteralStack","literalStack","annotationsBuffer","subjects","subjectsWasDefined","blankNode","valueBuffer","unidentifiedValuesBuffer","subject","depthOffsetGraph","getDepthOffsetGraph","graphs","getGraphContainerValue","graph","bufferedValue","emitQuadChecked","predicate","object","reverse","isEmbedded","subGraphBuffer","getUnidentifiedGraphBufferSafe","graphBuffer","unidentifiedGraphsBuffer","termType","topLevelProperties","emitQuad","emitError","INVALID_ANNOTATION","annotationsBufferParent","getAnnotationsBufferSafe","annotation","validate","isPropertyHandler","fill","map","v","isParsingContextInner","valueJobCb","contextTree","jobs","job","executeBufferedJobs","applicableTypeJobs","applicableTypeJobIds","typeJob","isPrefixArray","sortedTypeJobs","sort","job1","job2","sortedApplicableTypeJobIds","jobId","DEFAULT_PROCESSING_MODE","EntryHandlerArrayValue","EntryHandlerKeywordContext","EntryHandlerKeywordId","EntryHandlerKeywordIncluded","EntryHandlerKeywordGraph","EntryHandlerKeywordNest","EntryHandlerKeywordType","EntryHandlerKeywordValue","EntryHandlerKeywordAnnotation","EntryHandlerKeywordUnknownFallback","EntryHandlerPredicate","EntryHandlerInvalidFallback","ErrorCoded_1","ContextTree_1","JsonLdParser_1","contextParser","ContextParser","documentLoader","skipValidation","skipContextValidation","produceGeneralizedRdf","allowSubjectList","processingMode","strictValues","defaultGraph","rdfDirection","normalizeLanguageTags","streamingProfileAllowOutOfOrderPlainType","rdfstar","rdfstarReverseInEmbedded","activeProcessingMode","parseFloat","rootContext","parseContext","validateContext","JsonLdContextNormalized","parentContext","ignoreProtection","activeVersion","getContextRaw","PROCESSING_MODE_CONFLICT","INVALID_VERSION_VALUE","keysOriginal","contextData","getContextPropagationAware","contextRaw","contextKeyEntry","scopedContext","propagate","originalDepth","hasApplicablePropertyScopedContext","lastKey","lastKeyValue","handlePendingContainerFlushBuffers","pendingFlushBuffer","emitContext","getUnidentifiedValueBufferSafe","getExpandOptions","EXPAND_OPTIONS","shiftStack","depthOffset","deeperIdStack","allowPrefixForcing","allowPrefixNonGenDelims","allowVocabRelativeToBase","rdf_data_factory_1","canonicalizeJson","DataFactory","rdfFirst","namedNode","RDF","rdfType","rdfJson","getContextValue","contextKey","fallback","entry","type","getContextValueContainer","getContextValueType","valueType","getContextValueLanguage","getContextValueDirection","isContextValueReverse","getContextValueIndex","isPropertyReverse","isPropertyInEmbeddedNode","isPropertyInAnnotationObject","isValidIri","iri","needle","haystack","indexHashes","id","index","existingIndexValue","CONFLICTING_INDEXES","valueToTerm","literal","valueToJsonString","getContextSelfOrPropertyScoped","unaliasKeywords","val","valueLanguage","valueDirection","valueIndex","subValue","INVALID_VALUE_OBJECT","INVALID_VALUE_OBJECT_VALUE","INVALID_INDEX_VALUE","INVALID_LANGUAGE_TAGGED_VALUE","validateLanguage","INVALID_LANGUAGE_TAGGED_STRING","toLowerCase","validateDirection","nullableTermToArray","createLanguageDirectionLiteral","INVALID_TYPED_VALUE","typeTerm","createVocabOrBaseTerm","INVALID_SET_OR_LIST_OBJECT","listValue","graphContainerEntries","values","valueId","valueTerm","INVALID_ID_VALUE","resourceToTerm","stringValueToTerm","Boolean","XSD_BOOLEAN","XSD_INTEGER","XSD_DOUBLE","term","predicateToTerm","expanded","expandTerm","substr","INVALID_IRI_MAPPING","startsWith","expandOptions","intToString","datatype","isFinite","isInteger","toExponential","replace","defaultDatatype","contextType","contextLanguage","contextDirection","language","direction","valueNode","disableCache","cachedUnaliasedKeyword","isPotentialKeyword","unliased","hash","newHash","containers","getContainerHandler","isComplexGraphContainer","validateReverseSubject","INVALID_REVERSE_PROPERTY_VALUE","depthContainer","graphContainerIndex","getContainerGraphIndex","graphId","keyUnaliased","getContainerKey","getPropertiesDepth","lastValidDepth","validateReverseInEmbeddedNode","INVALID_EMBEDDED_NODE","emitAnnotation","annotationQuad","nestedAnnotation","nestedAnnotations","XSD","ContainerHandlerIdentifier","canCombineWithGraph","maybeId","ids","some","equals","ContainerHandlerIndex","graphContainer","indexKey","indexPropertyRaw","INVALID_TERM_DEFINITION","indexProperty","indexValues","indexValue","handlePredicateObject","ContainerHandlerLanguage","INVALID_LANGUAGE_MAP_VALUE","ContainerHandlerType","containerTypeType","entryHasIdentifier","keyOriginal","listRootKey","keyOption","handleListElement","valueOriginal","listRootKeys","newLinkTerm","linkTerm","ContainerHandlerIdentifier_1","ContainerHandlerIndex_1","ContainerHandlerLanguage_1","ContainerHandlerType_1","isSimpleGraphContainer","checkGraphContainer","containersSelf","containersParent","containerHandleName","CONTAINER_HANDLERS","handler","containerName","isAnnotation","depthProperties","depthPropertiesGraph","atGraph","newAnnotation","existingAnnotation","objects","parentDepthOffset","listValueContainer","EntryHandlerKeyword","keyword","EntryHandlerKeyword_1","INVALID_STREAMING_KEY_ORDER","valueKeys","COLLIDING_KEYWORDS","INVALID_INCLUDED_VALUE","valueUnliased","INVALID_NEST_VALUE","elements","element","INVALID_TYPE_VALUE","hasTypedScopedContext","typeContext","c","keywordType","VALID_KEYWORDS_TYPES","errorCode","INVALID_REVERSE_VALUE","relativeIriProtocol","termCleanup","factory","quadCleanup","cleanup","ParserStream","input","transform","objectMode","entries","prefix","destroy","Sink","Impl","readable","blackList","Set","duplex","Proxy","target","Reflect","arguments","bind","set"],"sourceRoot":""}